# 前言

## 本书特色

本书借助数据仓库实现一套用户画像系统的方案。从实际工程案例出发，结合多业务场景，内容涵盖开发离线批处理计算的标签及流式计算标签，为读者的分析、开发、搭建用户画像系统，并借助该用户画像系统为运营人员制定运营用户的策略提供端到端的解决方案。

一套好的解决方案需要包括一下几个层面。

1）架构层：在画像系统的架构层，本书首先介绍了画像数据仓库的架构，进一步介绍了数据存储的技术选型，在什么场景下使用Hive、MySQL、HBase、ElasticSearch等工具存储数据，用户标签开发、人群计算开发等相应数据开发层面的内容，以及整个项目的开发流程和各阶段的关键产出。

2）流量层：介绍整个方案是如何运作起来的。本书主要涉及画像系统的作业流程调度、数据仓库和各业务系统的打通。

3）业务层：包括系统的前后端交互以及如何把这套系统应用在业务服务层面。本书通过用户画像产品化介绍了产品端和画像系统的“代码”层面是如何进行交互操作的。

4）方案价值：包括系统上线后如何服务于各业务场景产生业务价值以及有待进一步完善的地方。

我在学习数据仓库的时候学过Kimball的《数据仓库工具箱》，其中关于数据仓库的34个子系统的介绍对我影响很大，其对于如何解决特定问题并形成结构化思维有着系统的方法论与解决方案。虽然面对具体问题的处理方式是灵活且丰富多样的，但是固定的结构化思维有利于快速找到突破口，形成良好的开端。

# 第1章 用户画像基础

## 1.1 用户画像是什么

### 1.1.1 画像简介

用户画像，即用户信息标签化，通过收集用户的社会属性、消费习惯、偏好特征等各个维度的数据，进而对用户或者产品特征属性进行刻画，并对这些特征进行分析、统计，挖掘潜在价值信息，从而抽象出用户的信息全貌。用户画像可看作企业应用大数据的根基，是定向广告投放与个性化推荐的前置条件，为数据驱动运营奠定了基础。

数据应用体系的层级划分：

| 层级|功能内容|
|------|---------|
|5.战略决策|决策支持|
|4.精细化运营工具|用户行为分析、用户画像、数据挖掘、个性化推荐|
|3.产品运营与分析|自助提取数据、报表分析工具|
|2.报表与可视化|可配置数据报表以及报表的可视化展现|
|1.基础平台搭建|数据平台建设、数据仓库建设、统一SDK|

### 1.1.2 标签类型

用户画像建模其实就是对用户“打标签”，从对用户打标签的方式来看，一般分为3种类型：
①统计类标签；
②规则类标签；
③机器学习挖掘类标签。

下面我们介绍这3种类型的标签的区别：

1.统计类标签

这类标签是最基础也最常见的标签类型，例如，对于某个用户来说，其性别、年龄、城市、星座、近7日活跃时长、近7日活跃天数、近7日活跃次数等字段可以从用户注册数据、用户访问、消费数据中统计得出。该类标签构成了用户画像的基础。

2.规则类标签

该类标签基于用户行为及确定的规则产生。例如，对平台上“消费活跃”的用户这一口径的定义为“近30天交易次数≥2”。在实际开发画像的过程中，由于运营人员对业务更为熟悉，而数据人员对数据的结构、分布、特征更为熟悉，因此规则类标签的规则由运营人员和数据人员共同协商确定；

3.机器学习挖掘类标签

这类标签通过机器学习挖掘产生，用于对用户的某些属性或某些行为进行预测判断。例如，根据一个用户的行为习惯判断该用户是男性还是女性、根据一个用户的消费习惯判断其对某商品的偏好程度。该类标签需要通过算法挖掘产生。

在项目工程实践中，一般统计类和规则类的标签即可以满足应用需求，在开发中占有较大比例。机器学习挖掘类标签多用于预测场景，如判断用户性别、用户购买商品偏好、用户流失意向等。一般地，机器学习标签开发周期较长，开发成本较高，因此其开发所占比例较小。

## 1.2 数据架构

在整个工程化方案中，系统依赖的基础设施包括Spark、Hive、HBase、Airflow、MySQL、Redis、ElasticSearch。除去基础设施外，系统主体还包括Spark Streaming、ETL、产品端3个重要组成部分。

> ETL，是英文Extract-Transform-Load的缩写，用来描述将数据从来源端经过抽取（extract）、转换（transform）、加载（load）至目的端的过程。ETL一词较常用在数据仓库，但其对象并不限于数据仓库。

~~~
画像产品端管理
⬆           
①MySQL （标签元数据管理 BI报表展示数据 监控状态数据）
②ElasticSearch(人群计算/分析)
③HBase（个性化推荐数据 线上实时数据）
④FTP（文件传输）
⬆
Hive数据仓库
用户画像主题建模
（用户属性、用户行为、用户偏好、ID-MAP、购买品类、风险控制、群体偏好...） 
⬆                                                  ⬆
（Hive离线批处理/Spark实时处理）                       （Spark Streaming流式处理）
Hive数据仓库                                        Kafka
ETL作业
（DW、ODS、DM⬅业务数据、日志数据、埋点数据、外部数据）
~~~

下方为常见的数据仓库ETL加工流程，也就是将每日的业务数据、日志数据、埋点数据等经过ETL过程，加工到数据仓库对应的ODS层、DW层、DM层中。

中间即为用户画像建模的主要环节，用户画像不是产生数据的源头，而是对基于数据仓库ODS层、DW层、DM层中与用户相关数据的二次建模加工。在ETL过程中将用户标签计算结果写入Hive，由于不同数据库有不同的应用场景，后续需要进一步将数据同步到MySQL、HBase、Elasticsearch等数据库中。

- Hive：存储用户标签计算结果、用户人群计算结果、用户特征库计算结果。
- MySQL：存储标签元数据，监控相关数据，导出到业务系统的数据。
- HBase：存储线上接口实时调用类数据。
- Elasticsearch：支持海量数据的实时查询分析，用于存储用户人群计算、用户群透视分析所需的用户标签数据（由于用户人群计算、用户群透视分析的条件转化成的SQL语句多条件嵌套较为复杂，使用Impala执行也需花费大量时间）

> Impala是Cloudera公司主导开发的新型查询系统，它提供SQL语义，能查询存储在Hadoop的HDFS和HBase中的PB级大数据。已有的Hive系统虽然也提供了SQL语义，但由于Hive底层执行使用的是MapReduce引擎，仍然是一个批处理过程，难以满足查询的交互性。

用户标签数据在Hive中加工完成后，部分标签通过Sqoop同步到MySQL数据库，提供用于BI报表展示的数据、多维透视分析数据、圈人服务数据；另一部分标签同步到HBase数据库用于产品的线上个性化推荐。

> Sqoop(发音：skup)是一款开源的工具，主要用于在Hadoop(Hive)与传统的数据库(mysql、postgresql...)间进行数据的传递，可以将一个关系型数据库（例如 ： MySQL ,Oracle ,Postgres等）中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中。

## 1.3 主要覆盖模块

搭建一套用户画像方案整体来说需要考虑8个模块的建设。

- 用户画像基础：需要了解、明确用户画像是什么，包含哪些模块，数据仓库架构是什么样子，开发流程，表结构设计，ETL设计等。这些都是框架，大方向的规划，只有明确了方向后续才能做好项目的排期和人员投入预算。这对于评估每个开发阶段重要指标的关键产出非常重要，重点可看1.4节。
    - 用户画像是什么
        - 画像简介
        - 标签类型
    - 数据架构
    - 开发流程
    - 常见表结构设计
        - 日增量数据
        - 日全量数据
- 数据指标体系：根据业务线整理，包括用户属性、用户行为、风险控制等维度的指标体系。
    - 用户属性维度标签
        - 常见用户属性
        - 用户性别
    - 用户行为维度标签
    - 用户消费维度标签
    - 风险控制维度标签
    - 标签命名方式
- 标签数据存储：标签相关数据可存储在Hive、MySQL、HBase、Elasticsearch等数据库中，不同存储方式适用于不同的应用场景。
    - Hive存储
        - 分区插入数据
        - 标签ID-Mapping
    - MySQL存储
        - 元数据管理
        - 标签量级监控
        - 结果集存储
    - HBase存储
    - ES存储
- 标签数据开发：用户画像工程化的重点模块，包含统计类、规则类、挖掘类、流式计算类的开发，以及人群计算功能的开发，打通画像数据和各业务系统之间的通路，提供接口服务等开发内容。
    - 统计类标签开发
    - 规则类标签开发
        - 数据调研
        - 确定业务规则
    - 挖掘类标签开发
        - 读取Kafka数据
        - 标签开发
        - 上线工程化
    - 打通数据服务层
- 开发性能调优：标签加工、人群计算等脚本上线调度后，为了缩短调度时间、保障数据的稳定性等，需要对开发的脚本进行迭代重构、调优。
    - 数据倾斜调优
    - Spark读取小文件调优
    - 使用Spark缓存
    - 减少 Shuffle类算子
    - ID-Mapping映射
    - 开发中间表
- 作业流程调度：标签加工、人群计算、同步数据到业务系统、数据监控预警等脚本开发完成后，需要调度工具把整套流程调度起来。本书讲解了Airflow这款开源ETL工具在调度画像相关任务脚本上的应用。
    - Crontab命令调度
    - Airflow工作平台
        - Airflow服务构成
        - 主要功能模块
        - 工作流调度
        - 常用命令
    - 标签数据监控预警
    - ETL异常排查
- 用户画像产品化：为了能让用户数据更好地服务于业务方，需要以产品化的形态应用在业务上。产品化的模块主要包括标签视图、用户标签查询、用户分群、透视分析等。
    - 标签视图查询
    - 标签编辑管理
    - 自定义配置查询
    - 多维透视分析
    - 目标人群固定
- 用户画像应用：画像的应用场景包括用户特征分析、短信、邮件、站内信、Push消息的精准推送、客服针对用户的不同话术、针对高价值用户的极速退货退款等VIP服务应用。
    - 经营分析
        - 商品分析
        - 用户分析
        - 流量分析
    - 精装营销
        - 短信/邮件营销
        - ROI效果分析
    - 个性化推荐与服务
        - Push消息
        - 相关商品推荐
        - 用户个性化服务

## 1.4 开发阶段流程

### 1.4.1 开发上线流程
~~~
目标解读
任务分解与需求调研
需求场景讨论与明确
应用场景与数据口径确认
特征选取与模型数据落表
线下模型数据验收与测试
线上模型发布与效果追踪（迭代优化，回到需求场景讨论与明确）
~~~

第一阶段：目标解读

第二阶段：任务分解与需求调研

第三阶段：需求场景讨论与明确

第四阶段：应用场景与数据口径确认

第五阶段：特征选取与模型数据落表

第六阶段：线下模型数据验收与测试

第七阶段：线上模型发布与效果追踪

### 1.4.2 各阶段关键产出

- 标签开发：根据业务需求和应用场景梳理指标体系，调研业务上定义的数据口径，确认数据来源，开发相应的标签。标签开发在整个画像周期中占有较大比重。
- ETL调度开发：梳理需要调度的各任务之间的依赖关系，开发调度脚本及调度监控告警脚本，上线调度系统。
- 打通服务层接口：为了让画像数据走出数据仓库，应用到用户身上，需要打通数据仓库和各业务系统的接口。
- 画像产品化：需要产品经理与业务人员、技术开发人员一起对接业务需求点和产品功能实现形式，画产品原型，确定工作排期。Java Web端开发完成后，需要数据开发人员向对应的库表中灌入数据。
- 开发调优：在画像的数据和产品端搭建好架构、能提供稳定服务的基础上，为了让调度任务执行起来更加高效、提供服务更加稳健，需要对标签计算脚本、调度脚本、数据同步脚本等相关计算任务进行重构优化。
- 面向业务方推广应用：用户画像最终的价值产出点是业务方应用画像数据进行用户分析，多渠道触达运营用户，分析ROI，提升用户活跃度或营收。因此，面向业务人员推广画像系统的使用方式、提供针对具体业务场景的解决方案显得尤为重要。在该阶段，相关人员需要撰写画像的使用文档，提供业务支持。

## 1.5 画像应用的落地

## 1.6 某用户画像案例

### 1.6.1 案例背景介绍

### 1.6.2 相关元数据

### 1.6.3 画像表结构设计

## 1.7 定性类画像

# 第2章 数据指标体系

数据指标体系是建立用户画像的关键环节，也是在标签开发前要进行的工作，具体来说就是需要结合企业的业务情况设定相关的指标。

互联网相关企业在建立用户画像时一般除了基于用户维度（userid）建立一套用户标签体系外，还会基于用户使用设备维度（cookieid）建立相应的标签体系。基于cookieid维度的标签应用也很容易理解，当用户没有登陆账户而访问设备时，也可以基于用户在设备上的行为对该设备推送相关的广告、产品和服务。

建立的用户标签按标签类型可以分为统计类、规则类和机器学习挖掘类，相关内容在1.1.2节中有详细介绍。从建立的标签维度来看，可以将其分为用户属性类、用户行为类、用户消费类和风险控制类等常见类型。

## 2.1 用户属性维度

### 2.1.1 常见用户属性

用户属性是刻画用户的基础。常见用户属性指标包括：用户的年龄、性别、安装时间、注册状态、城市、省份、活跃登陆地、历史购买状态、历史购买金额等。

### 2.1.2 用户性别

## 2.2 用户行为维度

## 2.3 用户消费维度

## 2.4 风险控制维度

## 2.5 社交属性维度

## 2.6 其他常见标签划分方式

- 用户属性：包括用户的年龄、性别、设备型号、安装/注册状态、职业等刻画用户静态特征的属性。
- 用户行为：包括用户的消费行为、购买后行为、近N日的访问、收藏、下单、购买、售后等相关行为。
- 偏好细分：用户对于商品品类、商品价格段、各营销渠道、购买的偏好类型、不同营销方式等方面的偏好特征；
- 风险控制：对用户从征信风险、使用设备的风险、在平台消费过程中产生的问题等维度考量其风险程度；
- 业务专用：应用在各种业务上的标签，如A/B测试标签、Push系统标签等；
- 营销场景：以场景化进行分类，根据业务需要构建一系列营销场景，激发用户的潜在需求，如差异化客服、场景用户、再营销用户等；
- 地域细分：标识用户的常住城市、居住商圈、工作商圈等信息，应用在基于用户地理位置进行推荐的场景中；
- 用户分层：对用户按生命周期、RFM、消费水平类型、活跃度类型等进行分层划分。

## 2.7 标签命名方式

|标签主题|用户维度|标签类型|一级归类|
|-------|------|------|------|
|ATTRIBUTE：人口属性<br/>ACTION：行为属性<br/>CONSUME：用户消费<br/>RISKMANAGE：风险控制<br/>...|C:cookieid<br/>U:userid|统计型<br/>规则型<br/>算法型|自然性别<br/>购物性别<br/>年龄<br/>地域<br/>...|

- 标签主题：用于刻画属于哪种类型的标签，如人口属性、行为属性、用户消费、风险控制等多种类型，可分别用ATTRIBUTE、ACTION、CONSUME、RISKMANAGE等单词表示各标签主题。
- 用户维度：用于刻画该标签是打在用户唯一标识（userid）上，还是打在用户使用的设备（cookieid）上。可用U、C等字母分别标识userid和cookieid维度。
- 标签类型：类型可划分为统计型、规则型和算法型。其中统计型开发可直接从数据仓库中各主题表建模加工而成，规则型需要结合公司业务和数据情况，算法型开发需要对数据做机器学习的算法处理得到对应的标签。
- 一级维度：在每个标签主题大类下面，进一步细分维度来刻画用户。

参照上面的命名维度和命名方式，下面通过几个例子来讲述如何命名标签。

对于用户的性别标签，标签主题是人口属性，用户维度为userid，标签类型属于算法型。给男性用户打上标签“ATTRIBUTE_U_01_001”，给女性用户打上标签“ATTRIBUTE_U_01_002”，其中“ATTRIBUTE”为人口属性主题，“`_`”后面的“U”为userid维度，“`_`”后面“01”为一级归类，最后面的“001”和“002”为该一级标签下的标签明细，如果是划分高中低活跃用户的，对应一级标签下的明细可划分为“001”、“002”、“003”。

标签统一命名后，维护一张码表记录标签id名称、标签含义及标签口径等主要信息，后期方便元数据的维护和管理。本节介绍的标签命名方式可作为开发标签过程中的一种参考方式。

# 第3章 标签数据存储

## 3.1 Hive存储

### 3.1.1 Hive数据仓库

建立用户画像首先需要建立数据仓库，用于存储用户标签数据。Hive是基于Hadoop的数据仓库工具，依赖于HDFS存储数据，提供的SQL语言可以查询存储在HDFS的数据。开发时一般使用Hive作为数据仓库，存储标签和用户特征库等相关数据。

“数据仓库之父” W.H.Inmon在《Building the Data Warehouse》一书中定义数据仓库是“一个面向主题的、集成的、非易失的、随时间变化的、用来支持管理人员决策的数据集合”。

- 面向主题：业务数据库中的数据主要针对事务处理，各个业务系统之间是相互分离的，而数据仓库中的数据是按照一定主题进行组织的。
- 集成：数据仓库中存储的数据是从业务数据库中提取出来的，但并不是对原有数据的简单复制，而是经过了抽取、清理、转换（ETL）等工作。业务数据库记录的是每一项业务处理的流水账。这些数据不适合进行分析处理，进入数据仓库之前需要经过一系列计算，同时抛弃一些无关分析处理的数据。
- 非易失：业务数据库中一般只存储短期数据，因此其数据是不稳定的，记录的是系统中数据变化的瞬态。数据仓库中的数据大多表示过去某一时刻的数据，主要用于查询、分析，不像业务系统中的数据库一样经常修改，一般数据仓库构建完成后主要用于访问，不进行修改和删除。
- 随时间变化：数据仓库关注的是历史数据，按时间顺序定期从业务库和日志库里面载入新的数据进行追加，带有时间属性。

在数据仓库建模的过程中，主要涉及事实表和维度表的建模开发。

事实表主要围绕业务过程设计，就应用场景来看主要包括事务事实表，周期快照事实表和累计快照事实表：

- 事务事实表：用于描述业务过程，按业务过程的单一性或多业务过程可进一步分为单事务事实表和多事务事实表。其中单事务事实表分别记录每个业务过程，如下单业务记入下单事实表，支付业务计入支付事实表。多事务事实表在同一个表中包含了不同业务过程，如下单、支付、签收等业务过程记录在一张表中，通过新增字段来判断属于哪一个业务过程。当不同业务过程有着相似性时可考虑将多业务过程放到多事务事实表中。
- 周期快照事实表：在一个确定的时间间隔内对业务状态进行度量。例如查看一个用户的近1年付款金额、近1年购物次数、近30日登陆天数等。
- 累计快照事实表：用于查看不同事件之间的时间间隔，例如分析用户从购买到支付的时长、从下单到订单完结的时长等。一般适用于有明确时间周期的业务过程。

维度表主要用于对事实属性的各个方面描述，例如，商品维度包括商品的价格、折扣、品牌、原厂家、型号等方面信息。维度表开发的过程中，经常会遇到维度缓慢变化的情况，对于缓慢变化维一般会采用：

①重写纬度值，对历史数据进行覆盖；
②保留多条记录，通过插入维度列字段加以区分；
③开发日期分区表，每日分区数据记录当日维度的属性；
④开发拉链表按时间变化进行全量存储等方式进行处理。

在画像系统中主要使用Hive作为数据仓库，开发相应的维度表和事实表来存储标签、人群、应用到服务层的相关数据。

### 3.1.2 分区存储

如果将用户标签开发成一张大的宽表，在这张宽表下放几十种类型标签，那么每天该画像宽表的ETL作业将会花费很长时间，而且不便于向这张宽表中新增标签类型。

要解决这种ETL花费时间较长的问题，可以从以下几个方面着手：

- 将数据分区存储，分别执行作业；
- 标签脚本性能调优；
- 基于一些标签共同的数据来源开发中间表。

### 3.1.3 标签汇聚

### 3.1.4 ID-MAP

开发用户标签的时候，有一项非常重要的内容——ID-Mapping，即把用户不同来源的身份标识通过数据手段识别为同一个体。用户的属性、行为相关数据分散在不同的数据来源中，通过ID-Mapping能够把用户在不同场景下的行为串联起来，消除数据孤岛。

缓慢变化维是在维表设计中常见的一种方式，维度并不是不变的，随时间也会发生缓慢变化。在设计ID-Mapping表时，由于一个用户可以在多个设备上登录，一个设备也能被多个用户登录，所以考虑用缓慢变化维表来记录这种不同时间点的状态变化。

拉链表时针对缓慢变化维表的一种设计方式，记录一个事物开始到当前状态的全部状态变化信息。

## 3.2 MySQL存储

MySQL作为关系型数据库，在用户画像中国可用于元数据管理、监控预警数据、结果集存储等应用中。下面详细介绍这3个应用场景。

### 3.2.1 元数据管理

Hive适合于大数据量的批处理作业，对于量级较小的数据，MySQL具有更快的读写速度。Web端产品读写MySQL数据库会有更快的速度，方便标签的定义、管理。

### 3.2.2 监控预警数据

MySQL还可用于存储每天对ETL结果的监控信息。从整个画像调度流的关键节点来看，需要监控的环节主要包括对每天标签的产出量、服务层数据同步情况的监控等主要场景。

1.标签计算数据监控

主要用于监控每天标签ETL的数据量是否出现异常，如果有异常情况则发出告警邮件，同时暂停后面的ETL任务。

2.服务层同步数据监控

服务层一般采用HBase、Elasticsearch等作为数据库存储标签数据供线上调用，将标签相关数据从Hive数仓向服务层同步的过程中，有出现差错的可能，因此需要记录相关数据在Hive中的数量及同步到对应服务层后的数量，如果数量不一致则触发告警。

在对画像的数据监控中，调度流每跑完相应的模块，就将该模块的监控数据插入MySQL中，当校验任务判断达到触发告警阈值时，发送告警邮件，同时中断后续的调度任务。待开发人员解决问题后，可重启后续调度。

### 3.2.3 结果集存储

结果集可以用来存储多维透视分析用的标签、圈人服务用的用户标签、当日记录各标签的数量，用于校验标签数据是否出现异常。

有的线上业务系统使用MySQL、Oracle等关系型数据库存储数据，如短信系统、消息推送系统等。在打通画像数据与线上业务系统时，需要考虑将存储在Hive中的用户标签相关数据同步到各业务系统，此时MySQL可用于存储结果集。

Sqoop是一个用来将Hadoop和关系型数据库中的数据相互迁移的工具。它可以将一个关系型数据库（如MySQL、Oracle、PostgreSQL等）中的数据导入Hadoop的HDFS中，也可以将HDFS中的数据导入关系型数据库中。

## 3.3 HBase存储

### 3.3.1 HBase简介

HBase是一个高性能、列存储、可伸缩、实时读写的分布式存储系统，同样运行在HDFS之上。与Hive不同的是，HBase能够在数据库上实时运行，而不是跑MapReduce任务，适合进行大数据的实时查询。

画像系统中每天在Hive里跑出的结果集数据可同步到HBase数据库，用于线上实时应用的场景。

下面介绍几个基本概念：

- row key：用来表示唯一一行记录的主键，HBase的数据是按照row key的字典顺序进行全局排列的。访问HBase中的行只有3种方式：
    - 通过单个row key访问；
    - 通过row key正则访问；
    - 全表扫描。

由于HBase通过rowkey对数据进行检索，而rowkey由于长度限制的因素不能将很多查询条件拼接在rowkey中，因此HBase无法像关系数据库那样根据多种条件对数据进行筛选。一般地，HBase需建立二级索引来满足根据复杂条件查询数据的需求。

Rowkey设计时需要遵循三大原则：

- 唯一性原则：rowkey需要保证唯一性，不存在重复的情况。在画像中一般使用用户id作为rowkey。
- 长度原则：rowkey的长度一般为10-100bytes。
- 散列原则：rowkey的散列分布有利于数据均衡分布在每个RegionServer，可实现负载均衡。
- columns family：指列簇，HBase中的每个列都归属于某个列簇。列簇是表的schema的一部分，必须在使用表之前定义。划分columns family的原则如下：
    - 是否具有相似的数据格式；
    - 是否具有相似的访问类型。

### 3.3.2 应用场景

### 3.3.3 工程化案例

在业务人员配置好规则后，下面我们来看在数据调度层面是如何运行的。

用户标签数据经过ETL将每个用户身上的标签聚合后插入到目标表中。聚合后数据存储为每个用户id，以及他身上对应的标签集合。

接下来需要将Hive中的数据导入HBase，便于线上接口实时调用库中数据。

HBase的服务器体系结构遵循主从服务器架构，同一时刻只有一个HMaster处于活跃状态，当活跃的Master挂掉后，Backup HMaster自动接管整个HBase集群。在同步数据前，首先需要判断HBase当前活跃节点是哪台机器。

## 3.4 Elasticsearch存储

### 3.4.1 Elasticsearch简介

Elasticsearch是一个开源的分布式全文检索引擎，可以近乎实时地存储、检索数据。而且扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。对于用户标签查询、用户人群计算、用户群多维透视分析这类对响应时间要求较高的场景，也可以考虑选用Elasticsearch进行存储。

Elasticsearch是面向文档型数据库，一条数据在这里就是一个文档，用json作为文档格式。为了更清晰地理解Elasticsearch查询的一些概念，将其和关系型数据库的类型进行对照。

|Elasticsearch|MySQL||
|------------|------------|---------|
|index|database|数据库|
|type|table|表|
|document|row|行|
|mapping|column|列|
|GET http://...|SELECT * FROM ...|查询数据|
|PUT http://...|UPDATE table SET ...|插入数据|

在关系型数据库中查询数据时可以通过选中数据库、表、行、列来定位所查找的内容，在Elasticsearch中通过索引（index）、类型（type）、文档（document）、字段来定位查找内容。一个Elasticsearch集群可以包括多个索引（数据库），也就是说，其中包含了很多类型（表），这些类型中包含了很多的文档（行），然后每个文档中又包含了很多的字段（列）。Elasticsearch的交互可以使用Java API，也可以使用HTTP的RESTful API方式。

### 3.4.2 应用场景

基于HBase的存储方案并没有解决数据的高效检索问题。在实际应用中，经常有根据特定的几个字段进行组合后检索的应用场景，而HBase采用rowkey作为一级索引，不支持多条件查询，如果要对库里的非rowkey进行数据检索和查询，往往需要通过MapReduce等分布式框架进行计算，时间延迟上会比较高，难以同时满足用户对于复杂条件查询和高效率响应这两方面的需求。

为了既能支持对数据的高效查询，同时也能支持通过条件筛选进行复杂查询，需要在HBase上构建二级索引，以满足对应的需要。在本案中我们采用Elasticsearch存储HBase的索引信息，以支持复杂高效的查询功能。

主要查询过程包括：

1）在Elasticsearch中存放用于检索条件的数据，并将rowkey也存储进去；

2）使用Elasticsearch的API根据组合标签的条件查询出rowkey的集合；

3）使用上一步得到的rowkey去HBase数据库查询对应的结果。

HBase数据存储数据的索引放在Elasticsearch中，实现了数据和索引的分离。在Elasticsearch中documentid是文档的唯一标识，在HBase中rowkey是记录的唯一标识。在工程实践中，两者可以同时选用用户在平台上的唯一标识（如userid或deviceid）作为rowkey或documentid，进而解决HBase和Elasticsearch索引关联的问题。

### 3.4.3 工程化案例

# 第4章 标签数据开发

标签数据开发是用户画像体系搭建中最主要的环节，主要包括离线标签开发、实时类标签开发、用户特征库开发、人群计算、打通数据服务层等开发内容。

离线标签开发主要围绕第2章讲的数据指标体系开发统计类标签、规则类标签、挖掘类标签展开；
实时类标签主要针对给用户展现实时性较强的场景开发相关数据，如首页新人弹窗、新人红包等场景；
用户特征库围绕用户的每次行为明细记录相关数据，如用户浏览、搜索、收藏、下单等行为明细，一般该特征库按日做时间分区；
人群计算应用在数据服务层之前，业务方需要组合用户的标签来筛选出对应人群，通过人群计算功能组合标签划分出对应的人群；
打通数据服务层将业务方根据业务规则圈定出来的用户人群推送到不同的业务系统中去。

## 4.1 统计类标签开发

统计类标签是指统计用户相关数值、客观描述用户状态的标签，如用户的年龄、体重、累计购买金额、累计购买次数、近30日登录次数等。

### 4.1.1 近30日购买行为标签案例

### 4.1.2 最近来访标签案例

## 4.2 规则类标签开发

规则类标签一般是指根据业务运营上的需要，在业务层面指定规则的标签。这类标签会带有一些人为主观判断的因素，所以在开发前需要先进行数据调研，摸清本平台上业务数据的情况，然后再根据运营业务规则开发相关标签。

除了由数据开发人员写脚本开发标签外，还可以根据设定的规则，结合用户在平台上的行为进行自动打标签。比如用户触发的50个行为记录中，有40个记录是3C类商品，我们会给用户打上“数码达人”的标签。根据规则，自动化打标签重要的是结合本平台业务数据情况设定好规则，同时也需要建立测试账号来校验自动打标签的准确性。

### 4.2.1 用户价值类标签案例

RFM模型是衡量用户价值的重要工具和方法，RFM模型主要由3个基础指标组成：

（1）最近一次消费（Recency），是指用户上一次购买时间；
（2）消费频率（Frequency），是指用户在一定时间段内的消费次数；
（3）消费金额（Money），是指用户在一定时间段内累计消费的金额。

在3个基础指标进行组合可以划分出8类人群

|R|F|M|用户类型|备注|
|---|---|---|------|-----------|
|高|高|高|重要价值用户|该类用户与企业交易频繁、交易量大，但长时间没有与企业进行交易，存在流失风险。该类高价值用户是企业利润的潜在来源|
|低|高|高|重要保持用户|该类用户与企业交易频繁、交易量大，且最近一次交易时间间隔短，实际贡献价值很高，是企业优质客户群|
|高|低|高|重要发展用户|该类用户购买量较大，但是从购买频率和近期购买时间来看交易不频繁。这类用户有很高的潜在价值，可采取针对性营销手段吸引他们，提高其购买频率|
|低|低|高|重要挽留用户|该类用户最近一次交易时间短，购买金额大，但是购买频率较低，具有很高的潜在价值|
|高|高|低|一般价值用户|该类用户购买频率较高，但长时间没有与企业进行交易，而且购买量很低，企业已很难从他们身上获取更多利润|
|低|高|低|一般保持用户|该类用户最近一次交易时间间隔短、购买频率高，属于活跃用户，但累计购买金额较少，购买能力有限，属于企业一般保持用户|
|高|低|低|一般发展用户|从购买频率、购买金额一级近期购买情况来看，该类用户属于低价值用户，企业应将其作为一般发展用户|
|低|低|低|一般挽留用户|该类用户最近交易时间间隔短，但是购买频率和购买金额相对较低，无法立即给企业带来较大利润|

### 4.2.2 用户活跃度标签案例

## 4.3 挖掘类标签开发

挖掘类标签需要应用算法挖掘用户相关特征，一般用户相关的挖掘类标签可以包括预测用户男女性别、预测用户点击下单、判断用户已经流失或将要流失、判断用户购买品类偏好等。

由于挖掘类标签需要进行数据调研，找用户行为特征进行特征工程开发、算法参数调优以及上线工程化调度等多个开发环节，一般开发周期较长。

### 4.3.1 案例背景

### 4.3.2 特征选取及开发

机器学习以统计理论为基础，通过算法对已知的训练数据做统计分析从而获得规律，再运用规律对未知数据做预测。在文本分类问题上的基本思路是：标注——人工对一批文档进行准确分类，作为训练集样本；训练——计算机从标注好的文档集中挖掘出能够有效分类的规则，生成分类器；分类——将生产的分类器应用在待分类的文档集中，从而获得文档的分类结果。

首先对待分类的文章做切词处理，将切好的词语写入指定的路径下。对文本进行分类是需要基于特征的，拿到数据后怎么抽取具有区分度的特征是关键的一步。本案例中使用Bunch方法构建文本特征。

文章分类并打标签的建模主要包括以下步骤：

1）对已划分好类型的文本集（训练集）和待划分类型的文本集（测试集）进行文本的分词处理，使文本长句划分为单个词组；

2）将步骤1中切好的词组放入词包中，扩展成链式结构，形成bag of word；

3）应用TF-IDF算法计算训练集文档中每篇文章的TF-IDF权重矩阵；

4）使用朴素贝叶斯分类方法对训练集数据进行训练，得到参数对测试集数据进行分类处理。

模型中用到的算法和数据处理技术包括文本分词、TF-IDF算法、朴素贝叶斯分类算法。

### 4.3.3 文本分词处理

分词是将连续的字序列按照一定的规范重新组合成词序列的过程，中文分词将一个汉字序列（句子）切分成一个个独立的单词。为了构建空间向量，首先需要对待分类文本做切词处理，将切好后的词语写入指定的路径下。在这里，我们使用Python中的jieba工具对文本进行分词

### 4.3.4 数据结构处理

为了便于后续生成词向量空间模型，这些分词后的文本信息需要转换成文本向量信息并对象化。这里使用Scikit-Learn库中的Bunch数据结构，将文本存储成链式结构。Bunch是一个“字典”类型的数据，在实例化Bunch的时候定义Bunch中包含的key类型，在使用时为key参数赋予value值。

### 4.3.5 文本TF-IDF权重

该步骤将上一步存储的结构化数据构建成一个TF-IDF词向量空间，空间中的词均来自该训练集，各个词的权重矩阵也都一并保存下来。在建模的过程中需要注意将训练集的词向量空间坐标赋值给测试集

### 4.3.6 朴素贝叶斯分类

一般的模式分类方法都可应用于文本分类中，常用的分类算法包括朴素贝叶斯分类、支持向量机分类。

本案例针对文本分类，从精度、召回率和F-测度值三个角度进行评价。假设a表示分类器将输入文本正确分类到某个类别的个数；b表示分类器将输入文本错误分类到某个类别的个数；c表示分类器将输入文本错误地排除在某个类别之外的个数；d表示分类器将输入文本正确地排除在某个类别之外地个数；则该分类器的召回率、正确率和F-测量值的计算公式如下：

- 精度：p=a/(a+b)✖100%
- 召回率：r=a/(a+c)✖100%
- F-测度值：F=(2✖p✖r)/(p+r)

## 4.4 流式计算标签开发

Spark Streaming开发相关的实时数据

### 4.4.1 流式标签建模框架

Spark Streaming是Spark Core API的扩展，支持实时数据流的处理，并且有可扩展、高吞吐量、容错的特点。数据可以从Kafka、Flume等多个来源获取，可以使用map、reduce、window等多个高级函数对业务逻辑进行处理。最后处理后的数据被推送到文件系统、数据库等。

在内部Spark Streaming接收实时数据流并将数据分成多个batch批次，然后由Spark引擎进行处理，批量生成结果流。Spark Streaming提供了一个高层抽象，称为Discretized Stream或Dstream，它表示连续的数据流。Dstream可以通过Kafka、Flume等来源的数据流创建，也可以通过在其他Dstream上应用高级操作来创建。

### 4.4.2 Kafka简介

Kafka的核心功能是作为分布式消息中间件。Kafka集群由多个Broker server组成，其中，消息的发送者称为Producer；消息的消费者称为Consumer；Broker是消息处理的节点，多个Broker组成Kafka集群；Topic是数据主题，用来区分不同的业务系统，消费者通过订阅不同的Topic来消费不同主题的数据，每个Topic又被分为多个Partition，Partition是topic的分组，每个Partition都是一个有序队列；offset用于定位消费者在每个Partition中消费的位置。

Kafka对外使用Topic概念，生产者向Topic中写信息，消费者从Brokers里面拉取指定的Topic消息，然后进行业务处理。

向一个Topic中写入数据，写入的数据被追加到Partition的尾部。当Consumer消费消息时，每个Partition下的Offset会按从小到大的顺序向前驱动。

在Consumer消费消息时，还需要指定这个Consumer属于哪个Consumer Group，每个Consumer Group消费一个Topic下的所有Partition数据。每个Consumer实例都属于一个Consumer Group，每一条消息只会被同一个Consumer Group里的一个Consumer实例消费，不同的Consumer Group可以同时消费同一条数据。开发时需要在对应的代码中指定GroupId。

### 4.4.3 Spark Streaming集成Kafka

Spark Streaming可以通过Receiver和Direct两种模式来集成Kafka。

在Receiver模式下，Spark Streaming作为Consumer拉取Kafka中的数据，将获取的数据存储在Executor内存中。但可能会因为数据量大而造成内存溢出，所以启用预写日志机制（Write Ahead Log）将溢出部分写入到HDFS上。在接受数据中，当一个Receiver不能及时接收所有的数据时，再开启其他Receiver接收，它们必须属于同一个Consumer Group，这样可以提高Streaming程序的吞吐量。整体来说，Receiver模式效率较低，容易丢失数据，在生产环境中使用较少。

在Direct模式下，Spark Streaming直接读取Kafka的topic中的所有Partition，获取Offset信息。Spark Streaming中有一个Inputstream，这个Dstream的每一个分区对应着Kafka中需要消费的Topic的每一个分区，并且从Kafka中读取数据。在Direct模式下，是Spark Streaming自己跟踪消费的Offset，消除了与Zookeeper不一致的情况，处理和输出过程符合Exactly-once模式。

对比来看，Receiver模式是通过Zookeeper来连接Kafka队列的，Direct模式则直接连接Kafka节点来获取消息。Receiver模式消费Topic中的offset是保存在Zookeeper中，Direct模式消除了与Zookeeper不一致的情况，基于Direct模式可以使Spark Streaming应用完全达到Exactly-once语义情况。

Spark Streaming 对 Kafka的集成有两个版本，一个是0.8版本，另一个是0.10以上的版本，0.10以后只保留了Direct模式。

### 4.4.4 标签开发及工程化

实时类标签的处理流程主要包括4个部分：

- 读取数据源，这里讲解消费Kafka中的数据；
- 解析数据，即解析消费的Kafka数据；
- 将解析后的数据存储到指定位置（如MySQL、HDFS、HBase等）；
- 存储消费的Offset，Direct模式下需要保存消费到的位置。

## 4.5 用户特征库开发

为进一步从多个维度丰富用户特征，挖掘用户的相关行为，除了开发用户标签体系外，一般还会开发用户的特征库。一方面为个性化推荐、精确营销、商业分析等应用提供中间层数据，另一方面也可以削减不同算法在特征构建时的冗余加工。

简单来说，用户特征库就是对用户每一次的不同行为（如浏览、收藏、搜索、购买等）及该行为对应的标签（或商品品类）进行详细的记录，以便从用户的行为特征中挖掘用户的偏好。与开发用户标签相比，用户特征库可以对数据进行汇总统计，从多个维度分析用户特征，而用户标签则“相对静态”地记录了用户当前的状态。

### 4.5.1 特征库规划

### 4.5.2 数据开发

### 4.5.3 其他特征库规划

## 4.6 标签权重计算

用户在平台上的不同行为具体到用户标签层面有着不同的行为权重。在本案例场景中，用户购买某商品的行为权重要比用户添加到购物车、收藏某商品、浏览某商品的行为权重依次要高。具体到某个产品层面，需要用户画像建模人员与运营人员密切沟通，结合业务场景给不同的行为类型定权重（基本思想是复杂程度越高的行为价值越大），同时需要考虑标签本身在全体标签类型中的权重属性。下面介绍主观权重打分结合TF-IDF算法的综合权重计算方法。

### 4.6.1 TF-IDF词空间向量

TF-IDF是一种统计方法，用以评估一个字或词相对于一个文件集或一个语料库中的其他词语的重要程度。字词的重要性随着它在文件集中出现的次数的增加成正比增加，同时随着它在语料库中出现的频率成反比下降。在本章介绍的案例中，对于每个用户来说，其身上同一个标签出现的次数越多，该标签对于这个用户来说越重要，该标签在全部用户的所有标签产生的标签集中出现的次数越多，该标签的重要性越低。

使用TF-IDF方法来表示标签（Tag,T）和用户（User,P）之间的关系：其中w(P,T)表示一个标签T被用于标记某个用户P的次数，TF(P,T)表示这个标记次数在所有标记P的标签中所占的比例，TF计算公式如下：

$$
TF(P,T)=\frac{w(P,T)}{\sum_{T_i=tags}w(P,T_i)}
$$

在一定程度上，这个比例反映了用户P被认为与标签T有关联的度量。这个度量越大说明在更多情况下用户P与标签T之间的关系越紧密。

IDF（P,T）表示标签T的稀缺程度，即这个标签在全体用户的所有标签中出现的概率。对一个标签T来说，如果它本身出现的概率就比较小，却被用来标记用户P，这会使得用户P与标签T之间的关系更加紧密。IDF的计算公式如下：

$$
IDF(P,T)=log\frac{\sum_{P_j=users}\sum_{T_i=tags}w(P_j,T_i)}{\sum_{P_j=tags}w(P_j,T)}
$$

这样，用户P和标签T之间的关系系数为TF(P,T)和IDF(P,T)的乘积，计算公式为：

$$
rel(P,T)=TF(P,T)\times IDF(P,T)
$$

至此，通过TF-IDF算法求出了用户和标签之间的权重关系。但是此时计算标签的权重还没有结束，当前的标签权重是未考虑业务场景，仅考虑用户与标签之间的关系求出来的，这显然是不够的。

### 4.6.2 时间衰减系数

当用户数据达到足够的密集程度后，用户身上打的标签对应的属性会表现出较高的稳定性，这种稳定性与用户长期行为形成的个人真实特征相匹配。但是也存在灵活变化的适应性较弱的问题。

为了解决这个问题，我们引入了时间衰减这个参数，根据发生时间的先后为用户行为数据分配权重。时间衰减是指随着时间的推移，用户的历史行为和当前行为的相关性不断减弱，在建立与时间衰减相关的函数时，我们可套用牛顿冷却定律数学模型。牛顿冷却定律描述的场景是：一个较热的物体在一个温度比其温度低的环境下，这个较热的物体的温度是要降低的，而周围物体的温度要上升，最后物体的温度和周围的温度达到平衡，在这个平衡的过程中，较热物体的温度F(t)随着时间t的增长而呈现指数型衰减，其温度衰减公式为：

$$
F(t)=初始温度\times e^{-\alpha \times 间隔时间}
$$

其中，α为衰减常数，可通过回归计算得出。例如：指定45分钟后物体温度为初始温度的0.5倍，即0.5=1✖exp(-α✖45)，求得α=0.1556。

在用户画像的应用中，用户的某些行为会随时间衰减，而某些行为不会随时间衰减。一般来说，用户操作的复杂程度越高，其行为随时间衰减的影响性越小，我们可视该类行为不随时间衰减（如下单、购买行为）。对于随时间衰减的行为，在计算行为权重时需考虑时间因素，衰减方式可套用牛顿冷却定律；对于不随时间衰减的行为则不必考虑时间的影响。

### 4.6.3 标签权重配置

用户标签的权重最终还是需要进一步结合标签所处的业务场景、距离当前时间、用户行为产生该标签的行为次数等因素，最终得到用户标签权重的综合打分公式：

用户标签权重=行为类型权重✖时间衰减✖用户行为次数✖TF-IDF计算标签权重

公式中各参数的释义如下：

- 行为类型权重：用户浏览、搜索、收藏、下单、购买等不同行为对用户而言有着不同的重要性。一般而言，操作复杂度越高的行为权重越大。该权重值一般由运营人员或数据分析人员主观给出。
- 时间衰减：用户某些行为受时间影响不断减弱，行为时间距现在越远，该行为对用户当前行为来说意义越小。
- 行为次数：用户标签权重按天统计，用户某天与该标签产生的行为次数越多，该标签对用户的影响越大。
- TF-IDF计算标签权重：由每个标签对用户的重要性与该标签在全体标签中的重要性的乘积得出每个标签的客观权重值。

结合标签权重的计算公式，可以对用户特征库的行为数据计算标签权重，筛选出与用户行为相关性最大的标签。

## 4.7 标签相似度计算

根据标签之间的相互关系进行聚类也是画像开发中经常遇到的一类问题。如何结合业务背景对标签进行有效聚类，不同的公司或业务背景有不同的处理方式。本节内容通过一个案例来介绍如何对用户身上的标签构建“同现矩阵”的方式对标签进行聚类。

### 4.7.1 案例场景

同现矩阵是指标签和标签之间的关联程度，这种关联程度由用户身上的标签所决定。这里的同现是指标签同时出现，即一个用户被打上A标签的同时被打上B标签。如果有很多用户同时被打上A、B标签，那么A、B标签之间可能潜在某种相关性。

### 4.7.2 数据开发

用余弦相似度函数计算两两标签之间的相关性。余弦相似度函数通过空间中两个向量夹角的余弦值来衡量两个个体差异的大小，余弦值越接近1，表明两个向量的相似性越大。

## 4.8 组合标签计算

组合标签计算是画像开发中的一个重要模块。本章前面几个小节讲的都是如何开发用户身上的一个个标签，当业务方根据业务规则应用标签时，是需要组合多个标签创建对应的用户群体的，此时需要应用到组合标签计算。

### 4.8.1 应用场景

组合标签计算的实现逻辑，总结来说分为3个过程：

- 读取不同组合标签的计算规则
- 将人群规则拼接成接口传入参数的查询命令，通过接口方式进行查询；
- 接口查询计算时，通过Elasticsearch查询符合这些条件的用户id，返回用户id作为rowkey去HBase中查询这些用户身上的标签信息。

### 4.8.2 数据计算

业务人员在画像产品端可以组合标签圈定人群，对应的在关系数据库中将会记录该条人群规则包含的用户标签。

记录圈定人群规则的表中主要包括以下主要内容：

- 人群id：创建该条人群规则对应的唯一id标识。
- 人群名称：该条人群规则在业务定义上的名称。
- 人群规则：人群组合标签规则中包含的标签及标签值。
- 人群数量：该人群对应的数量。
- 创建时间：该人群规则首次创建时间。
- 修改时间：该人群规则的最近一次修改时间。
- 是否应用：该人群是否应用到线上。

本节介绍了一种组合标签计算用户人群的解决方案，总结来说包括两个过程：首先从关系库表中（如MySQL）读取业务人员圈定人群的规则，将人群规则拼接成接口的传入参数，然后通过接口请求Elasticsearch的方式查询对应的用户id。

## 4.9 数据服务层开发

数据最终的目的是走出数据仓库，应用到业务系统和营销场景中。一般在开发完画像后，还需要打通标签数据和各业务系统之间的通路，通过产品化的方式将标签数据应用到业务中去。这里需要打通的服务层包括离线服务层和在线服务层，其中离线服务层将ETL后的用户群数据推送到对应业务系统，在线服务层以RESTful API方式提供接口服务，可支持个性化推荐、营销推送、在线特征库等场景。

几个典型的应用场景包括：

1）短信营销：可以基于用户画像的自定义圈人服务，进行重点用户的广告/消息推送/短信/邮件营销。

2）邮件营销：可以基于不同用户群体，进行个性化有效的会员营销，同时在服务上也可以基于已经打通的用户数据，提供会员差异化的客服/物流/活动等服务。

3）风控系统：可以根据用户级别，作为风控系统规则引擎或模型的输入。

4）数据分析：可以分析不同群体的行为特征，提供分析和决策。

5）BI数据：可以监控核心用户群体的变化，为上层决策提供数据基础支持。

> BI就是商务智能，它是一套完整的解决方案，用来将企业中现有的数据进行有效的整合，快速准确地提供报表并提出决策依据，帮助企业做出明智的业务经营决策。简单来说，就是用BI工具，来代替excel处理海量数据。

### 4.9.1 推送至营销系统

### 4.9.2 接口调用服务

## 4.10 GraphX图计算用户

### 4.10.1 图计算理论及应用场景

Spark GraphX是分布式图计算框架，基于Spark平台提供了对图计算的简单且丰富的接口，以满足对分布式图处理的需求。

对Graph视图的所有计算，最终会转化为其关联的Table视图的RDD操作来完成。在工程实践中，存在需要计算二度关系用户的场景，即用户与用户之间通过其共同的好友找到他们的二度关系熟人，这种对图的挖掘计算可借助Spark GraphX完成。

GraphX提供顶点（Vertex）、边（Edge）、三元组（Triple）三种视图，GraphX图计算也在这三种视图上完成。顶点包括顶点id和顶点属性；边包括源顶点（srcid），目标顶点（dstid）和属性（property）；三元组是对顶点和边的扩展，将顶点和边的属性保存为一个RDD【EdgeTriplet\[VD,ED\]】。

### 4.10.2 数据开发案例

在GraphX中核心操作是调用API：aggregateMessages，负责向邻边发送消息，以及合并收到的邻边消息。

# 第5章 开发性能调优

## 5.1 数据倾斜调优

数据倾斜是开发画像过程中常遇到的问题，当任务执行一直卡在map 100%、reduce 99%，最后的1%花了几个小时都没执行完时，这时一般是遇到了数据倾斜。

问题出现的原因是当进行分布式计算时，由于某些节点需要计算的数据较多，导致其他节点的reduce阶段任务执行完成时，该节点的任务还没有执行完成，造成其他节点等待该节点执行完成的情况。比如两张大表在join的时候大部分key对应10条数据，但是个别几个key对应了100万条数据，对应10条数据的task很快执行完成了，但对应了100万数据的key则要执行几个小时。

下面介绍两种解决数据倾斜问题的方案。

方案一：过滤掉倾斜数据

当少量key重复次数特别多，如果这种key不是业务需要的key，可以直接过滤掉。

方案二：引入随机数

数据按照类型group by时，会将相同的key所需的数据拉取到一个节点进行聚合，而当某组数据量过大时，会出现其他组已经计算完成而当前任务未完成的情况。可以考虑加入随机数，将原来的一组key强制拆分为多组进行聚合。

## 5.2 合并小文件

在Spark执行“insert overwrite table表名”的语句时，由于多线程并行向HDFS写入且RDD默认分区为200个，因此默认情况下会产生200个小文件。

Spark中可以使用reparation或coalesce对RDD的分区重新进行划分，reparation是coalesce接口中shuffle为true的实现。

在Spark内部会对每一个分区分配一个task执行，如果task过多，那么每个task处理的数据量很小，这就会造成线程频繁在task之间切换，导致集群工作效率低下。为解决这个问题，常采用RDD重分区函数来减少分区数量，将小分区合并为大分区，从而提高集群工作效率。

## 5.3 缓存中间数据

Spark的一个重要能力就是将数据持久化缓存，这样在多个操作期间都可以访问这些持久化的数据。当持久化一个RDD时，每个节点的其他分区都可以使用RDD在内存中进行计算，在该数据上的其他action操作将直接使用内存中的数据，这样会使其操作计算速度加快。对RDD的复杂操作如果没有持久化，那么一切操作都会从源头开始，一步步往后计算，不会复用原始数据。

在画像标签每天ETL的时候，对于一些中间计算结果可以不落磁盘，只需把数据缓存在内存中。而使用Hive进行ETL时需要将一些中间计算结果落在临时表中，使用完临时表后再将其删除。

RDD可以使用persist或cache方法进行持久化，使用StorageLevel对象给persist方法设置存储级别时，常用的存储级别如下所示。

- MEMORY_ONLY：只存储再内存中；
- MEMORY_ONLY_2：只存储再内存中，每个分区在集群中两个节点上建立副本；
- DISK_ONLY：只存储在磁盘中；
- MEMORY_AND_DISK：先存储在内存中，内存不够的话存储在磁盘中。

其中cache方法等同于调用persist()的MEMORY_ONLY方法。

在画像标签开发中，一般从Hive中读取数据，然后将需要做中间处理的DataFrame注册成缓存表。

## 5.4 开发中间表

在用户画像迭代开发的过程中，初期开发完标签后，通过对标签加工作业的血缘图整理，可以找到使用相同数据源的标签，对这部分标签，可以通过加工中间表缩减每个画像调度作业时间。

做中间层设计需要明确几个重要的点：

1）这个中间层对应的业务场景、业务目标是什么？
2）业务方有了这份中间层数据以后可以进行哪些维度分析，ETL时有了这份中间层数据可以减少对哪些数据的重复开发计算？
3）这个业务场景分析中包含哪些分析维度和指标？
4）同时面向很多业务场景的中间层不一定是好的中间层。

在开发中间表前，首先需要梳理目前用户标签计算时依赖的上游数据仓库的表和标签的血缘依赖。

# 第6章 作业流程调度

在开发完每一个画像标签对应的脚本后，需要将该脚本提上调度流，每天定时作业刷昨天产生的新标签。

在开发迭代的过程中，开发初期会使用crontab命令调度开发任务定时执行，但随着调度任务规模的增加，使用Kettle、Airflow这样的工具替代crontab做定时调度会提高集群工作效率。一方面可以帮助厘清任务之间的依赖关系，另一方面当调度出现异常时可快速定位出现问题的位置。

## 6.1 crontab命令调度

画像开发的初期阶段，为了数据尽快上线迭代，对于标签调度作业规范化的要求或许会放在次要位置。在这一阶段中，通过Shell脚本、Python脚本和crontab调度命令即可完成简单的ETL任务。

## 6.2 Airflow工作平台

Airflow时Airbnb内部发起的一个工作流管理平台。使用Python编写实现的任务管理、调度、监控工作流平台。Airflow的调度依赖于crontab命令，与crontab相比，Airflow可以方便地查看任务的执行状况，任务执行失败时可以收到邮件通知、查看错误日志。对于管理调度任务有很大帮助。

crontab命令管理调度的方式总结来看存在以下几个方面的弊端：

1）在多任务调度执行的情况下，难以厘清任务间的依赖关系；

2）不便于查看当前执行到哪一个任务；

3）不便于查看调度流下每个任务执行的起止消耗时间，而这对于优化task作业是非常重要的；

4）不便于记录历史调度任务的执行情况，而这对于优化作业和排查错误是非常重要的；

5）执行任务失败时不便于查看执行日志，不方便定位报错的任务和接收错误告警邮件。

### 6.2.1 基础概念

在介绍Airflow这个调度工具前先介绍几个相关的基础概念。

- DAG（Directed Acyclic Graph，有向无环图）：用于描述数据流的计算过程。
- Operators：描述了DAG中一个具体的task要执行的任务，如BashOperator为执行一条bash命令，EmailOperator用于发送邮件，HTTPOperator用于发送HTTP请求，PythonOperator用于调用任意的Python函数。
- Task：是Operator的一个实例，也就是DAG的一个节点。
- Task Instance：记录task的一次运行。TaskInstance有自己的状态，包括“running”“success”“failed”“skipped”“up for retry”等。
- Trigger Rules：指task的触发条件。

每个节点可视为一个task，每个task用于执行一条任务，比如执行某个表的ETL加工。这些task调度任务按执行顺序的先后连接起来形成一个有向无环图。

### 6.2.2 Airflow服务构成

一个正常运行的Airflow系统一般由以下几个服务构成。

1.WebServer

Airflow提供了一个可视化的Web界面，启动WebServer后，可以在Web界面上查看定义好的DAG并监控及改变其运行状况。也可以在Web界面中对一些变量进行配置。

2.Worker（Celery模式）

一般地，我们使用Celery Worker来执行具体作业。Worker可以部署在多台机器上，并可以分别设置接收的队列。当接收的队列有作业任务时，Worker就会接收这个作业任务并开始执行。Airflow会自动在每个部署Worker的机器上同时部署一个Server Logs服务，这样就可以在Web界面上方便地查看分布在不同机器上的日志了。

3.Scheduler

整个Airflow的调度由Scheduler负责发起，每隔一段时间Scheduler就会检查所有定义完成的DAG和定义在其中的作业，如果有符合运行条件的作业，Scheduler就会发起相应的作业任务以供Worker接收。

4.Flower（Celery模式）

Flower提供了一个可视化界面用于监控所有Celery Worker的运行状况。

### 6.2.3 Airflow的安装

### 6.2.4 主要模块功能

### 6.2.5 工作流调度

### 6.2.6 脚本实例

### 6.2.7 常用命令行

### 6.2.8 工程化调度方案

在工程实践中，对于用户画像每天的ETL调度工作，除了标签的调度，还包括同步数据到服务层、数据的监控预警（标签预警、同步到服务层的预警等）。下面详细介绍工程化调度中覆盖的模块，通过该调度方案可以把前面介绍的标签开发、同步数据到服务层、服务层调用数据等开发内容的知识点全部串联起来，使读者对用户画像整体方案有一个宏观上的认知。

用户画像工程的调度主要可划分为2个模块，包括在数据仓库进行的标签计算，以及数据写入服务层，下面详细进行介绍。

1.标签计算

标签计算主要用于每天通过ETL将标签打在用户身上，包括统计类标签、规则类标签、机器学习标签等。对应的ETL脚本执行作业过程中如果失败，Airflow支持失败后重试。

标签计算完成后，校验当天标签的产出是否正常，当校验通过后继续进行输出到服务层的任务，否则任务失败重试或任务挂起。

2.数据写入服务层

在ETL任务执行到服务层时，将对应的标签数据写入服务层对应的数据库中。如对接本公司的营销平台，则将数据写入到HBase、Elasticsearch等数据库，或对接第三方营销平台，通过接口的方式将数据输出到第三方营销平台去。

3.服务层调用

服务层通过接口方式调用符合业务需求的用户数据。

## 6.3 数据监控预警

相比Hive，由于MySQL等关系型数据库对小量的数据读写速度较快，所以开发时考虑将数据的监控相关表维护在MySQL中。

数据监控预警整体来看涵盖下面几个主要模块。

标签监控预警：用于监控每个标签当日的ETL是否产生问题，当数据量超出正常范围时，发出报警邮件。

服务层数据监控预警：数据从数据仓库走出提供到服务层时，该过程中是否正常进行，一般通过对比数据仓库（Hive）中各业务线的数量和各业务系统（如MySQL、HBase、csv文件等）中对应的业务线的数量进行监控。

### 6.3.1 标签监控预警

标签监控预警主要用于保证每日用户标签加工的正常进行，当标签的数量或覆盖用户情况出现波动时会触发邮件报警，开发人员收到报警邮件后定位问题标签的原因并进行处理。

### 6.3.2 服务层预警

该监控主要用于保证服务层数据的稳定性和准确性，在数据从数据仓库走向服务层时需要对其进行监控，否则应用到各业务系统中会影响用户的感知或体验。如：当推动到服务层的数据存在问题时，App推送给用户的弹窗或发送给用户的短信邮件等都会受到影响。所以在将数据推送到服务层前需要对其监控，当发现问题时，暂停推送到服务层，排查问题后再重新推送。

## 6.4 ETL异常排查

在画像标签每天ETL调度的过程中，难免会遇到调度失败的情况。作业失败时，短时间（小时级别）来看对于圈人服务、BI透视分析来说暂停服务的影响还不算很大，但是对于线上实时推荐的业务来说就会带来用户体验较差、推荐准确性不足等关系到营收的重大影响。因此在调度失败时，快速定位作业失败的原因很关键。

关于调度失败的原因，总结下来，按照排查错误方向的优先级来说，主要包括以下几个方面。

1.资源池内存不足导致作业失败

这是最常见的失败原因。当集群资源竞争严重时，画像标签ETL调度很有可能受到影响，关于该种原因的排查，只需查看调度失败任务对应的执行日志文件即可。在日志文件中搜索“error”关键词可快速定位到报错原因的位置。

通常因内存不足而引起的作业失败，日志中会报出“java.lang.OutOfMemoryError”等错误类型。

2.上游数据ETL延迟导致标签加工失败

出现该错误的原因可通过标签数据监控预警邮件发现。标签数据监控预警会报出当日哪个标签的数据量下降幅度超过合理范围。针对数据量下降异常的标签，查看该标签加工脚本依赖的上游表包括哪些，进一步查看上游表的ETL完成时间是否在标签脚本ETL时间之前。

3.上游数据ETL异常或失败导致标签加工失败

这种失败原因比第2条失败原因更难发现。当上游数据已经加工完毕，写表落仓后，即使在HDFS上查找上游文件的写入时间也不会发现问题。此时可通过横向对比该上游表近期每日的数据量来发现是否存在问题。

4.标签脚本逻辑导致数据加工失败

这种情况也是可能引起错误的原因之一。标签上线前期ETL作业正常，但随着时间的推移，积攒的问题最终会爆发出来。这里举一个开发过程中遇到的问题来进行详解。

我们知道一个用户（userid）可能在多个设备上登录，同一个设备（cookieid）上可能登陆过多个用户，即userid和cookieid为多对多关系。在某次开发需要从cookieid关联到userid，获取userid的状态标签时，忽略了这两个维度之间的多对多关系，未加条件限制。初始化标签数据时，脚本执行后跑出“看似合乎逻辑”的数据。但ETL作业调度两天后，这种直接多对多关联的错误逻辑，引起了数据膨胀，造成作业执行失败。

5.线上业务变动导致原有标签加工逻辑失效

这种问题虽然不常见，但发生时也会引起标签数据的波动。

对于这种情况应尽量避免，需要运营方在上线新的链接前通知标签开发人员。

# 第7章 用户画像产品化

## 7.1 即时查询

即时查询功能主要面向数据分析师。将用户画像相关的标签表、用户特征库相关的表开放出来供数据分析师查询。

## 7.2 标签视图与标签查询

标签视图和标签查询功能主要是面向业务人员使用。

## 7.3 元数据管理

标签编辑管理功能主要是面向数据开发人员。数据开发人员在开发完标签后，需要将标签录入元数据进行管理。

标签的编辑管理也即对标签做元数据管理。

可在该页面中编辑标签相关的元数据，包括标签id、名称、开发人员、标签类型、标签描述、数据源等，方便业务人员在应用时理解该标签的业务意义以及其负责人员。

## 7.4 用户分群功能

用户分区功能主要是面向业务人员使用。

## 7.5 人群分析功能

人群分析功能主要是面向业务人员、数据分析师、产品经理等人群使用。

人群分析提供根据现有用户标签圈定用户群的功能，同时业务方可以从多个维度（如地域、性别、年龄、消费水平等）进一步分析该批用户群的特征，从而为精细化运营提供支持。和上一小节讲的用户人群功能相似，人群分析功能首先也需要组合标签圈定用户群体，不同之处在于多维透视分析功能支持从多个维度去分析圈定用户群体的特征，而用户分群功能侧重的是将筛选出来的用户群推送到各业务系统中，提供服务支持。

# 第8章 用户画像应用

## 8.1 经营分析

### 8.1.1 商品分析

借助用户画像，可以对商品的销量进行分析，比如说可以快速定位到爆款品类，进一步分析购买爆款品类的用户在各个维度上的特征。

### 8.1.2 用户分析

借助画像产品可以了解平台的性别、年龄、职业等各维度特征的用户量分布特征。

### 8.1.3 渠道分析

根据增长黑客理论（AARRR）模型，将产品的营收路径拆分为激活-注册-留存-下单-传播，其中激活主要是流量运营在负责；用户运营会贯穿接下来的流程；内容运营主要负责生产优质内容来提高用户黏性，从而提高留存；主线运营主要负责主营业务的产品路径，优化转化节点，提高转化率。

~~~
AARRR模式及运营重点：
                     / \
变现                /传播\            用户运营、内容运营、主线运营   
营收转化           / 下单 \           主线运营、用户运营
促活、留存        /  留存  \           用户运营、内容运营
注册转化         /   注册   \          用户运营、流量运营
拉新            /    激活    \         流量运营
~~~

下面对AARRR模型中各渠道的定义及运营方式进行详细讲解：

1）激活：这是流量来源的必经动作，只有有足够多的用户进入平台，才能对这些用户进行转化。而我们都知道，互联网新客的获客成本是比较高的，如果不清楚渠道的流量质量，很有可能既花了钱又没有获取到质量较好的用户。对于这一块，用户触达的基本分析就是对用户来源渠道进行分析，即本节要介绍的内容。在不依靠自然流量的情况下，哪些合作、投放渠道对我们的App、Web产品更合适。

2）注册：流量激活之后，如果用户只是点进来就走了，这个流量对产品并没有什么作用。只有通过高质量的内容、合适的产品功能契合用户的需求，用户才会有进一步了解产品的欲望，才会有转化的下一步操作——注册。因此通过渠道将用户引入平台还是远远不够的，需要进一步关注用户是否进一步注册转化，从注册流程上看是否存在需要优化的细节点。

3）留存：前面我们提过，新用户的获客成本是比较高的，因此不可能一味地花钱去获取新的流量，同时也需要维系老用户，让进来的用户能对产品形成依赖，产品能契合用户需求，让用户持续不断地来用我们的产品。因此提升留存一方面需要满足用户需求，另一方面需要优化用户体验。在优化过程中可通过用户分群、精细化运营、将精准内容推送给有特定需求的用户等手段来提高用户对产品的满意度。数据可以通过追踪用户行为来分析哪些行为可以促使用户持续访问产品、如何激发这些行为发生。并通过用户生命周期的研究，对沉默用户进行识别，让运营通过运营手段对这批用户进行唤醒：对流失用户进行标记，让运营通过推送、发放优惠等方式进行用户召回。

4）营收：用户是收入的前提。只有产品完全满足用户的需求，用户认同产品的价值，才会促使用户向付费转化。而要让产品持续稳定地运营下去，就需要通过一系列运营手段让新用户持续地向付费转化，让老用户持续付费。而用户运营的基础是对用户足够了解、足够熟悉，数据能做的是帮助运营了解用户的所有属性，让用户不断向营收进行转化。

5）传播：只有用户对产品高度认可及对产品功能高度依赖，才会愿意将产品分享或推荐给其他人。而在分享或推荐的过程中，又扩大了流量的来源，形成了良性的循环，最终源源不断的将用户往营收用户进行转化，达到价值翻倍的目的。

### 8.1.4 漏斗分析

漏斗分析用于分析产品流程或关键节点的转化效果，常借助漏斗图展现转化效果。漏斗图是一种外形类似漏斗的可视化图表，使用该方法可以直观地追踪产品的整体流程、追踪业务的转化路径、追踪不同生命周期阶段下的用户群体表现。通过一系列转化率的分析，可以迅速定位问题，方便运营人员及时调整运营策略。

漏斗图的主要运用场景有以下几个：

- 产品流程的关键路径转化追踪，比如电商常用的购买流程；
- 业务价值路径的转化流程追踪，比如常用的AARRR模型的价值转化追踪；
- 虚拟流程类指标追踪，比如按生命周期区分的处于不同生命周期阶段的用户流转形态追踪。

转化漏斗帮助业务人员分析每天来访用户中在详情页访问、加购点击、下单点击、支付结算等各关键环节的转化情况，从而帮助业务人员不断优化产品路径。

### 8.1.5 客服话术

用户标签在客服系统中也有广泛的应用。生活中经常遇到这样的场景：当我们在向某平台的客服部门投诉、咨询或反馈意见时，客服人员可以准确地说出我们在该平台的历史购买情况，上一次咨询的问题和处理结果等信息，这也是画像标签应用的场景之一。

### 8.1.6 人群特征分析

前4节介绍的都是从单一维度分析用户特征，而用户人群特征分析可以通过组合标签来自定义人群，然后对自定义人群从各个维度进行透视分析或建立对照组人群做人群对比分析。

## 8.2 精准营销

### 8.2.1 短信/邮件营销

### 8.2.2 效果分析

## 8.3 个性化推荐与服务

# 第9章 实践案例详解

## 9.1 风控反欺诈预警

### 9.1.1 应用背景

