# 第1章 走进Java世界中的线程

## 1.1 进程、线程与任务

进程（Process）是程序的运行实例。例如，一个运行的Eclipse就是一个进程。进程与程序之间的关系就好比播放中的视频（如《摩登时代》这部电影）与相应的视频文件（如MP4文件）之间的关系，前者从动态的角度刻画事物而后者从静态的角度刻画事物。运行一个Java程序的实质是启动一个Java虚拟机进程，也就是说一个运行的Java程序就是一个Java虚拟机进程。

进程是程序向操作系统申请资源（如内存空间和文件句柄）的基本单位。线程（Thread）是进程中可独立执行的最小单位。例如，一个实现从服务器上下载大文件功能的程序为了提高其文件下载效率可以使用多个线程，这些线程各自独立地从服务器上下载大文件的一段数据。

一个进程可以包含多个线程。同一个线程中的所有线程共享该进程中的资源，如内存空间、文件句柄等。

线程所要完成的计算就被称为任务，特定的线程总是在执行着特定的任务。任务代表线程所要完成的工作，它是一个相对的概念。一个任务可以是从服务器上下载一个文件、解压缩一批文件、解压缩一个文件、监视某个文件的最后修改时间等。这些任务也正是相应线程存在的理由。

## 1.2 多线程编程简介

### 1.2.1 什么是多线程编程

函数式编程（Functional Programming）中的函数是基本抽象单位，面向对象编程中的类（Class）是基本抽象单位。类似地，多线程编程就是以线程为基本抽象单位的一种编程范式（Paradigm）。但是，多线程编程和面向对象编程是可以相容的，即我们可以在面向对象编程的基础上实现多线程编程，事实上Java平台中的一个线程就是一个对象。

### 1.2.2 为什么使用多线程

为什么使用多线程进行编程？弄清楚这个问题有助于我们在实践中做到有的放矢，不至于为了使用多线程而使用多线程。下面我们通过几个多线程编程的典型例子去直观感受一下多线程编程。

某款音乐播放手机软件在其启动的时候会专门启动一个线程用于在用户的手机存储中查找音乐文件，然后自动将这些文件名添加到名为“本地音乐”的播放列表。由于从手机存储器（如SD卡）查找特定的文件（音乐文件）是一个相对慢的操作，我们不希望该操作使得该软件启动时显得卡顿。因此，搜索手机本地音乐文件这个任务使用专门的一个线程执行比将其放在负责界面显示的线程（Event Loop线程）中执行给用户带来的体验要好。

Web服务器（如Apache Tomcat）常常在同一时间内会收到多个HTTP请求。为了避免一个请求的处理快慢影响到其他请求的处理，绝大多数服务器都会采用一些专门的线程（工作者线程）负责请求处理，这些线程各自处理分配给它的请求，从而使得一个请求处理的快慢不会对其他请求的处理产生影响（当然，这里的“不影响”是相对的）。这有点像快餐店在点餐顾客多的情况下多开几条点餐线，以减少每个顾客的等待时间。

某系统需要从指定的日志文件中统计出一些信息。而待统计的日志文件中的每个文件可包含上万条记录。若要统计几十个这样的日志文件就会涉及几十万甚至上百万条记录的读取和处理。而读取日志文件所涉及的I/O操作又是一个比较慢的操作。因此，这里我们可以使用一个专门的线程负责日志文件的读取。另外，再使用专门的一个线程去负责对读取到内存中的日志记录数据进行统计。这样，使用多线程编程可以使得该统计工具的统计效率尽可能高。

## 1.3 Java线程API简介

Java标准库类java.lang.Thread就是Java平台对线程的实现。Thread类或其子类的一个实例就是一个线程。

### 1.3.1 线程的创建、启动与运行

在Java平台中创建一个线程就是创建一个Thread类（或其子类）的实例。为了讨论的方便，本书后面提到的线程与Thread实例如无特别说明指的是同一概念。

每个线程都有其要执行的任务。线程的任务处理逻辑可以在Thread类的run实例方法中直接实现或者通过该方法进行调用，因此run方法相当于线程的任务处理逻辑的入口方法，它由Java虚拟机在运行相应线程时直接调用，而不是由应用代码进行调用。

运行一个线程实际上就是让Java虚拟机执行该线程的run方法，从而使相应线程的任务处理逻辑代码得以执行。为此，我们首先要启动线程。Thread类的start方法的作用是启动相应线程。启动一个线程的实质是请求Java虚拟机运行相应的线程，而这个线程具体何时能够运行是由线程调度器（Scheduler）决定的。因此，start方法调用结束并不意味着相应线程已经开始运行，这个线程可能稍后才被运行，甚至也可能永远不会被运行。

Thread类的两个常用的构造器是：Thread() 和 Thread(Runnable target)。相应地，Java语言中创建线程有两种方式。一种是使用上述第1个构造器：定义Thread类的子类，在该子类中覆盖（Override）run方法并在该方法中实现线程任务处理逻辑；另一种是使用上述第2个构造器：创建一个java.lang.Runnable接口的实例，并在该实例的run方法中实现任务处理逻辑，然后以该Runnable接口实例作为构造器的参数直接创建（new）一个Thread类的实例。

在Java平台中，每个线程均可以有自己的名字，这个名字便于我们（人）区分不同的线程。



不管是采用哪种方式创建线程，一旦线程的run方法执行（由Java虚拟机调用）结束，相应的线程的运行也就结束了。当然，run方法执行结束包括正常结束（run方法返回）以及代码中抛出异常而导致的中止。运行结束的线程所占用的资源（如内存空间）会如同其他Java对象一样被Java虚拟机垃圾回收。

线程属于“一次性用品”，我们不能通关重新调用一个已经运行结束的线程的start方法来使其重新运行。事实上，start方法也只能够被调用一次，多次调用同一个Thread实例的start方法会导致其抛出IllegalThreadStateException异常。

在Java平台中，一个线程就是一个对象，对象的创建离不开内存空间的分配。创建一个线程与创建其他类型的Java对象所不同的是，Java虚拟机会为每个线程分配调用栈（Call Stack）所需的内存空间。调用栈用于跟踪Java代码（方法）间的调用关系以及Java代码对本地代码（Native Code，通常是C代码）的调用。另外，Java平台中的每个线程可能还有一个内核线程（具体与Java虚拟机的实现有关）与之对应。因此相对来说，创建线程对象比创建其他类型的对象的成本要高一些。

Java平台中的任意一段代码（比如一个方法）总是由确定的线程负责执行的，这个线程就相应地被称为这段代码的执行线程。同一段代码可以被多个线程执行。	任意一段代码都可以通过调用`Thread.currentThread()`来获取这段代码的执行线程，这个线程就被称为当前线程。由于同一段代码可以被多个线程执行，因此当前线程是相对的，即概念层次上的当前线程（即Thread.currentThread()的返回值）在代码实际运行的时候可能对应着不同的线程（对象）。这就好比大家都自称“本人”（当前线程），“本人”这个词由张三来说就是指张三（线程X），而由李四来说则指李四（线程Y）。

我们知道线程的run方法总是由java虚拟机直接调用的。尽管如此，Java语言并不阻止我们直接调用run方法，这是因为：首先，线程在Java平台中也是一个对象，其次毕竟run方法也是一个public方法。但是，多数情况下我们不能这样做，因为这样做有违创建线程（对象）的初衷。

因此，如果我们没有启动线程而是在应用代码中直接调用线程的run方法的话，那么这个线程的run方法其实运行在当前线程（即run方法的调用方代码的执行线程）之中而不是运行在其自身线程之中，从而违背了创建线程的初衷。

### 1.3.2 Runnable接口

Runnable接口只定义了一个方法，该方法的声明如下：

~~~java
public void run()
~~~

Runnable接口可以被看作对任务进行的抽象，任务的处理逻辑就体现在run方法中。Thread类实际上是Runnable接口的一个实现类，其对Runnable接口的实现如下所示：

~~~java
public void run(){
    if (target != null) {
        target.run();
    }
}
~~~

可见，Thread类的run方法中实现的逻辑是如果target不为null，那么就调用target.run()，否则它什么也不做。其中，实例变量target的类型为Runnable。如果相应的线程实例是通过构造器Thread(Runnable target)创建的，那么target的值为构造器中参数值，否则target的值为null。因此，Thread类所实现的任务处理逻辑是要么什么也不做（target为null）。要么直接执行target所引用的Runnable实例所实现的任务处理逻辑。Thread类的run方法的这种处理逻辑决定了创建线程的两种方式：一种是在Thread子类的run方法中直接实现任务处理逻辑，另一种是在一个Runnable实例中实现任务处理逻辑，该逻辑由Thread类的run方法负责调用。

>扩展阅读 线程两种创建方式的区别
>
>从面向对象编程的角度来看：第1种创建方式（创建Thread类的子类）是一种基于继承（Inheritance）的技术，第2种创建方式（以Runnable接口实例为构造器参数直接通过new创建Thread实例）是一种基于组合（Composition）的技术。由于组合相对继承来说，其类和类之间的耦合性（Coupling）更低，因此它也更加灵活。一般我们认为组合是优先选用的技术。
>
>从对象共享的角度来看：第2种创建方式意味着多个线程实例可以共享同一个Runnable实例。在某些情况下这可能导致程序的运行结果出乎我们的意料。
>
>从对象创建成本的角度来看：Java中的线程实例是一个“特殊”的Runnable实例，因为在创建它的时候Java虚拟机会为其分配调用栈空间、内核线程等资源。因此，创建一个线程实例比起创建一个普通的Runnable实例来说，其成本要相对昂贵一点。所以，如果创建Runnable实例再将其作为方法参数传递给其他对象使用（JDK标准库中有不少API都使用了Runnable接口）而不必利用它来创建相应的线程（即第2种线程创建方式）即可满足我们的计算需要，那么就不要创建线程实例。

### 1.3.3 线程属性

线程的属性包括线程的编号（ID）、名称（Name）、线程类别（Daemon）和优先级（Priority），详情如表所示

| 属性               | 属性类型及用途                                               | 只读属性 | 重要注意事项                                                 |
| ------------------ | ------------------------------------------------------------ | -------- | ------------------------------------------------------------ |
| 编号（ID）         | 类型：long。用于标识不同的线程。不同的线程拥有不同的编号     | 是       | 某个编号的线程运行结束后，改编号可能被后续创建的线程使用。不同线程拥有的编号虽然不同，但是这种编号的唯一性只在Java虚拟机的一次运行有效。也就是说重启一个Java虚拟机（如重启Web服务器）后，某些线程的编号可能与上次Java虚拟机运行的某个线程的编号一样，因此该属性的值不适合用作某种唯一标识，特别是作为数据库中的唯一标识（如主键） |
| 名称（Name）       | 类型：String。面向人（而非机器）的一个属性，用于区分不同的线程。默认值与线程的编号有关，默认值的格式为：“Thread-线程编号”，如“Thread-0” | 否       | Java并不禁止我们将不同的线程的名称属性设置为相同的值。尽管如此，设置线程的名称属性有助于代码调试和问题定位 |
| 线程类别（Daemon） | 类型：boolean。值为true表示相应的线程为守护线程，否则表示相应的线程为用户线程。该属性的默认值与相应线程的父线程的该属性的值相同 | 否       | 该属性必须在相应线程启动之前设置，即对setDaemon方法的调用必须在对start方法的调用之前，否则setDaemon方法会抛出IllegalThreadStateException异常。负责一些关键任务处理的线程不适宜设置为守护线程 |
| 优先级（Priority） | 类型：int。该属性本质上是给线程调度器的提示，用于表示应用程序希望哪个线程能够优先得以运行。Java定义了1~10的10个优先级。默认值一般为5（表示普通优先级）。对于具体的一个线程而言，其优先级的默认级与其父线程（创建该线程的线程）的优先级值相等 | 否       | 一般使用默认优先级即可。不恰当地设置该属性值可能导致严重的问题（线程饥饿） |

通过名称属性，我们可以为每个线程设置一个便于区分不同线程的名称。虽然Java虚拟机并不要求每个线程的名称都不同，但是设置该属性有助于程序调试和问题定位。因此，我们建议为每个线程都设置一个简短而又能够体现其作用或其实现的功能的名称。

线程的属性除了编号外，其他属性都是可读写的属性，即Thread类提供了相应的get方法和set方法用于读取或者设置相应的属性。例如，getName方法可返回线程的名称属性值而setName方法则可以设置线程的名称属性值。

Java线程的优先级属性本质上只是一个给线程调度器的提示信息，以便于线程调度器决定优先调度哪些线程运行。它并不能保证线程按照其优先级高低的顺序运行。注意，Java线程的优先级使用不当或者滥用则可能导致某些线程永远无法得到运行，即产生了线程饥饿（Thread Starvation）。因此，线程的优先级并不是设置得越高越好；一般情况下使用普通优先级即可，即不必设置线程的优先级属性。

按照线程是否会阻止Java虚拟机正常停止，我们可以将Java中的线程分为守护线程（Daemon Thread）和用户线程（User Thread，也称非守护线程）。线程的daemon属性用于表示相应线程是否为守护线程。用户线程会阻止Java虚拟机的正常停止，即一个Java虚拟机只有在其所有用户线程都运行结束（即Thread.run()调用未结束）的情况下才能正常停止。因此，守护线程通常用于执行一些重要性不是很高的任务，例如用于监视其他线程的运行情况。

如果Java虚拟机是被强制停止的，比如在Linux系统下使用kill命令强制终止一个Java虚拟机进程，那么即使是用户线程也无法阻止Java虚拟机的停止。

### 1.3.4 Thread类的常用方法

join方法的作用相当于执行该方法的线程和线程调度器说：“我得先暂停一下，等到另外一个线程运行结束后我才能继续（干活）。”我们会在第5章中进一步讲解该方法。

yield静态方法的作用相当于执行该方法的线程对线程调度器说：“我现在不急，如果别人需要处理器资源的话先给他用吧。当然，如果没有其他人要用，我也不介意继续占用。”

### 1.3.5 Thread类的一些废弃方法

| 方法    | 功能                   |
| ------- | ---------------------- |
| stop    | 停止线程的运行         |
| suspend | 暂停线程的运行         |
| resume  | 使被暂停的线程继续运行 |

## 1.4 无处不在的线程

## 1.5 线程的层次关系

Java平台中的线程不是孤立的，线程与线程之间总是存在一些联系。假设线程A所执行的代码创建了线程B，那么，习惯上我们称线程B为线程A的子线程，相应地线程A就被称为线程B的父线程。子线程所执行的代码还可以创建其他线程，因此一个子线程也可以是其他线程的父线程。所以，父线程、子线程是一个相对的称呼。

线程间的这种父子关系就被称为线程的层次关系。由于Java虚拟机创建的main线程（也被称为主线程）负责执行Java程序的入口方法main方法，因此main方法中直接创建的线程都是main线程的子线程。这些子线程所执行的代码又可能创建其他线程。因此，这就形成了Java程序的线程层次关系。

在Java平台中，一个线程是否是一个守护线程默认取决于其父线程：默认情况下父线程是守护线程，则子线程也是守护线程；父线程是用户线程，则子线程也是用户线程。另外，父线程在创建子线程后启动子线程之前可以调用该线程的setDaemon方法，将相应的线程设置为守护线程（或者用户线程）。

一个线程的优先级默认值为该线程的父线程的优先级，即如果我们没有设置或者更改一个线程的优先级，那么这个线程的优先级的值与父线程的优先级的值相等。

不过，Java平台中并没有API用于获取一个线程的父线程，或者获取一个线程的所有子线程。并且，父线程和子线程之间的生命周期也没有必然的联系。比如父线程运行结束后，子线程可以继续运行，子线程运行结束也不妨碍其父线程继续运行。

习惯上，我们也称某些子线程为工作者线程（Worker Thread）或者后台线程（Background Thread）。工作者线程通常是其父线程创建来用于专门负责某项特定任务的执行的。

## 1.6 线程的生命周期状态

在Java语言中，一个线程从其创建、启动到运行结束的整个生命周期可能经历若干状态。

~~~mermaid
graph TB
	NEW --> RUNNABLE
	RUNNABLE --发起阻塞式I/O操作--> BLOCKED
	BLOCKED --阻塞式I/O操作结束--> RUNNABLE
	RUNNABLE --申请锁--> BLOCKED
	BLOCKED --获得锁--> RUNNABLE
	RUNNABLE --Object.wait调用--> WAITING
	WAITING --Object.notify/notifyAll调用--> RUNNABLE
	RUNNABLE --Thread.join调用--> WAITING
	WAITING --被等待线程终止--> RUNNABLE
	RUNNABLE --LockSupport.park调用--> WAITING
	WAITING --LockSupport.unpark Object调用--> RUNNABLE
	RUNNABLE --Thread.sleep long 调用--> TIMED_WAITING
	RUNNABLE --Object.wait long 调用--> TIMED_WAITING
	RUNNABLE --LockSupport.parkNanos/parkUntil调用--> TIMED_WAITING
	TIMED_WAITING --等待超时--> RUNNABLE
	RUNNABLE---->TERMINATED
	
	subgraph RUNNABLE_
	READY --被线程调度器选中--> RUNNING
	RUNNING --Thread.yield调用--> READY
	end
~~~

Java线程的状态可以使用监控工具查看，也可以通过Thread.getState()调用来获取。Thread.getState()的返回值类型Thread.State是一个枚举类型（Enum）。Thread.State所定义的线程状态包括以下几种。

- **NEW**：一个已创建而未启动的线程处于该状态。由于一个线程实例只能能够启动一次，因此一个线程只可能有一次处于该状态。
- **RUNNABLE**：该状态可以被看成一个复合状态。它包括两个子状态：READY和RUNNING。前者表示处于该状态的线程可以被线程调度器（Scheduler）进行调度而使之处于RUNNING状态。后者表示处于该状态的线程正在运行，即相应线程对象的run方法所对应的指令正在由处理器执行。执行Thread.yield()的线程，其状态可能会由RUNNING转换为READY。处于READY子状态的线程也被称为活跃线程。
- **BLOCKED**：一个线程发起一个阻塞式I/O（Blocking I/O）操作后，或者申请一个由其他线程持有的独占资源（比如锁）时，相应的线程会处于该状态。处于BLOCKED状态的线程并不会占用处理器资源。当阻塞式I/O操作完成时，或者线程获得了其申请的资源，该线程的状态又可以转换为RUNNABLE。
- **WAITING**：一个线程执行了某些特定方法之后就会处于这种等待其他线程执行另外一些特定操作的状态。能够使其执行线程变更为WAITING状态的方法包括：Object.wait()、Thread.join() 和 LockSupport.park(Object)。能够使相应线程从WAITING变更为RUNNABLE的相应方法包括：Object.notify()/notifyAll()和LockSupport.unpark(Object)。
- **TIMED_WAITING**：该状态和WAITING类似，差别在于处于该状态的线程并非无限制地等待其他线程执行特定操作，而是处于带有时间限制的等待状态。当其他线程没有在指定时间内执行该线程所期望的特定操作时，该线程的状态自动转换为RUNNABLE。
- **TERMINATED**：已经执行结束的线程处于该状态。由于一个线程实例只能够被启动一次，因此一个线程也只可能有一次处于该状态。Thread.run()正常返回或者由于抛出异常而提前终止都会导致相应线程处于该状态。

一个线程在其整个生命周期中，只可能有一次处于NEW状态和TERMINATED状态。

## 1.7 线程的监视

一个真实的Java系统运行时往往有上百个线程在运行，如果没有相应的工具能够对这些线程进行监视，那么这些线程对于我们来说就成了黑盒。而我们在开发过程中进行代码调试、定位问题甚至是定位线上环境（生产环境）中的问题时往往都需要将线程变为白盒，即我们要能够知道系统中特定时刻存在哪些线程、这些线程处于什么状态以及这些线程具体是在做什么事情这些信息。

对线程进行监视的主要途径是获取并查看程序的线程转储（Thread Dump）。一个程序的线程转储包含了获取这个线程转储的那一刻该线程的线程信息。这些信息包括程序中有哪些线程以及这些线程的具体信息。Java程序的线程转储包含的线程具体信息包括线程的属性（ID、名称、优先级等）、生命周期状态、线程的调用栈（Call Stack）以及锁（第3章会介绍这个概念）的相关信息等。通过查看调用栈我们就能够了解线程的执行情况（具体在干些什么）。

获取线程转储的方法如表所示

| 平台          | 获取途径                                               | 备注                                                         |
| ------------- | ------------------------------------------------------ | ------------------------------------------------------------ |
| 平台无关      | 执行命令：jstack -l PID                                | ①PID为Java程序的进程ID。Java程序的进程ID可以使用JDK的jps命令（可执行文件是JDK主目录/bin/jps）或者Linux的ps命令来获取。<br/>②jstack是Oracle JDK自带的一个工具，其可执行文件是：JDK主目录/bin/jstack；Windows版JDK自JDK 1.6开始提供该工具 |
|               | 单机图形化工具jvisualvm中的Thread Dump按钮             | ③jvisualvm是Oracle JDK自带的一个工具，其可执行文件是：JDK主目录/bin/jvisualvm |
|               | 使用图形化工具Java Mission Control（JMC）              | ④JMC是Oracle JDK 1.8开始自带的一个工具，其可执行文件是：JDK主目录/bin/jmc。JMC支持Eclipse插件 |
| 特定于Linux   | 执行命令：kill -3 PID                                  |                                                              |
|               | 在启动Java程序的控制台中按下“CTRL+\”组合键             |                                                              |
| 特定于Windows | 在启动Java程序的命令行提示窗口中按下“CTRL+Break”组合键 |                                                              |

## 1.8 多线程编程简单运用实例

## 1.9 多线程编程的优势和风险

多线程编程具有以下优势：

- 提高系统的吞吐率（Throughput）。多线程编程使得一个进程中可以有多个并发（Concurrent，即同时进行的）的操作。例如，当一个线程因为I/O操作而处于等待时，其他线程仍然可以执行其操作。
- 提高响应性（Responsiveness）。在使用多线程编程的情况下，对于GUI软件（如桌面应用程序）而言，一个慢的动作（比如从服务器上下载一个大的文件）并不会导致软件的界面出现被“冻住”的现象而无法响应用户的其他操作；对于Web应用程序而言，一个请求的处理慢了并不会影响其他请求的处理。
- 充分利用多核（Multicore）处理器资源。如今多核处理器的设备越来越普及，就算是手机这样的消费类设备也普遍使用多核处理器。实施恰当的多线程编程有助于我们充分利用设备的多核处理器资源，从而避免了资源浪费。
- 最小化对系统资源的使用。一个进程中的多个线程可以共享其所在进程所申请的资源（如内存空间），因此使用多个线程相比于使用多个进程进行编程来说，节约了对系统资源的使用。
- 简化程序的结构。线程可以简化复杂应用程序的结构。

多线程编程也有自身的问题与风险，包括以下几个方面。

- 线程安全（Thread Safe）问题。多个线程共享数据的时候，如果没有采取相应的并发访问控制措施，那么就可能产生数据一致性问题，如读取脏数据（过期的数据）、丢失更新（某些线程所做的更新被其他线程所做的更新覆盖）等。
- 线程活性（Thread Liveness）问题。一个线程从其创建到运行结束的整个生命周期会经历若干状态。从单个线程的角度来看，RUNNABLE状态时我们所期望的状态。但实际上，代码编写不当可能导致某些线程一直处于等待其他线程释放锁的状态（BLOCKED状态），即产生了死锁（Deadlock）。例如，线程T1拥有锁L1，并试图去获取锁L2，而此时线程T2拥有锁L2而试图去获得锁L1，这就导致线程T1和T2一直处于等待对方释放锁而一直又得不到锁的状态。当然，一直忙碌的线程也可能会出现问题，它可能面临活锁（Livelock）问题，即一个线程一直在尝试某个操作但就是无法进展，这就好比小猫一直追着自己的尾巴咬却一直咬不到的情形。另外，线程是一种稀缺的计算资源，一个系统所拥有的处理器数量相比于该系统中存在的线程数量而言总是少之又少的。某些情况下可能出现线程饥饿（Starvation）的问题，即某些线程永远无法获取处理器执行的机会而永远处于RUNNABLE状态的READY子状态。
- 上下文切换（Context Switch）。处理器从执行一个线程转向执行另外一个线程的时候操作系统所需要做的一个动作被称为上下文切换。由于处理器资源的稀缺性，因此上下文切换可以被看作多线程编程的必然副产物，它增加了系统的消耗，不利于系统的吞吐率。
- 可靠性。多线程编程一方面可以有利于可靠性，例如某个线程意外提前终止了，但这并不影响其他线程继续其处理。另一方面，线程是进程的一个组件，它总是存在于特定的进程中，如果这个进程由于某种原因意外提前终止，比如某个Java进程由于内存泄漏导致Java虚拟机崩溃而意外终止，那么该进程中所有的线程也就随之而无法继续运行。因此，从提高软件可靠性的角度来看，某些情况下可能要考虑多进程多线程的编程方式，而非简单的单进程多线程方式。

# 第2章 多线程编程的目标与挑战

## 2.1 串行、并发与并行

假设我们有3件事情（事情A、事情B和事情C）要完成，完成每件事情所需的时间包括实际投入时间（如做准备活动所需的时间）和等待的时间，完成这些事情所需的时间为：事情A耗时15分钟（实际投入5分钟，等待10分钟）、事情B耗时10分钟（实际投入2分钟，等待8分钟）、事情C耗时10分钟（实际投入10分钟，无等待耗时）。那么，我们有3种方式来完成这几件事情。

串行（Sequential），先开始做事情A，待其完成之后再开始做事情B，依此类推，直到事情C完成。这实际上顺序逐一完成几件事情，只需要投入一个人。在这种方式下3件事情总共耗时35（15+10+10）分钟。

并发（Concurrent）。这种方式也可以只投入一个人。这个人先开始做事情A，事情A的准备活动做好后（此时消耗了5分钟)，在等待A完成的这段时间内他开始做事情B。为事情B的准备活动花了2分钟之后，在等待事情B完成的这段时间内他开始做事情C，直到10分钟之后事情C完成。这整个过程实际上是以交替的方式利用等待某件事情完成的时间来做其他事情。在这种方式下3件事情总共耗时17（5+2+10）分钟，这比第1种方式节约了一半多的时间。

并行（Parallel）。这种方式需要投入3个人，每个人负责完成其中一件事情。这3个人在同一时刻开始齐头并进地完成这些事情。在这种方式下3件事情总共耗时15分钟（取决于耗时最长的那件事情所需的时间），比并发的方式节约了2分钟的时间。

可见，并发是串行的反面，并发往往可以提高我们对事情的处理效率，即一段时间内可以处理或者完成更多的事情。而并行是一种更为严格、理想的并发，即并行可以被看作并发的一个特例。并发往往是带有部分串行的并发，而并发的极致就是并行（Parallel）。

从软件的角度来说，并发就是在一段时间内以交替的方式去完成多个任务，而并行就是以齐头并进的方式去完成多个任务。并发与上述生活种的并发并无本质的区别，不过二者还存在一些差异。首先，现实世界种的一个人可以以并发的方式去完成几件事情，而软件要以并发的方式去完成几个任务往往需要借助多个线程（而不是一个线程）。其次，软件世界中的并发也未必就比串行的处理效率更高或者效率提高得那么明显，这点在本书的后面内容中会体现出来。

从硬件的角度来说，在一个处理器一次只能够运行一个线程的情况下，由于处理器可以使用时间片（Time-slice）分配的技术来实现在同一段时间内运行多个线程，因此一个处理器就可以实现并发。而并行则需要靠多个处理器在同一时刻各自运行一个线程来实现。

多线程编程的实质就是将任务的处理方式由串行改为并发，即实现并发化，以发挥并发的优势。而现实是以并发的方式对任务进行处理的过程也存在一些挑战，这点正是本章后续几节的主题。

如果一个任务的处理方式可以由串行改为并发（或者并行），那么我们就称这个任务是可并发化（或者可并行化）的。但是，有的任务的处理方式则可能必须是串行的。例如，在Java平台中读取一个文件就是串行的。

## 2.2 竞态

多线程编程中经常遇到的一个问题就是对于同样的输入，程序的输出有时候是正确的而有时候却是错误的。这种一个计算结果的正确性与时间有关的现象就被称为竞态（Race Condition）。

### 2.2.1 二维表分析法：解释竞态的结果

> **术语定义**
>
> 状态变量（State Variable）：即类的实例变量、静态变量。
>
> 共享变量（Shared Variable）：即可以被多个线程共同访问的变量。共享变量中的“共享”强调的是“可以被共享”的可能性，因此称呼一个变量为共享变量并不表示该变量一定会被多个线程访问。状态变量由于可以被多个线程共享，因此也被称为共享变量。

可见，nextSequence()是导致上述竞态的直接因素。进一步来说，导致竞态的常见因素是多个线程在没有采取任何控制措施的情况下并发地更新、读取同一个共享变量。nextSequence()所访问的实例变量sequence就是这样一个例子：多个线程（业务线程）通过调用nextSequence()并发地访问sequence，显然这些线程没有采取任何控制措施。

nextSequence() 中的语句“sequence++”看起来像是一个操作，它实际上相当于如下伪代码所代表的3个指令：

~~~java
load(sequence, r1); //指令①：将变量sequence的值从内存读到寄存器r1
increment(r1); //指令②：将寄存器r1的值增加1
store(sequence, r1); //指令③：将寄存器r1的内容写入变量sequence所对应的内存空间
~~~

竞态（Race Condition）是指计算的正确性依赖于相对时间顺序（Relative Timing）或者线程的交错（Interleaving）。根据这个定义可知，竞态不一定就导致计算结果的不正确，它只是不排除计算结果时而正确时而错误的可能。

竞态往往伴随着读取脏数据（Dirty Read）问题，即线程读取到一个过时的数据，丢失更新（Lost Update）问题，即一个线程对数据所做的更新没有体现在后续其他线程对该数据的读取上。而上述的二维表分析法是分析竞态问题的一种简单而有效的方法。

> **注意**
>
> 竞态不一定就导致计算结果的不正确，它只是不排除计算结果时而正确时而错误的可能。

### 2.2.2 竞态的模式与竞态产生的条件

从上述竞态典型实例中我们可以提炼出竞态的两种模式：read-modify-write(读-改-写)和check-then-act（检测而后行动）。

read-modify-write(读-改-写)操作，该操作可以被细分为这样几个步骤：读取一个共享变量的值（read），然后根据该值做一些计算（modify），接着更新该共享变量的值（write）。例如，在清单2-1中，nextSequence()中的“sequence++”就是read-modify-write模式的一个实例。“sequence++”实际上相当于如下伪代码表示的几个指令的组合。

~~~java
load(sequence, r1); //指令①：将变量sequence的值从内存读到寄存器r1（读取共享变量值）
increment(r1); //指令②：将寄存器r1的值增加1（根据共享变量值做一些计算）
store(sequence, r1); //指令③：将寄存器r1的内容写入变量sequence所对应的内存空间（更新共享变量）
~~~

一个线程在执行完指令①之后到开始（或者正在）执行指令②的这段时间内其他线程可能已经更新了共享变量（sequence）的值，这就使得该线程在执行指令②时使用的是共享变量的旧值（读脏数据）。接着，该线程把根据这个旧值计算出来的结果更新到共享变量，而这又使得其他线程对该共享变量所做的更新被“覆盖”，即造成了更新丢失。

check-then-act（检测而后行动）操作，该操作可以被细分为这样几个步骤：读取某个共享变量的值，根据该变量的值决定下一步的动作是什么。例如，在清单2-1中，nextSequence()中的if-else语句就是该模式的一个实例。

~~~java
if (sequence >= 999) { // 子操作①check：检测共享变量的值
    sequence = 0;
} else {
    sequence++;
}
~~~

一个线程在执行完子操作①到开始（或者正在）执行子操作②的这段时间内，其他线程可能已经更新了共享变量的值而使得if语句中的条件变为不成立，那么此时该线程仍然会执行子操作②，尽管这个子操作所需的前提（if语句中的条件）实际上并未成立！读者也可以根据二维表分析法自行分析多个线程并发执行上述代码的时候可能导致丢失更新和脏数据的问题。

从上述分析中我们可以总结出竞态产生的一般条件。设O1和O2是并发访问共享变量V的两个操作，这两个操作并非都是读操作。如果一个线程在执行O1期间（开始执行而未执行结束）另一个线程正在执行O2，那么无论O2是在读取还是更新V都会导致竞态。从这个角度来看，竞态可以被看作访问（读取、更新）同一组共享变量的多个线程所执行的操作相互交错（Interleave），比如一个线程读取共享变量并以该共享变量为基础进行计算的期间另外一个线程更新了该共享变量的值而导致的干扰（读取脏数据）或者冲突（丢失更新）的结果。

对于局部变量（包括形式参数和方法体内定义的变量），由于不同的线程各自访问的是各自的那一份局部变量，因此局部变量的使用不会导致竞态！

synchronized关键字会使其修饰的方法在任一时刻只能够被一个线程执行，这使得该方法涉及的共享变量在任一时刻只能够有一个线程访问（读、写），从而避免了这个方法的交错执行而导致的干扰，这样就消除了竞态。第3章会详细解释synchronized。

## 2.3 线程安全性

一般而言，如果一个类在单线程环境下能够运作正常，并且在多线程环境下，在其使用方不必为其做任何改变的情况下也能运作正常，那么我们就称其是线程安全（Thread-safe）的，相应的我们称这个类具有线程安全性（Thread Safety）。反之，如果一个类在单线程环境下运作正常而在多线程环境下则无法正常运作，那么这个类就是非线程安全的。因此，一个类如果能够导致竞态，那么它就是非线程安全的；而一个类如果是线程安全的，那么它就不会导致竞态。

使用一个类的时候我们必须先弄清楚这个类是否是线程安全的。因为这关系到我们如何正确使用这些类。Java标准库中的一些类如ArrayList、HashMap和SimpleDateFormat，都是非线程安全的，在多线程环境下直接使用它们可能导致一些非预期的结果，甚至是一些灾难性的结果。比如，多线程环境下多个线程共享同一个HashMap实例（而不采取任何控制措施）可能导致死循环（表现为主机上的某个处理器使用率一直为100%）和内存泄漏（最后可能导致Java虚拟机崩溃）。一般来说，Java标准库中的类在其API文档（JavaDoc）中会说明其是否是线程安全的（没有说明其是否是线程安全的，则可能是也可能不是线程安全的）。

从线程安全的定义上我们不难看出，如果一个线程安全的类在多线程环境下能够正常运作，那么它在单线程环境下也能正常运作。既然如此，那为什么不干脆把所有的类都做成线程安全的呢？是否将一个类做成线程安全的，从某种程度上来说是一个设计上的权衡的结果或决定：一方面，一个类是否需要是线程安全的与这个类预期被使用的方式有关，比如，我们希望一个类总是只能被一个线程独自使用，那么就没有必要将这个类做成线程安全的。其次，把一个类做成线程安全的往往是有额外代价的。

一个类如果不是线程安全的，我们就说它在多线程环境下直接使用存在线程安全问题。线程安全问题概括来说表现为3个方面：原子性、可见性和有序性。

## 2.4 原子性

原子（Atomic）的字面意思是不可分割的（Indivisible）。对于涉及共享变量访问的操作，若该操作从其执行线程以外的任意线程来看是不可分割的，那么该操作就是原子操作，相应地我们称该操作具有原子性（Atomicity）。

所谓“不可分割”，其中一个含义是指访问（读、写）某个共享变量的操作从其执行线程以外的任何线程来看，该操作要么已经执行结束要么尚未发生，即其他线程不会“看到”该操作执行了部分的中间效果。

设O1和O2是访问共享变量V的两个原子操作，这两个操作并非都是读操作。那么一个线程执行O1期间（开始执行而未执行完毕），其他线程无法执行O2。也就是说，访问同一组共享变量的原子操作是不能能够被交错的，这就排除了一个线程执行一个操作期间另外一个线程读取或者更新该操作所访问的共享变量而导致的干扰（读脏数据）和冲突（丢失更新）的可能。这就是“不可分割”的第二个含义。由此可见，使一个操作具备原子性也就消除了这个操作导致竞态的可能性。

理解原子操作这个概念还需要注意以下两点。

- 原子操作是针对访问共享变量的操作而言的。也就是说，仅涉及局部变量访问的操作无所谓是否是原子的，或者干脆把这一类操作都看成原子操作。
- 原子操作是从该操作的执行线程以外的线程来描述的，也就是说它只有在多线程环境下有意义。换言之，单线程环境下一个操作无所谓是否具有原子性，或者我们干脆把这一类操作都看成原子操作。

> **提示**
>
> 原子操作多线程环境下的一个概念，它是针对访问共享变量的操作而言的。原子操作的“不可分割”包括以下两层含义。
>
> - 访问（读、写）某个共享变量的操作从其执行线程以外的任何线程来看，该操作要么已经执行结束要么尚未发生，即其他线程不会“看到”该操作执行了部分的中间效果。
> - 访问同一组共享变量的原子操作是不能够被交错的。

总的来说，Java中有两种方式来实现原子性。一种是使用锁（Lock）。锁具有排他性，即它能够保障一个共享变量在任意一个时刻只能够被一个线程访问。这就排除了多个线程在同一时刻访问同一共享变量而导致干扰与冲突的可能，即消除了竞态。另一种是利用处理器提供的专门CAS（Compare-and-Swap）指令，CAS指令实现原子性的方式与锁实现原子性的方式实质上是相同的，差别在于锁通常是在软件这一层次实现的，而CAS是直接在硬件（处理器和内存）这一层次实现的，它可以被看作“硬件锁”。

在Java语言中，long型和double型以外的任何类型的变量的写操作都是原子操作，即对基础类型（long/double除外，仅包括byte、boolean、short、char、float和int）的变量和引用型变量的写操作都是原子的。这点由Java语言规范（JLS，Java Language Specification）规定，由Java虚拟机具体实现。

对long/double型变量的写操作由于Java语言规范并不保障其具有原子性，因此在多个线程并发访问同一long/double型变量的情况下，一个线程可能会读取到其他线程更新该变量的“中间结果”。

尽管如此，Java语言规范特别地规定对于volatile关键字修饰的long/double型变量的写操作具有原子性。因此，我们只需要用volatile关键字修饰清单2-6中的共享变量value，就可以保障对该变量的写操作的原子性。

volatile关键字仅能够保障变量写操作的原子性，它并不能保障其他操作（比如read-modify-write操作和check-then-act操作）的原子性。第3章会进一步介绍该关键字。

Java语言中针对任何变量的读操作都是原子操作。

从原子操作的“不可分割”特性可知，使一个操作具有原子性就可以消除该操作导致竞态的可能性。因此，我们可以将read-modify-write操作和check-then-act操作转换为原子操作来消除竞态。

竞态模式中的read-modify-write操作本身不是原子操作，但是我们可以使用Java语言提供的机制使其具有原子性。例如，synchronized关键字

竞态模式中的check-then-act操作本身不是原子操作。同样地，我们也可以使用与将read-modify-write操作转换为原子操作同样的方法将这种操作转换为原子操作，即使其具有原子性。

## 2.5 可见性

# 第3章 Java线程同步机制

## 3.3 内部锁：synchronized关键字

Java平台中的任何一个对象都有唯一一个与之关联的锁。这种锁被称为监视器（Monitor）或者内部锁（Intrinsic Lock）。内部锁是一种排他锁，它能够保障原子性、可见性和有序性。

内部锁是通过synchronized关键字实现的。synchronized关键字可以用来修饰方法以及代码块（花括号“{}”包裹的代码）。

synchronized关键字修饰的方法就被称为**同步方法**（Synchronized Method）。synchronized修饰的静态方法就称为**同步静态方法**，synchronized修饰的实例方法就被称为**同步实例方法**。同步方法的整个方法体就是一个临界区。

synchronized关键字修饰的代码块被称为**同步块**（Synchronized Block），其语法如下所示：

~~~java
synchronized(锁句柄) {
    // 在此代码块中访问共享数据
}
~~~

synchronized关键字所引导的代码块就是临界区。**锁句柄**是一个对象的引用（或者能够返回对象的表达式）。例如，锁句柄可以填写为this关键字（表示当前对象）。习惯上我们也直接称锁句柄为锁。锁句柄对应的监视器就被称为相应同步块的**引导锁**。相应地，我们称呼相应的同步块为该**锁引导的同步块**。

同步实例方法相当于以“this”为引导锁的同步块。

作为锁句柄的变量通常采用final修饰。这是因为锁句柄变量的值一旦改变，会导致执行同一个同步块的多个线程实际上使用不同的锁，从而导致竞态。有鉴于此，通常我们会使用private修饰作为锁句柄的变量。

> **注意**
>
> 作为锁句柄的变量通常采用private final修饰，如：private final Object lock = new Object();

同步静态方法相当于以当前类对象（Java中的类本身也是一个对象）为引导锁的同步块。例如同步静态方法：

~~~java
public class SynchronizedMethodExample{
    public static synchronized void staticMethod() {
        // 在此访问共享数据
    }
    // ...
}
~~~

相当于

~~~java
public class SynchronizedMethodExample{
    public void staticMethod() {
        synchronized (SynchronizedMethodExample.class){
	        // 在此访问共享数据
    	}
    }
    // ...
}
~~~

线程在执行临界区代码的时候必须持有该临界区的引导锁。一个线程执行到同步块（同步方法也看作同步块）时必须先申请该同步块的引导锁，只有申请成功（获得）该锁的线程才能够执行相应的临界区。一个线程执行完临界区代码后引导该临界区的锁就会被自动释放。在这个过程中，线程对内部锁的申请与释放的动作由Java虚拟机负责代为实施，这也正是synchronized实现的锁被称为内部锁的原因。

内部锁的使用并不会导致锁泄漏。这是因为Java编译器（javac）在将同步块代码编译为字节码的时候，对临界区中可能抛出的而程序代码中又未捕获的异常进行了特殊（代为）处理，这使得临界区的代码即使抛出异常也不会妨碍内部锁的释放。

### 内部锁的调度

Java虚拟机会为每个内部锁分配一个入口集（Entry Set），用于记录等待获得相应内部锁的线程。多个线程申请同一个锁的时候，只有一个申请者能够成为该锁的持有线程（即申请锁的操作成功），而其他申请者的申请操作会失败。这些申请失败的线程并不会抛出异常，而是会被暂停（生命周期状态变为BLOCKED）并被存入相应锁的入口集中等待再次申请锁的机会。入口集中的线程就被称为相应内部锁的等待线程。当这些线程申请的锁被其持有线程释放的时候，该锁的入口集中的一个任意线程会被Java虚拟机唤醒，从而得到再次申请锁的机会。由于Java虚拟机对内部锁的调度仅支持非公平调度，被唤醒的等待线程占用处理器运行时可能还有其他新的活跃线程（处于RUNNABLE状态，且未进入过入口集）与该线程抢占这个被释放锁，因此被唤醒的线程不一定就能成为该锁的持有线程。另外，Java虚拟机如何从一个锁的入口集中选择一个等待线程，作为下一个可以参与再次申请相应锁的线程，这个细节与Java虚拟机的具体实现有关：这个被选中的线程有可能是入口集中等待时间最长的线程，也可能是等待时间最短的线程，或者完全是随机的一个线程。因此，我们不能依赖这个具体的选择算法。

# 第4章 牛刀小试：玩转线程

## 4.5 合理设置线程数

在本章的第一个案例中，工作者线程的数量是通过程序的参数指定的。线程数不宜过小，线程数过小可能导致无法充分利用处理器资源；线程数也不宜过大，线程数过大会增加上下文切换以及其他开销。那么，我们如何设置一个合理的线程数呢？在回答这个问题之前，我们先看一下线程数与多线程程序相对于单线程程序的提速（Speedup）之间的关系。

### 4.5.1 Amdahl's定律

Amdahl's定律（Amdahl's Law）描述了线程数与多线程程序相对于单线程程序的提速之间的关系。在一个处理器上一个时刻只能够运行一个线程的情况下，处理器的数量就等同于并行线程的数量。设处理器的数量为N，程序中必须串行（即无法并发化）的部分耗时占程序全部耗时的比率为P，那么将这样一个程序改为多线程程序，我们能够获得的理论上的最大提速$S_{max}$与N、P之间的关系就是Amdahl's 定律内容，如下4-2所示。
$$
S_{max} = \frac{1}{P+\frac{1-P}{N}}
$$
了解该公式的推导过程有助于我们更好地理解多线程编程的本质。我们知道，一个程序的算法中有些部分是可以并行化的，而有些部分则只能够是串行的。设P为这个程序的串行部分的耗时比率，T(1)为该程序的单线程版运行总耗时，T(N)为该程序的多线程版运行总耗时，那么将该程序由单线程改为多线程所得到的提速$S_{max}$可以表示为：
$$
S_{max} = \frac{T(1)}{T(N)}
$$
为方便起见，设T(1)为1，则该程序中的串行部分耗时为P，可并行部分耗时为1-P。将这个程序改为多线程程序的时候，该程序的可并行部分耗时会被N个并行线程平均分摊，因此该程序的多线程版的并行部分总耗时为(1-P)/N（串行部分仍然是P！）。由此，我们可以得出T(N) = P + (1-P)/N。将 T(N) 及 T(1) = 1 代入式（4-2）即可得到Amdahl‘s 定律的公式表示。

从上述推导过程可以看出，多线程程序的提速主要来自多个线程对程序中可并行化部分的耗时均摊。

由Amdahl's定律的公式可知：
$$
\lim_{N\rightarrow\infty} S_{max} = \lim_{N\rightarrow\infty} \frac{1}{P+\frac{1-P}{N}} = \frac{1}{P}
$$
即当N趋向于无穷大的时候，$S_{max}$趋向于1/P。由此可见，最终决定多线程程序提速的因素是整个计算中串行部分的耗时比率P，而不是线程数N！P的值越大，即程序中不可并行化的部分所占比率越大，那么提速越小。因此，为使多线程程序能够获得较大的提速，我们应该从算法入手，减少程序中必须串行的部分，而不是仅寄希望于增加线程数（或者处理器的数目）！

### 4.5.2 线程数设置的原则

设$N_{cpu}$表示一个系统的处理器数目，$N_{cpu}$的具体值可以通过如下Java代码获取：

~~~java
int nCPU = Runtime.getRuntime().availableProcessors();
~~~

线程数的合理值可以根据如下规则设置。

- 对于CPU密集型线程，考虑到这类线程执行任务时消耗的主要是处理器资源，我们可以将这类线程的线程数设置为$N_{cpu}$个。因为CPU密集型线程也可能由于某些原因（比如缺页中断/Page Fault）而被切出，此时为了避免处理器资源浪费，我们也可以为这类线程设置一个额外的线程，即将线程数设置为$N_{cpu}+1$。
- 对于I/O密集型线程，考虑到I/O操作可能导致上下文切换，为这样的线程设置过多的线程数会导致过多的额外系统开销。因此如果一个这样的工作者线程就足以满足我们的要求，那么就不要设置更多的线程数。例如，在本章的第2个实战案例中我们仅使用一个工作者线程去负责所有日志文件的读取。如果一个工作者线程仍然不够用，那么我们可以考虑将这类线程的数量设置为$2 \times N_{cpu}$。这是因为I/O密集型线程在等待I/O操作返回结果时是不占用处理器资源的，因此我们可以为每个处理器安排一个额外的线程以提高处理器资源的利用率。

> **提示**
>
> 对于CPU密集型线程，线程数通常可以设置为$N_{cpu}+1$；对于I/O密集型线程，优先考虑将线程数设置为1，仅在一个线程不够用的情况下将线程数向$2\times N_{cpu}$靠近。

商用软件往往会规定某个软件在其运行过程中对处理器的使用率不能超过某个阈值（如75%）。因此，如果要进一步“精确”地设置线程数，我们可能需要考虑目标处理器使用率，即我们期望软件运行过程中会保持多少平均CPU使用率。另外，如果任务本身是混合型而不太好将其拆分成CPU密集型和I/O密集型地子任务的话，也可以考虑不拆分。此时，我们可以参考式（4-5）来设置线程数：
$$
N_{threads} = N_{cpu} \times U_{cpu} \times (1+\frac{WT}{ST})
$$
其中，$N_{threads}$为线程数的合理大小，$N_{cpu}$为CPU数目，$U_{cpu}$为目标CPU使用率（$0 \lt U_{cpu} \leq 1$），WT（Wait Time）为程序花费在等待（例如等待I/O操作结果）上的时长，ST（Service Time）为程序实际占用处理器执行计算的时长。在实践中，我们可以使用jvisualvm提供的监控数据计算出WT/ST的值。

# 第5章 线程间协作

## 5.1 等待与通知：wait/notify

一个线程因其执行目标动作所需的保护条件未满足而被暂停的过程就被称为**等待**（Wait）。一个线程更新系统的状态，使得其他线程所需的保护条件得以满足的时候唤醒那些被暂停的线程的过程就被称为**通知**（Notify）。

### 5.1.1 wait/notify的作用与用法

在Java平台中，Object.wait()/Object.wait(long) 以及 Object.notify()/Object.notifyAll() 可用于实现等待和通知：Object.wait()的作用是使其执行线程被暂停（其生命周期状态变更为WAITING），该方法可用来实现等待；Object.notify()的作用使唤醒一个被暂停的线程，调用该方法可实现通知。相应地，Object.wait()的执行线程就被称为**等待线程**；Object.notify()的执行线程就被称为**通知线程**。由于Object类是Java中任何对象的父类，因此使用Java中的任何对象都能够实现等待与通知。

使用Object.wait()实现等待，其代码模板如下伪代码所示：

~~~java
//在调用wait方法前获得相应对象的内部锁
synchronized(someObject) {
    while(保护条件不成立) {
        //调用Object.wait()暂停当前线程
        someObject.wait();
    }
    
    // 代码执行到这里说明保护条件已经满足
    // 执行目标动作
    doAction();
}
~~~

其中，保护条件是一个包含共享变量的布尔表达式。当这些共享变量被其他线程（通知线程）更新之后使相应的保护条件得以成立时，这些线程会通知等待线程。由于一个线程只有在持有一个对象的内部锁的情况下才能够调用该对象的wait方法，因此Object.wait()调用总是放在相应对象所引导的临界区之中。包含上述模板代码的方法被称为**受保护方法**（Guarded Method）。受保护方法包括3个要素：保护条件、暂停当前线程和目标动作。

设someObject为Java中任意一个类的实例，因执行someObject.wait()而被暂停的线程就称为对象someObject上的**等待线程**。由于同一个对象的同一个方法（someObject.wait()）可以被多个线程执行，因此一个对象可能存在多个等待线程。someObject上的等待线程可以通过其他线程执行someObject.notify()来唤醒。someObject.wait()会以原子操作的方式使其执行线程（当前线程）暂停并使该线程释放其所持有的someObject对应的内部锁。当前线程被暂停的时候其对someObject.wait()调用并未返回。其他线程在该线程所需的保护条件成立的时候执行相应的notify方法，即someObject.notify()可以唤醒someObject上的一个（任意的）等待线程。被唤醒的等待线程在其占用处理器继续运行的时候，需要再次申请someObject对应的内部锁。被唤醒的线程在其再次持有someObject对应的内部锁的情况下继续执行someObject.wait()中剩余的指令，直到wait方法返回。

等待线程只在保护条件不成立的情况下才执行Object.wait()进行等待，即在执行Object.wait()前我们需要判断保护条件是否成立（当然，此时保护条件也是有可能成立的）。另外，等待线程在其被唤醒，继续运行到其再次持有相应对象的内部锁的这段时间内，由于其他线程可能抢先获得相应的内部锁并更新了相关共享变量而导致该线程所需的保护条件再次不成立，因此Object.wait()调用返回之后，我们需要再次判断此时保护条件是否成立。所以，对保护条件的判断以及Object.wait()调用应该放在循环语句之中，以确保目标动作只有在保护条件成立的情况下才能够执行！

另外，等待线程对保护条件的判断以及目标动作的执行必须是一个原子操作，否则可能产生静态——目标动作被执行前的那一刻其他线程对共享变量的更新又使得保护条件重新不成立。因此，目标动作的执行必须和保护条件的判断以及Object.wait()调用放在同一个对象所引导的临界区中。

> **注意**
>
> - 等待线程对保护条件的判断、Object.wait()的调用总是应该放在相应对象所引导的临界区中的一个循环语句之中。
> - 等待线程对保护条件的判断、Object.wait()的执行以及目标动作的执行必须放在同一个对象（内部锁）所引导的临界区之中。
> - Object.wait()暂停当前线程时释放的锁只是与该wait方法所属对象的内部锁。当前线程所持有的其他内部锁、显式锁并不会因此被释放。

使用Object.notify()实现通知，其代码模板如下伪代码所示：

~~~java
synchronized (someObject) {
    // 更新等待线程的保护条件涉及的共享变量
    updateSharedState();
    // 唤醒其他线程
    someObject.notify();
}
~~~

包含上述模板代码的方法被称为通知方法，它包含两个要素：更新共享变量、唤醒其他线程。由于一个线程只有在持有一个对象的内部锁的情况下才能够执行该对象的notify方法，因此Object.notify()调用总是放在相应对象内部锁所引导的临界区之中。也正是由于Object.notify()要求其执行线程必须持有该方法所属对象的内部锁，因此Object.wait()在暂停其执行线程的同时必须释放相应的内部锁；否则通知线程无法获得相应的内部锁；否则通知线程无法获得相应的内部锁，也就无法执行相应对象的notify方法来通知等待线程！Object.notify()的执行线程持有的相应对象的内部锁只有在Object.notify()调用所在的临界区代码执行结束后才会被释放，而Object.notify()本身并不会将这个内部锁释放。因此，为了使等待线程在其被唤醒之后能够尽快再次获得相应的内部锁，我们要尽可能地将Object.notify()调用放在靠近临界区结束的地方。等待线程被唤醒之后占用处理器继续运行时，如果有其他线程持有了相应对象的内部锁，那么这个等待线程可能又会再次被暂停，以等待再次获得相应内部锁的机会，而这会导致上下文切换。

调用Object.notify()所唤醒的线程仅是相应对象上的一个任意等待线程，所以这个被唤醒的线程可能不是我们想要唤醒的那个线程。因此，有时候我们需要借助Object.notify()的兄弟——Object.notifyAll()，它可以唤醒相应对象上的所有等待线程。由于等待线程和通知线程在其实现等待和通知的时候必须是调用同一个对象的wait方法、notify方法，而这两个方法都要求其执行线程必须持有该方法所属对象的内部锁，因此等待线程和通知线程是同步在同一对象之上的两种线程。

> **注意**
>
> 等待线程和通知线程必须调用同一个对象的wait方法、notify方法来实现等待和通知。调用一个对象的notify方法所唤醒的线程仅是该对象上的一个任意等待线程。notify方法调用应该尽可能地放在靠近临界区结束的地方。

> **扩展阅读** Object.wait()/notify()的内部实现
>
> 我们知道Java虚拟机会为每个对象维护一个入口集（Entry Set）用于存储申请该对象内部锁的线程。此外，Java虚拟机还会为每个对象维护一个被称为等待集（Wait Set）的队列，该队列用于存储该对象上的等待线程。Object.wait()将当前线程暂停并释放相应内部锁的同时会将当前线程（的引用）存入该方法所属对象的等待集中。执行一个对象的notify方法会使该对象的等待集中的一个任意线程被唤醒。被唤醒的线程仍然会停留在相应对象的等待集之中，直到该线程再次持有相应内部锁的时候（此时Object.wait()调用尚未返回）Object.wait()会使当前线程从其所在的等待集移除，接着Object.wait()调用就返回了。Object.wait()/notify()实现的等待/通知中的几个关键动作，包括将当前线程加入等待集、暂停当前线程、释放锁以及将唤醒后的等待线程从等待集中移除等，都是在Object.wait()中实现的。Object.wait()的部分内部实现相当于如下伪代码：
>
> ~~~java
> public void wait() {
>     // 执行线程必须持有当前对象对应的内部锁
>     if(!Thread.holdsLock(this)){
>         throws new IllegalMonitorStateException();
>     }
>     
>     if(当前线程不在等待集中){
>         // 将当前线程加入当前对象的等待集中
>         addToWaitSet(Thread.currentThread());
>     }
>     
>     atomic {
>         // 原子操作开始
>         // 释放当前对象的内部锁
>         releaseLock(this);
>         // 暂停当前线程
>         block(Thread.currentThread()); // 语句①
>         // 原子操作结束
>     }
>     
>     // 再次申请当前对象的内部锁
>     aquireLock(this); // 语句②
>     // 将当前线程从当前对象的等待集中移除
>     removeFromWaitSet(Thread.currentThread());
>     return; // 返回
> }
> ~~~
>
> 等待线程在语句①被执行之后就被暂停了。被唤醒的线程在其占用处理器继续运行的时候会继续执行其暂停前调用的Object.wait()中的其他指令，即从上述代码中的语句②开始继续执行：先再次申请Object.wait()所属对象的内部锁，接着将当前线程从相应的等待集中移除，然后Object.wait()调用才返回！

### 5.1.2 wait/notify的开销及问题

下面我们看wait/notify实现的等待/通知时可能遇到的问题及其解决方法。

- 过早唤醒（Wakeup too soon）问题。设一组等待/通知线程同步在对象someObject之上，初始状态下所有保护条件都不成立。接着，线程N1更新了共享遍历state1使得保护条件1得以成立，此时为了唤醒使用该保护条件的所有等待线程（线程W1和线程W2），N1执行了someObject.notifyAll()。由于someObject.notifyAll()唤醒的是someObject上的所有等待线程，因此这时线程W2也会被唤醒。然而W2所使用的保护条件2此时并没有成立，这就使得该线程被唤醒之后仍然需要继续等待。这种等待线程在其所需的保护条件并未成立的情况下被唤醒的现象就被称为过早唤醒（Wakeup too soon）。过早唤醒使得那些本来无须被唤醒的等待线程也被唤醒了，从而造成资源浪费。过早唤醒问题可以利用JDK 1.5 引入的java.util.concurrent.locks.Condition 接口来解决，5.2节会介绍该接口。
- 信号丢失（Missed Signal）问题。如果等待线程在执行Object.wait() 前没有先判断保护条件是否已然成立，那么有可能出现这种情形——通知线程在该等待线程进入临界区之前就已经更新了相关共享变量，使得相应的保护条件成立并进行了通知，但是此时等待线程还没有被暂停，自然也就无所谓唤醒了。这就可能造成等待线程直接执行Object.wait()而被暂停的时候，该线程由于没有其他线程进行通知而一直处于等待状态。这种现象就相当于等待线程错过了一个本来“发送”给他的“信号”，因此被称为**信号丢失**（Missed Signal）。只要将对保护条件的判断和Object.wait()调用放在一个循环语句之中就可以避免上述场景的信号丢失。信号丢失的另外一个表现在应该调用Object.notify()的地方却调用了Object.notify()。比如，对于使用同一个保护条件的多个等待线程，如果通知线程在侦测到这个保护条件成立后调用的是Object.notify()，那么这些等待线程最多只有一个线程能够被唤醒，甚至一个也没有被唤醒——被唤醒的线程是Object.notify()所属对象上使用其他保护条件的一个等待线程！也就是说，尽管通知线程在调用Object.notify()前可能考虑（判断）了某个特定的保护条件是否成立，但是Object.notify()本身在其唤醒线程时是不考虑任何保护条件的！这就可能使得通知线程执行Object.notify()进行的通知对于使用相应保护条件的等待线程来说丢失了。这种情形下，避免信号丢失的一个方法是在必要的时候使用Object.notifyAll()来通知。总的来说，信号丢失本质上是一种代码错误，而不是Java标准库API自身的问题。
- 欺骗性唤醒（Spurious Wakeup）问题。等待线程也可能在没有其他任何线程执行Object.notify()/notifyAll() 的情况下被唤醒。这种现象被称为**欺骗性唤醒**（Spurious Wakeup）。由于欺骗性唤醒的作用，等待线程被唤醒的时候该线程所需的保护条件可能仍然未成立，因为此时没有任何线程对相对共享变量进行过更新。可见，欺骗性唤醒也会导致过早唤醒。欺骗性唤醒虽然在实践中出现的概率非常低，但是由于操作系统是允许这种现象产生的，因此 Java 平台同样也允许这种现象的存在。欺骗性唤醒是Java平台对操作系统妥协的一种结果。只要我们将对保护条件的判断和Object.wait() 调用行放在一个循环语句之中，欺骗性唤醒就不会对我们造成实际的影响。
  欺骗性唤醒和信号丢失问题的规避方法前文已经提及：将等待线程对保护条件的判断、Object.wait()的调用放在相应对象所引导的临界区中的一个循环语句之中即可。
- 上下文切换问题。wait/notify的使用可能导致较多的上下文切换。
  - 首先，等待线程执行Object.wait() 至少会导致该线程对相应对象内部锁的两次申请与释放。通知线程在执行Object.notify()/notifyAll() 时需要持有相应对象的内部锁，因此 Object.notify()/notifyAll() 调用会导致一次锁的申请。而锁的申请与释放可能导致上下文切换。
  - 其次，等待线程从被暂停到唤醒这个过程本身就会导致上下文切换。
  - 再次，被唤醒的等待线程在继续运行时需要再次申请相应对象的内部锁，此时等待线程可能需要和相应对象的入口集中的其他线程以及其他新来的活跃线程（即申请相应的内部锁且处于RUNNABLE状态的线程）争用相应的内部锁，而这又可能导致上下文切换。
  - 最后，过早唤醒问题也会导致额外的上下文切换，这是因为被过早唤醒的线程仍然需要继续等待，即再次经历被暂停和唤醒的过程。

以下方法有助于避免或者减少 wait/notify 导致过多的上下文切换。

- 在保证程序正确性的前提下（5.1.3节会介绍），使用Object.notify() 替代 Object.notifyAll()。Object.notify()调用不会导致过早唤醒，因此减少了相应的上下文切换开销。
- 通知线程在执行完 Object.notify()/notifyAll() 之后尽快释放相应的内部锁。这样可以避免被唤醒的线程在 Object.wait() 调用返回前再次申请相应内部锁时，由于该锁尚未被通知线程释放而导致该线程被暂停（以等待再次获得锁的机会）。

### 5.1.3 Object.notify()/notifyAll()的选用

Object.notify() 可能导致信号丢失这样的正确性问题，而 Object.notifyAll() 虽然效率不太高（把不需要唤醒的等待线程也给唤醒了），但是其在正确性方面有保障。因此实现通知的一种比较流行的保守性方法是优先使用 Object.notifyAll() 以保障正确性，只有在有证据表明使用Object.notify()足够的情况下才使用Object.notify()——Object.notify() 只有在下列条件全部满足的情况下才能够用于替代notifyAll方法。

**条件1** 一条通知仅需要唤醒至多一个线程。这一点容易理解，但是光满足这一点还不足以用Object.notify() 去替代 Object.notifyAll()。在不同的等待线程可能使用不同的保护条件的情况下，Object.notify() 唤醒的一个任意线程可能并不是我们需要唤醒的那一个（种）线程。因此，这个问题还需要通过满足条件2来排除。

**条件2** 相应对象的等待集中仅包含同质等待线程。所谓**同质等待线程**指这些线程使用同一个保护条件，并且这些线程在Object.wait() 调用返回之后的处理逻辑一致。最为典型的同质线程是使用同一个Runnable接口实例创建的不同线程（实例）或者从同一个Thread子类的new出来的多个实例。

> **注意**
>
> Object.notify()唤醒的是其所属对象上的一个任意等待线程。Object.notify() 本身在唤醒线程时是不考虑保护条件的。 Object.notifyAll() 方法唤醒的是其所属对象上的所有等待线程。使用Object.notify() 替代 Object.notifyAll() 时需要确保以下两个条件同时得以满足：
>
> - 一次通知仅需要唤醒至多一个线程。
> - 相应对象上的所有等待线程都是同质等待线程。

### 5.1.4 wait/notify 与 Thread.join()

Thread.join() 可以使当前线程等待目标线程结束之后才继续运行。Thread.join()还有另外一个如下声明的版本：

~~~java
public final void join(long millis) throws InterruptedException
~~~

join(long) 允许我们指定一个超时时间。如果目标线程没有在指定的时间内终止，那么当前线程也会继续运行。join(long) 实际上就是使用了 wait/notify 来实现的，如下所示：

~~~java
public final synchronized void join(long millis) throws InterruptedException {
    long base = System.currentTimeMillis();
    long now = 0;
    
    if(millis < 0){
        throw new illegalArgumentException("timeout value is negative");
    }
    
    if(millis == 0){
        while(isAlive()){
            wait(0);
        }
    } else {
        while(isAlive()){
            long delay = millis - now;
            if(delay <= 0){
                break;
            }
            wait(delay);
            now = System.currentTimeMillis() - base;
        }
    }
}
~~~

join(long) 是一个同步方法。它检测到目标线程未结束的时候会调用 wait 方法来暂停当前线程，直到目标线程已终止。这里，当前线程相当于等待线程，其所需的保护条件是“目标线程已终止”（Thread.isAlive()为false）。Java虚拟机会在目标线程的run方法运行结束后执行该线程（对象）的notifyAll方法来通知所有的等待线程。可见这里的目标线程充当了同步对象的角色，而Java虚拟机中notifyAll方法的执行线程则是通知线程。另外，join(long)正是按照清单5-2所展示的实现等待超时空控制的方法来使用 wait(long) 方法的。

Thread.join() 调用相当于 Thread.join(0) 调用。

## 5.2 Java条件变量

总的来说，Object.wait()/notify()过于底层，并且还存在过早唤醒问题以及Object.wait(long)无法区分其返回是由于等待超时还是被通知线程唤醒等问题。但是，了解wait/notify 有助于我们理解和维护现有系统，以及学习和使用JDK 1.5 中引入的新的标准库类 java.util.concurrent.locks.Condition 接口。

Condition接口可作为wait/notify的替代品来实现等待/通知，它为解决过早唤醒问题提供了支持，并解决了Object.wait(long) 不能区分其返回是否是由等待超时而导致的问题。Condition接口定义的await方法、signal方法和signalAll方法分别相当于Object.wait()、Object.notify() 和 Object.notifyAll()。

Lock.newCondition() 的返回值就是一个Condition实例，因此调用任意一个显式锁实例的newCondition 方法可以创建一个相应的Condition接口。Object.wait()/notify()要求其执行线程持有创建该Condition实例的显式锁。Condition实例也被称为**条件变量**（Condition Variable）或者**条件队列**（Condition Queue），每个Condition实例内部都维护了一个用于存储等待线程的队列（等待队列）。设 cond1 和 cond2 是两个不同的Condition实例，一个线程执行cond1.wait()会导致其被暂停（线程生命周期状态变更为WAITING）并被存入cond1的等待队列。cond1.signal() 会使 cond1 的等待队列中的一个任意线程被唤醒。cond1.signalAll()会使cond1的等待队列中的所有线程被唤醒，而cond2的等待队列中的任何一个线程不受此影响。

Condition接口的使用方法与wait/notify 的使用方法相似，如下代码模板所示：

~~~java
class ConditionUsage {
    private final Lock lock = new ReentrantLock();
    private final Condition condition = lock.newCondition();
    public void aGuaredMethod() throws InterruptedException {
        lock.lock();
        try {
            while (保护条件不成立) {
                condition.await();
            }
            // 执行目标动作
            doAction();
        } finally {
            lock.unlock();
        }
    }
    
    private void doAction() {
        // ...
    }
    
    public void anNotificationMethod() throws InterruptedException {
        lock.lock();
        try {
            // 更新共享变量
            changeState();
            condition.signal();
        } finally {
            lock.unlock();
        }
    }
    
    private void changeState() {
        // ...
    }
}
~~~

可见，Condition.await()/signal() 的执行线程需要持有创建相应条件变量的显式锁。对保护条件的判断、Condition.await()的调用也同样放在一个循环语句之中，并且该循环语句与目标动作的执行放在同一个显示锁所引导的临界区之中，这同样也是考虑到了欺骗性唤醒问题、信号丢失问题。Condition.await() 与 Object.wait() 类似，它使当前线程暂停的同时也使当前线程释放其持有的相应显式锁，并且这时 Condition.await() 调用也同样未返回。被唤醒的等待线程继续运行的时候也需要再次申请相应的显式锁，被唤醒的等待线程再次获得相应的显式锁后 Condition.await() 调用才返回。上述模板代码中的 aGuaredMethod 方法是一个受保护方法，anNotificationMethod 方法是一个通知方法。

应用代码是这样解决过早唤醒问题的：在应用代码这一层次上建立保护条件与条件变量之间的对应关系，即让使用不同保护条件的等待线程调用不同的条件变量的await方法来实现其等待；并让通知线程在更新了共享变量之后，仅调用涉及了这些共享变量的保护条件所对应的条件变量的signal/signalAll 方法来实现通知。

> **注意**
>
> Condition接口本身只是对解决过早唤醒问题提供了支持。要真正解决过早唤醒问题，我们需要通过应用代码维护保护条件与条件变量之间的对应关系，即使用不同的保护条件的等待线程需要调用不同的条件变量的await方法来实现其等待，并使通知线程在更新了相关共享变量之后，仅调用与这些共享变量有关的保护条件所对应的条件变量的signal/signalAll 方法来实现通知。

Condition接口还解决了 Object.wait(long) 存在的问题 —— Object.wait(long) 无法区分其返回是由于等待超时还是被通知的。 Condition.awaitUtil(Date deadline) 可以用于实现带超时时间限制的等待，并且该方法的返回值能够区分该方法调用是由于等待超时而返回还是由于其他线程执行了相应条件变量的signal/signalAll方法而返回。Condition.awaitUtil(Date deadline)的唯一参数 deadline 表示等待的最后期限（Deadline）。过了这个时间点就算等待超时。Condition.awaitUtil(Date) 返回值 true表示进行的等待尚未达到最后期限，即此时方法的返回是由于其他线程执行了相应条件变量的signal/signalAll 方法。由于Condition.await()/awaitUtil(Date) 与 Object.wait() 类似，等待线程因执行Condition.awaitUtil(Date) 而被暂停的同时，其持有的相应显式锁（即创建相应条件变量的显式锁）也会被释放，等待线程被唤醒之后得以继续运行时需要再次申请相应的显式锁，然后等待线程对Condition.await()/awaitUtil(Date) 的调用才能够返回。在等待线程被唤醒到其再次申请相应的显式锁的这段时间内，其他线程（或者通知线程本身）可能已经抢先获得相应的显式锁并在其临界区中更新了相应共享变量而使得等待线程所需的保护条件重新不成立。因此，Condition.awaitUtil(Date) 返回 true（等待未超时）的情况下我们可以选择继续等待，如清单5-3所示。

~~~java
public class TimeoutWaitWithCondition {
    private static final Lock lock = new ReentrantLock();
    private static final Condition condition = lock.newCondition();
    private static boolean ready = false;
    protected static final Random random = new Random();
    
    public static void main(String[] args) throws InterruptedException {
        Thread t = new Thread() {
            @Override
            public void run() {
                for (;;) {
                    lock.lock();
                    try {
                        ready = random.nextInt(100) < 5 ? true : false;
                        if (ready) {
                            condition.signal();
                        }
                    } finally {
                        lock.unlock();
                    }
                    
                    // 使当前线程暂停一段（随机）时间
                    Tools.randomPause(500);
                } // for 循环结束
            }
        };
        t.setDaemon(true);
        t.start();
        waiter(1000);
    }
    
    public static void waiter(final long timeOut) throws InterruptedException {
        if (timeOut < 0) {
            throw new IllegalArgumentException();
        }
        // 计算等待的最后期限
        final Date deadline = new Date(System.currentTimeMillis() + timeOut);
        // 是否继续等待
        boolean continueToWait = true;
        lock.lock();
        try {
            while (!ready) {
                Debug.info("still not ready, continue to wait:%s", continueToWait);
                // 等待未超时，继续等待
                if (!continueToWait) {
                    // 等待超时退出
                    Debug.error("Wait timed out, unable to execution target action!");
                    return;
                }
                continueToWait = condition.awaitUtil(deadline);
            } // while 循环结束
            
            // 执行目标动作
            guarededAction();
        } finally {
            lock.unlock();
        }
    }
    
    private static void guarededAction() {
        Debug.info("Take some action.");
        // ...
    }
}
~~~

在上述代码中，我们根据系统当前时间和等待超时时间限制（timeOut）来计算出等待的最后期限（deadline）,并以此为参数去调用Condition.awaitUtil(Date)。这里Condition.awaitUtil(Date) 调用与 Condition.await() 调用一样，也要放在一个循环语句之中。如果 Condition.awaitUtil(Date) 调用返回 false（表示等待超时），那么等待方法就直接返回，否则等待方法可以继续等待。

使用条件变量所产生的开销与wait/notify 方法基本相似；不过由于条件变量的使用可以避免过早唤醒问题，因此其使用导致的上下文切换要比 wait/notify 少一些。

## 5.3 倒计时协调器：CountDownLatch

Thread.join() 实现的是一个线程等待另外一个线程结束。有时候一个线程可能只需要等待其他线程执行的特定操作结束即可，而不必等待这些线程终止。当然，此时我们也可以使用条件变量来实现。不过，此时我们可以使用更加直接的工具类——java.util.concurrent.CountDownLatch。

CountDownLatch 可以用来实现一个（或者多个）线程等待其他线程完成一组特定的操作之后才继续运行。这组操作被称为**先决操作**。

CountDownLatch 内部会维护一个用于表示未完成的先决操作数量的计数器。CountDownLatch.countDown()每被执行一次就会使相应实例的计数器值减少1。CountDownLathc.await() 相当于一个受保护方法，其保护条件为“计数器值为0”（代表所有先决操作已执行完毕），目标操作是一个空操作。因此，当计数器值不为0时 CountDownLatch.await() 的执行线程会被暂停，这些线程就被称为相应 CountDownLatch 上的等待线程。CountDownLatch.countDown() 相当于一个通知方法，它会在计数器值达到 0 的时候唤醒相应实例上的所有等待线程。计数器的初始值是在CountDownLatch的构造参数中指定的，如下声明所示：

~~~java
public CountDownLatch(int count)
~~~

count 参数用于表示先决操作的数量或者需要被执行的次数。当计数器的值达到 0 之后，该计数器的值就不再发生变化。此时，调用CountDownLatch.countDown() 并不会导致异常的抛出，并且后续执行 CountDownLatch.await()的线程也不会被暂停。因此，CountDownLatch的使用是一次性的：一个CountDownLatch实例只能够实现一次等待和唤醒。

可见，CountDownLatch内部封装了对“全部先决操作已执行完毕”（计数器值为0）这个保护条件的等待与通知逻辑，因此客户端代码在使用CountDownLatch实现等待/通知的时候调用await、countDown方法都无须加锁。

~~~java
public class ServerStarter {
    public static void main(String[] args) {
        // 省略其他代码
        
        // 启动所有服务
        ServiceManager.startServices();
        
        // 执行其他操作
        
        // 在所有其他操作执行结束后，检查服务启动状态
        boolean allIsOK;
        // 检测全部服务的启动状态
        allIsOK = ServiceManager.checkServiceStatus();
        
        if (allIsOK) {
            System.out.println("All services were successfully started!");
            // 省略其他代码
        } else {
            // 个别服务启动失败，退出JVM
            System.err.println("Some service(s) failed to start, exiting JVM...");
            System.exit(1);
        }
        // ...
    }
}
~~~

~~~java
public class ServiceManager {
    static volatile CountDownLatch latch;
    static Set<Service> services;
    
    public static void startServices() {
        services = getServices();
        for(Service service: services) {
            service.start();
        }
    }
    
    public static boolean checkServiceStatus() {
        boolean allIsOK = true;
        // 等待服务启动结束
        try {
            latch.await();
        } catch (InterruptedException e) {
            return false;
        }
        
        for (Service service : services){
            if(!service.isStarted()){
                allIsOK = false;
                break;
            }
        }
        
        return allIsOK;
    }
    
    static Set<Service> getServices() {
        // 模拟实际代码
        latch = new CountDownLatch(3);
        HashSet<Service> servicesSet = new HashSet<Service>();
        servicesSet.add(new SampleServiceC(latch));
        servicesSet.add(new SampleServiceA(latch));
        servicesSet.add(new SampleServiceB(latch));
        return servicesSet;
    }
}
~~~

~~~java
public abstract class AbstractService implements Service {
    protected boolean started = false;
    protected final CountDownLatch latch;
    
    public AbstractService(CountDownLatch latch) {
        this.latch = latch;
    }
    
    @Override
    public boolean isStarted() {
        return started;
    }
    
    // 留给子类实现的抽象方法，用于实现服务器的启动逻辑
    protected abstract void doStart() throws Exception;
    
    @Override
    public void start() {
        new ServiceStarter().start();
    }
    
    @Override
    public void stop() {
        // 默认什么也不做
    }
    
    class ServiceStarter extends Thread {
        @Override
        public void run() {
            final String serviceName = AbstractService.this.getClass().getSimpleName();
            Debug.info("Starting %s", serviceName);
            try {
                doStart();
                started = true;
            } catch (Exception e) {
                e.printStackTrace();
            } finally {
                latch.countDown();
                Debug.info("Done Starting %s", serviceName);
            }
        }
    }
}
~~~

如果CountDownLatch内部计数器由于程序的错误而永远无法达到0，那么相应实例上的等待线程会一直处于WAITING状态。避免该问题的出现有两种方法。

其一，确保所有CountDownLatch.countDown() 调用都位于代码中正确的位置。例如本案例，如果我们把CountDownLatch.countDown() 调用放在 doStart() 调用之后而不是finally块中（见清单5-6），那么某个服务启动过程中出现异常（如运行时异常）会导致main线程执行到ServiceManager.checkServiceStatus()时，该线程一直处于WAITING状态。

其二，等待线程在等待先决操作完成的时候指定一个时间限制。此时我们可以使用CountDownLatch.await() 的另外一个版本，其声明如下：

~~~java
public boolean await(long timeout, TimeUnit unit) throws InterruptedException
~~~

CountDownLatch.await(long, TimeUnit) 允许指定一个超时时间，在该时间内如果相应CountDownLatch 实例的计数器值仍然未达到 0， 那么所有执行该实例的await 方法的线程都会被唤醒。该方法的返回值可用于区分其返回是否是由于等待超时。

> **注意**
>
> CountDownLatch 内部计数器值达到0后其值就恒定不变，后续执行该CountDownLatch实例的await方法的任何一个线程都不会被暂停。为了避免等待线程永远被暂停，CountDownLatch.countDown()调用必须放在代码中总是可以被执行到的地方，例如finally块中。

对于同一个CountDownLatch 实例 latch，latch.countDown() 的执行线程在执行该方法之前所执行的任何内存操作对等待线程在latch.await() 调用返回之后的代码是可见的且有序的。

前文我们说过CountDownLatch 的构造器中的参数既可以表示先决操作的数量，也可以表示先决操作需要被执行的次数。在上述实战案例中，CountDownLatch 的构造器中的参数的含义就属于前者。而后者表示我们可以在一个线程中多次调用同一个CountDownLatch 实例的countDown 方法，以使相应实例的内部计数器值达到 0，如清单5-7所示。

~~~java
public class CountDownLatchExample {
    private static final CountDownLatch latch = new CountDownLatch(4);
    private static int data;
    
    public static void main(String[] args) throws InterruptedException {
        Thread workerThread = new Thread() {
            @Override
            public void run() {
                for (int i = 1; i < 10; i++) {
                    data = i;
                    latch.countDown();
                    // 使当前线程暂停（随机）一段时间
                    Tools.randomPause(1000);
                }
            }
        };
        workerThread.start();
        latch.await();
        Debug.info("It's done. data=%d", data);
    }
}
~~~

我们在创建 CountDownLatch 实例 latch 的时候指定的构造器参数为4。尽管 latch.countDown() 一共会被子线程workerThread 执行 10 次，但是该程序的输出总是如下：

~~~
It's done. data=4
~~~

这里程序输出的 data 为 4 而不是 10 是由于：首先， latch.countDown() 被 workerThread 执行了 4 次之后，main 线程对 latch.countDown() 的调用就返回了，从而使该线程被唤醒。其次，workerThread 在执行 latch.countDown() 前所执行的操作（更新共享变量 data）的结果对等待线程（main 线程）从 latch.await() 返回之后的代码可见，因此 main 线程被唤醒时能够读取到此前 workerThread 在 latch.countDown() 调用返回前的操作结果——data被更新为 4。

这里，latch.countDown() 被 workerThread 执行的次数大于4次并不会导致异常，也不会导致latch内部状态（计数器值）的变更。

## 5.4 栅栏（CyclicBarrier）

有时候多个线程可能需要相互等待对方执行到代码中的某个地方（集合点），这时这些线程才能够继续执行。JDK 1.5开始引入了一个类java.util.concurrent.CyclicBarrier，该类可以用来实现这种等待。CyclicBarrier类的类名中虽然包含Barrier这个单词，但是它和我们前面讲的内存屏障没有直接的关联。类名中Cyclic表示CyclicBarrier实例是可以重复使用的。

使用CyclicBarrier实现等待的线程被称为**参与方**（Party）。参与方只需要执行CyclicBarrier.await()就可以实现等待。尽管从应用代码的角度来看，参与方是并发执行CyclicBarrier.await()的，但是，CyclicBarrier内部维护了一个显式锁，这使得其总是可以在所有参与方中区分出一个最后执行CyclicBarrier.await()的线程，该线程被称为**最后一个线程**。除最后一个线程外的任何参与方执行CyclicBarrier.await()都会导致该线程被暂停（线程生命周期状态变为WAITING）。最后一个线程执行Cyclic.await()会使得使用相应CyclicBarrier实例的其他所有参与方被唤醒，而最后一个线程自身并不会被暂停。

与CountDownLatch不同的是，CyclicBarrier实例是可重复使用的：所有参与方被唤醒的时候，任何线程再次执行CyclicBarrier.await()又会被暂停，直到这些线程中的最后一个线程执行了CyclicBarrier.await()。

CyclicBarrier的其中一个构造器允许我们指定一个被称为barrierAction的任务（Runnable接口实例）。barrierAction会被最后一个线程执行CyclicBarrier.await方法时执行，该任务执行结束后其他等待线程才会被唤醒。

由于CyclicBarrier内部实现是基于条件变量的，因此CyclicBarrier的开销与条件变量的开销相似，其主要开销在可能产生的上下文切换。

> **扩展阅读** CyclicBarrier的内部实现
>
> CyclicBarrier内部使用了一个条件变量trip来实现等待/通知。CyclicBarrier内部实现使用了分代（Generation）的概念用于表示CyclicBarrier实例是可以重复使用的。除最后一个线程外的任何一个参与方都相当于一个等待线程，这些线程所使用的保护条件是“当前分代内，尚未执行await方法的参与方个数（parties）为0”。当前分代的初始状态是parties等于参与方总数（通过构造器中的parties参数指定）。CyclicBarrier.await()每被执行一次会使相应实例的parties值减少1.最后一个线程相当于通知线程，它执行CyclicBarrier.await()会使相应实例的parties值变为0，此时该线程会先执行barrierAction.run()，然后再执行trip.signalAll()来唤醒所有等待线程。接着，开始下一个分代，即使得CyclicBarrier的parties值又重新恢复为其初始值。

设cyclicBarrier为一个任意的CyclicBarrier实例，任意一个参与方在执行cyclicBarrier.await()前所执行的任何操作对barrierAction.run()而言是可见的、有序的。barrierAction.run()中所执行的任何操作对所有参与方在cyclicBarrier.await()调用成功返回之后的代码而言是可见的、有序的。

### CyclicBarrier的典型应用场景

CyclicBarrier的典型应用场景包括以下几个，它们都可以在上述例子中找到影子。

- 使迭代（Iterative）算法并发化。在并发化的迭代算法中，迭代算法是由多个工作者线程并行执行的。CyclicBarrier可用来实现执行迭代操作的任何一个工作者线程必须等待其他工作者线程也完成当前迭代操作的情况下才继续其下一轮的迭代操作，以便形成迭代操作的中间结果作为下一轮迭代的基础（输入）。因此，该应用场景从代码上反映出来的是，CyclicBarrier.await()调用是在一个循环中执行的。
- 在测试代码中模拟高并发。在编写多线程程序的测试代码时，我们常常需要使用有限的工作者线程来模拟高并发操作。为此，CyclicBarrier可用来实现这些工作者线程中的任意一个线程在执行其操作前必须等待其他线程也准备就绪，即使得这些工作者线程尽可能地在同一时刻开始其操作，正如上述例子我们使用CyclicBarrier来实现一排中的士兵在同一时刻开始射击。

CyclicBarrier往往被滥用，其表现是在没有必要使用CyclicBarrier的情况下使用了CyclicBarrier。这种滥用的一个典型例子是利用CyclicBarrier的构造器参数barrierAction来指定一个任务，以实现一种等待线程结束的效果：barrierAction中的任务只有在目标线程结束后才能够被执行。事实上，这种情形下我们完全可以使用更加对口的Thread.join()或者CountDownLatch来实现。因此，如果代码对CyclicBarrier.await()调用不是放在一个循环之中，并且使用CyclicBarrier的目的也不是为了模拟高并发操作，那么此时对CyclicBarrier的使用可能是一种滥用。

## 5.5 生产者-消费者模式

在生产者-消费者模式中，生产者（Producer）的主要职责是生产（创建）产品（Product）。产品既可以是数据，也可以是任务。消费者（Consumer）的主要职责是消费生产者所生产的产品。这里的“消费”包括对产品所代表的数据进行加工处理或者执行产品所代表的任务。生产者和消费者是并发地运行在各自的线程之中的，这就意味着运用生产者-消费者模式可以使程序中原本串行的处理得以并发化。

由于线程之间无法像函数调用那样通过参数直接传递数据，因此生产者和消费者之间需要一个用于传递产品的传输通道（Channel）。传输通道相当于生产者和消费者之间的缓冲区，生产者每生产一个产品就将其放入传输通道，消费者则不断地从传输通道中取出产品进行消费，传输通道通常可以使用一个线程安全的队列来实现。

> **术语定义**
>
> 将产品存入传输通道的线程就被称为生产者线程，从传输通道中取出产品进行消费的线程就被称为消费者线程。

由于生产者和消费者运行在不同的线程中，因此生产者将产品（对象）存入传输通道，消费者再从相应的传输通道中取出产品的过程其实就是生产者线程将对象（产品）发布到消费者线程的过程，这种对象发布必须是线程安全的。

通常，生产者和消费者的处理能力是不同的，即生产者生产产品的速率和消费者消费产品的速率是不同的，较为常见的情形是生产者的处理能力比消费者的处理能力大。这种情况下，传输通道所起的作用不仅仅作为生产者和消费者之间传递数据的中介，它在一定程度上还起到一个平衡生产者和消费者处理能力的作用。

### 5.5.1 阻塞队列

传输通道相当于如清单5-10所示的接口。在该接口中，类型参数P代表产品的类型，take方法用于从传输通道中取出一个产品，put方法用于往传输通道中存入一个产品。

显然，当传输通道为空的时候消费者无法取出一个产品，此时消费者线程可以进行等待，直到传输通道非空，即生产者线程生产了新的产品。当传输通道存储空间满的时候生产者无法往其中存入新的产品，此时生产者线程可以进行等待，直到传输通道非满，即有消费者消费了产品而腾出新的存储空间。

生产者线程往传输通道中成功存入产品之后就会唤醒等待传输通道非空的消费者线程，而消费者线程从传输通道中取出一个产品之后就会唤醒等待传输通道非满的生产者线程。我们称这种传输通道的运作方式为阻塞式（Blocking），即从传输通道中存入一个产品或者取出一个产品时，相应的线程可能因为传输通道中没有产品或者其存储空间已满而被阻塞（暂停）。

> **术语定义**
>
> 一般而言，一个方法或者操作如果能够导致其执行线程被暂停（生命周期状态为WAITING或者BLOCKING），那么我们就称相应的方法/操作为阻塞方法（Blocking Method）或者阻塞操作。可见，阻塞方法/操作能够导致上下文切换。常见的阻塞方法/操作包括InputStream.read()、ReentrantLock.lock()、申请内部锁等。相反，如果一个方法或者操作并不会导致其执行线程被暂停，那么相应的方法/操作就被称为非阻塞方法（Non-blocking Method）或者非阻塞操作。

JDK 1.5中引入接口java.util.concurrent.BlockingQueue定义了一种线程安全的队列——阻塞队列。该接口相当于上述接口的超集。因此，我们也可以直接使用BlockingQueue的实现类作为传输通道。BlockingQueue的常用实现类包括ArrayBlockingQueue、LinkedBlockingQueue和SynchronousQueue等。

> **术语定义**
>
> 阻塞队列按照其存储空间的容量是否受限制来划分，可分为有界队列（Bounded Queue）和无界队列（Unbounded Queue）。有界队列的存储容量限制是由应用程序指定的，无界队列的最大存储容量为Integer.MAX_VALUE(2^31-1)个元素。
>
> 往队列中存入一个元素（对象）的操作被称为put操作，从队列中取出一个元素（对象）的操作被称为take操作。

put操作相当于生产者线程将对象（产品）安全发布到消费者线程。生产者线程执行put操作前所执行的任何内容操作，对后续执行take操作的消费者线程而言是可见的、有序的。

当消费者的处理能力低于生产者的处理能力时，产品的生产速率大于消费速率，这会导致队列中的产品积压，即队列中存储的产品会越来越多。由此导致队列中的这些对象（产品）所占用的内存空间以及其他资源越来越多。因此，我们可能需要限制传输通道的存储容量。此时，我们可以使用有界阻塞队列作为传输通道。

使用有界队列作为传输通道的另外一个好处是可以造成“反压”的效果：当消费者的处理能力跟不上生产者的处理能力时，队列中的产品会逐渐挤压到队列满。此时生产者会被暂停，直到消费者消费了部分产品而使队列非满，这相当于生产者暂停其产品生产而给消费者一个跟上其步伐的机会。当然，这里的代价是可能增加的上下文切换。



有界队列可以使用ArrayBlockingQueue或者LinkedBlockingQueue来实现。

ArrayBlockingQueue内部使用一个数组作为其存储空间，而数组的存储空间是预先分配的，因此ArrayBlockingQueue的put操作、take操作本身并不会增加垃圾回收的负担。ArrayBlockingQueue的缺点是其内部在实现put、take操作的时候使用的是同一个锁（显式锁），从而可能导致锁的高争用，进而导致较多的上下文切换。

LinkedBlockingQueue既能实现无界队列，也能实现有界队列。LinkedBlockingQueue的其中一个构造器允许我们创建队列的时候指定队列容量。

LinkedBlockingQueue的优点是其内部在实现put、take操作的时候分别使用了两个显式锁（putLock 和 takeLock），这降低了锁争用的可能性。LinkedBlockingQueue 的内部存储空间是一个链表，而链表节点（对象）所需的存储空间是动态分配的，put操作、take操作都会导致链表节点的动态创建和移除，因此LinkedBlockingQueue的缺点是它可能增加垃圾回收的负担。另外，由于LinkedBlockingQueue的put、take操作使用的是两个锁，因此LinkedBlockingQueue维护其队列的当前长度（size）时无法使用一个普通的int型变量而是使用了一个原子变量（AtomicInteger）。这个原子变量可能会被生产者线程和消费者线程争用，因此它可能导致额外的开销。

SynchronousQueue可以被看做一种特殊的有界队列。SynchronousQueue内部并不维护用于存储队列元素的存储空间。设synchronousQueue为一个任意的SynchronousQueue实例，生产者线程执行synchronousQueue.put(E)时如果没有消费者线程执行synchronousQueue.take()，那么该生产者线程会被暂停，直到有消费者线程执行了synchronousQueue.take()；类似地，消费者线程执行synchronousQueue.take()时如果没有生产者线程执行了synchronousQueue.put(E)，那么该消费者线程会被暂停，直到有生产者线程执行了synchronousQueue.put(E)。

因此，在使用SynchronousQueue作为传输通道的生产者-消费者模式中，生产者线程生产好一个产品之后，会等待消费者线程来取走这个产品才继续生产下一个产品，而不像使用ArrayBlockingQueue、LinkedBlockingQueue作为传输通道的情况下生产者线程将生产好的产品存入队列就继续生产下一个产品。



队列可以被看作生产者线程和消费者之间的共享资源，因此资源调度的公平性在队列上有所体现。占用队列的线程可以对队列进行put或者take操作，那么对队列（作为一种资源）的调度就是决定哪个线程可以进行put或者take操作的过程。ArrayBlockingQueue和SynchronousQueue都既支持非公平调度也支持公平调度，而LinkedBlockingQueue仅支持非公平调度。

如果生产者线程和消费者线程之间的并发程度比较大，那么这些线程对传输通道内部所使用的锁的争用可能性也随之增加。这时，有界队列的实现适合选用LinkedBlockingQueue，否则我们可以考虑ArrayBlockingQueue。

阻塞队列也支持非阻塞式操作（即不会导致执行线程被暂停）。比如，BlockingQueue接口定义的offer(E)和poll()分别相当于put(E)和take()的非阻塞版。非阻塞式方法通常用特殊的返回值表示操作结果：offer(E)的返回值false表示入队列失败（队列已满），poll()返回null表示队列为空。

> **提示**
>
> LinkedBlockingQueue适合在生产者线程和消费者线程之间的并发程度比较大的情况下使用。
>
> ArrayBlockingQueue适合在生产者线程和消费者线程之间的并发程度较低的情况下使用。
>
> SynchronousQueue适合在消费者处理能力与生产者处理能力相差不大的情况下使用。

### 5.5.2 限购：流量控制与信号量（Semaphore）

使用无界队列作为传输通道的一个好处是put操作并不会导致生产者线程被阻塞。因此，无界队列的使用不会影响生产者线程的步伐。但是在队列积压的情况下，无界队列中存储的元素可能越来越多，最终导致这些元素所占用的资源过多。因此，一般我们在使用无界队列作为传输通道的时候会同时限制生产者的生产速率，即进行流量控制以避免传输通道中积压过多的产品。

JDK 1.5中引入的标准库类java.util.concurrent.Semaphore可以用来实现流量控制。为了便于讨论，我们把代码所访问的特定资源或者执行特定操作的机会统一看作一种资源，这种资源被称为虚拟资源（Virtual Resource）。Semephore相当于虚拟资源配额管理器，它可以用来控制同一时间内对虚拟资源的访问次数。为了对虚拟资源的访问进行流量控制，我们必须使相应代码只有在获得相应配额的情况下才能够访问这些资源。为此，相应代码在访问虚拟资源前必须先申请相应的配额，并在资源访问结束后返还相应的配额。

Semaphore.acquire()/release()分别用于申请配额和返还配额。Semaphore.acquire()在成功获得一个配额后会立即返回。如果当前的可用配额不足，那么Semaphore.acquire()会使其执行线程暂停。Semaphore内部会维护一个等待队列用于存储这些被暂停的线程。Semaphore.acquire()在其返回之前总是会将当前的可用配额减少1.Semaphore.release()会使当前可用配额增加1，并唤醒相应Semaphore实例的等待队列中的一个任意等待线程。

Semaphore的使用需要注意以下几点。

- Semaphore.acquire()和Semaphore.release()总是配对使用。应用代码在访问虚拟资源前调用Semaphore.acquire()来申请配额，并在虚拟资源访问结束后调用Semaphore.release()来返回配额。由于Semaphore本身并不强制这种配对，即一个线程可以在未执行Semaphore.acquire()的情况下执行Semaphore.release()，因此Semaphore.acquire()/release()的配对使用需要由应用代码来保证。这点和锁的获得与释放有所不同，因为一个线程只有在持有某个锁的情况下才能释放该锁。
- Semaphore.release()调用总是应该放在一个finally块中，以避免虚拟资源访问出现异常的情况下当前线程所获得的配额无法返还（类似于锁泄漏）。
- 创建Semaphore实例时如果构造器中的参数permits值为1，那么所创建的Semaphore实例相当于一个互斥锁。与其他互斥锁不同的是，由于一个线程可以在未执行过Semaphore.acquire()的情况下执行相应的Semaphore.release()，因此这种互斥锁允许一个线程释放另外一个线程锁所持有的锁。
- 配额本身可被看作程序执行特定操作前所需持有的资源，因此对配额的调度也涉及公平性问题。默认情况下，Semaphore采用的是非公平性调度策略，因此在可用配额数为0的情况下，一个线程返回一个配额之后获得配额的那个线程可能是等待队列中那个被唤醒的线程，也可能是其他申请配额的活跃线程。

### *5.5.3 管道：线程间的直接输出与输入

Java标准库类PipedOutputStream和PipedInputStream是生产者-消费者模式的一个具体例子。PipedOutputStream和PipedInputStream分别是OutputStream和InputStream的一个子类，它们可用来实现线程间的直接输出和输入。所谓“直接”是指从应用代码的角度来看，一个线程的输出可作为另外一个线程的输入，而不必借用文件、数据库、网络连接等其他数据交换中介。

PipedOutputStream相当于生产者，其生产的产品是字节形式的数据：PipedInputStream相当于消费者。PipedInputStream内部使用byte型数组维护了一个循环缓冲区（Circular Buffer），这个缓冲区相当于传输通道。在使用PipedOutputStream、PipedInputStream进行输出、输入操作前，PipedOutputStream实例和PipedInputStream实例需要建立起关联（Connect）。建立关联的PipedOutputStream实例和PipedInputStream实例就像一条输送水流的管道，管道的一端连着注水口（PipedOutputStream），另一端连着出水口（PipedInputStream）。这样，生产者所生产的数据（相当于水流）通过向PipedOutputStream实例输出（相当于向管道注水），就可以被消费者通过关联的PipedInputStream实例所读取（相当于从出水口接水）。PipedOutputStream实例和PipedInputStream实例之间的关联可以通过调用各自实例的connect方法实现，也可以通过在创建相应实例的时候将对方的实例指定为自己的构造器参数来实现。

使用PipedOutputStream和PipedInputStream时需要注意以下几点。

- PipedOutputStream和PipedInputStream适合在两个线程间使用，即适用于单生产者-单消费者的情形。在PipedOutputStream和PipedInputStream所实现的生产者-消费者模式中，产品不是一个普通的对象而是字节形式的原始数据，因此在生产者线程不止一个或者消费者线程不止一个的情况下，我们往往需要保证产品序列（字节流）的顺序性，而这可能增加代码的复杂性和额外开销，比如为保证数据的顺序性而引入额外的锁所导致的开销。另外，PipedOutputStream和PipedInputStream不宜在单线程程序中使用，因为那样可能导致无限制的等待（死锁）。
- 输出异常的处理。如果生产者线程在其执行过程中出现了不可恢复的异常，那么消费者线程就会永远也无法读取到新的数据。但是，由于消费者线程和生产者线程不是同一个线程，因此生产者线程中出现了异常，消费者线程是无法直接侦测的，即无法像单线程程序那样通过try-catch捕获异常。所以，生产者线程出现异常时需要通过某种方式“知会”相应的消费者线程，否则消费者线程可能会无限制地等待新的数据。生产者线程通常可以通过关闭PipedOutputStream实例来实现这种“知会”。

### 5.5.4 一手交钱，一手交货：双缓冲与Exchanger

缓冲（Buffering）是一种常用的数据传递技术。缓冲区相当于数据源（Source，即数据的原始提供方）与数据使用方（Sink）之间的数据容器。从这个角度来看，数据源相当于生产者，数据使用方相当于消费者。数据源所提供的数据相当于产品，而缓冲区可被看作产品的容器或者外包装。在多线程环境下，有时候我们会使用两个（或者更多）缓冲区来实现数据从数据源到数据使用方的移动。其中一个缓冲区填充满来自数据源的数据后可以被数据使用方进行“消费”，而另外一个空的（或者已经使用过的）缓冲区则用来填充来自数据源的新的数据。这里，负责填充缓冲区的是一个线程（生产者线程），而使用已填充完毕的另外一个缓冲区的则是另外一个线程（消费者线程）。因此，当消费者线程消费一个已填充的缓冲区时，另外一个缓冲区可以由生产者线程进行填充，从而实现了数据生成与消费的并发。这种缓冲技术就被称为**双缓冲**（Double Buffering）。

JDK 1.5中引入的标准库类java.util.concurrent.Exchanger可以用来实现双缓冲。Exchanger相当于一个只有两个参与方的CyclicBarrier。Exchanger.exchange(V)相当于CyclicBarrier.await()。Exchanger.exchange(V)的声明如下：

~~~java
public V exchange(V x) throws InterruptedException
~~~

其中，V是Exchanger类的类型参数，参数x和返回值相当于缓冲区。

通常，初始状态下生成者和消费者各自创建一个空的缓冲区。消费者线程执行Exchanger.exchange(V)时将参数x指定为一个空的或者已经使用过的缓冲区，生产者线程执行Exchanger.exchange(V)时将参数x指定为一个已经填充完毕的缓冲区。比照CyclicBarrier来说，生产者线程和消费者线程都执行到Exchanger.exchange(V)相当于这两个线程都到达了集合点，此时生产者线程和消费者线程各自对Exchanger.exchange(V)的调用就会返回。Exchanger.exchange(V)的返回值是对方线程执行该方法时所指定的参数x的值。

因此，Exchanger.exchange(V)的返回就造成一种生产者线程和消费者线程之间交换缓冲区（产品）的效果，即消费者线程向生产者线程提供（通过指定参数x的值）的是一个空的（或者已经使用过的）的缓冲区，而生产者线程向消费者线程提供（通过指定参数x的值）的则是一个已经填充完毕的缓冲区。

这样，生产者线程和消费者线程之间通过不断地交换缓冲区（相当于产品的容器）就实现了将生产者所生产的一个个产品传递给消费者的效果。因此，Exchanger从逻辑上可以被看作一种SynchronousQueue，其内部也不维护用于存储产品的存储空间。

在单生产者-单消费者模式中，我们可以考虑使用Exchanger作为传输通道。

### 5.5.5 一个还是一批：产品的粒度

产品的粒度是一个相对的概念。在问题规模一定的情况下，产品的粒度过细会导致产品在传输通道上的移动次数增大；产品的粒度稍微大些可以减少产品在传输通道上的移动次数，但是产品所占用的资源也随之增加。因此，产品粒度的确定是权衡产品在传输通道上的移动次数和产品所占用资源的结果。

### 5.5.6 再探线程与任务之间的关系

## 5.6 对不起，打扰一下：线程中断机制



# 第6章 保障线程安全的设计技术

## 6.4 我有我地盘：线程持有对象

如果多个线程需要共享同一个非线程安全对象，那么我们往往需要借助锁来保障线程安全。事实上，我们也可以选择不共享非线程安全对象——对于一个非线程安全对象，每个线程都创建一个该对象的实例，各个线程仅访问各自创建的实例，且一个线程不能访问另外一个线程创建的实例。这种各个线程创建各自的实例，一个实例只能被一个线程访问的对象就被称为**线程特有对象**（TSO，Thread Specific Object），相对应的线程就被称为该线程特有对象的**持有线程**。线程特有对象既保障了对非线程安全对象的访问的线程安全，又避免了锁的开销。另外，对于特定类型的线程特有对象，一个线程往往只需要该对象的一个实例，这个实例可以被该线程（同一个线程）所执行的多个方法（包括不同类的方法）共享，因此线程持有对象也有利于减少对象的创建次数。线程持有对象可能是有状态对象，但是由于这个对象并不会被多个线程共享，因此线程特有对象也具有固有的线程安全性。

`ThreadLocal<T>`类相当于线程访问其线程特有对象的代理（Proxy），即各个线程通过这个对象可以创建并访问各自的线程特有对象，其类型参数T指定了相应线程特有对象的类型。一个线程可以使用不同的ThreadLocal实例来创建并访问其不同的线程特有对象。多个线程使用同一个`ThreadLocal<T>`实例所访问到的对象是类型T的不同实例，即这些线程各自的线程特有对象实例。因此，ThreadLocal类也可以理解为当前线程访问其线程特有对象的代理对象，这种代理与被代理的关系如图6-2所示

~~~mermaid
graph LR
	subgraph ThreadLocal1
		n11(.)
		n12(.)
		n13(.)
	end
	subgraph ThreadLocal2
		n21(.)
		n22(.)
		n23(.)
	end
	线程1-->n11-.->tsoX1
	线程1-->n21-.->tsoY1
	线程2-->n12-.->tsoX2
	线程2-->n22-.->tsoY2
	线程3-->n13-.->tsoX3
	线程3-->n23-.->tsoY3
~~~

从图6-2可以看出，ThreadLocal实例为每个访问它的线程（即当前线程）都关联了一个该线程的线程特有对象。换句话说，每个`ThreadLocal<T>`实例都有一个（且只有一个）当前线程的持有对象T的实例与之关联，这种关联关系就像一个变量总是有一个（且只有一个）值与之关联一样（尽量变量的值是可以改变的），因此ThreadLocal实例也被称为**线程局部变量**（Thread-local Variable）。ThreadLocal类的方法如表6-1所示。

| 方法                       | 功能                                                         |
| -------------------------- | ------------------------------------------------------------ |
| public T get()             | 获取与该线程局部变量关联的当前线程的线程特有对象             |
| public void set(T value)   | 重新关联该线程局部变量所对应的当前线程的线程持有对象         |
| protected T initialValue() | 该方法的返回值（对象）就是初始状态下该线程局部变量所对应的当前线程的线程特有对象 |
| public void remove()       | 删除该线程局部变量与相应的当前线程的线程特有对象之间的关联关系 |

设tlVar为任意一个线程局部变量。初始状态下，tlVar并没有与之关联的线程特有对象。当一个线程初次执行tlVar.get()的时候，tlVar.get()会调用tlVar.initialValue()。tlVar.initialValue()的返回值就会成为tlVar所关联的当前线程（即tlVar.get()的执行线程）的线程特有对象。这个线程后续再次执行 tlVar.get() 所返回的线程特有对象始终都是同一个对象（即tlVar.initialValue()的返回值），除非这个线程中途执行了tlVar.set(T)。由于ThreadLocal的initialValue方法的返回值为null，因此要设置线程局部变量关联的初始线程特有对象。我们需要创建ThreadLocal的子类（通常是匿名子类）并在子类中覆盖（Override）initialValue方法，然后在该方法中返回初始线程特有对象。从Java 8开始，ThreadLocal 引入了一个名为withInitial的静态方法，该方法使得我们能够用一个Lambda表达式（返回值）作为相应线程局部变量所关联的初始线程特有对象。例如，清单6-7中的线程局部变量SDF的初始值可写作`ThreadLocal.withInitial(()->new SimpleDateFormat("yyyy-MM-dd"))`。

使用ThreadLocal，我们可以将清单6-5中的非线程安全Servlet改造成线程安全的，如清单6-7所示。在这个例子中，ThreadLocal不仅使我们在无须借助锁的情况下实现了线程安全，还减少了对象创建的次数——doPost方法的各个执行线程各自仅创建各自的一个SimpleDateFormat实例。相反，如果我们直接在doPost方法中创建并使用SimpleDateFormat实例的话固然可以确保线程安全，但是那样就意味着每次执行doPost方法都会导致新的SimpleDateFormat实例被创建。

~~~java
public class ServletWithThreadLocal extends HttpServlet {
    final static ThreadLocal<SimpleDateFormat> SDF = new ThreadLocal<SimpleDateFormat>() {
        @Override
        protected SimpleDateFormat initialValue() {
            return new SimpleDateFormat("yyyy-MM-dd");
        }
    };
    
    @Override
    protected void doPost(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        final SimpleDateFormat sdf = SDF.get();
        String strExpiryDate = req.getParameter("expirtyDate");
        try (PrintWriter pwr = resp.getWritter()) {
            sdf.parse(strExpiryDate);
            // 省略其他代码
            pwr.printf("[%s]expirtyDate:%s", Thread.currentThread().getName(), strExpiryDate);
        } catch (ParseException e) {
            throw new ServletException(e);
        } // try结束
    }
}
~~~

线程局部变量通常是会被声明为某个类的静态变量，正如清单6-7所示。这是因为：如果把线程局部变量声明为某个类的实例变量，那么每创建该类的一个实例都会导致新的ThreadLocal实例被创建。这就可能导致当前线程中同一个类型的线程持有对象会被多次创建。而这即便不会导致错误，也会导致重复创建对象带来的浪费。

> **注意**
>
> ThreadLocal实例通常会被作为某个类的静态字段使用。

由于线程安全的对象内部往往需要使用锁，因此，多个线程共享线程安全的对象可能导致锁的争用。所以，有时候为了避免锁的争用导致的开销（主要是上下文切换），我们也特意将线程安全的对象作为线程特有对象来使用，从而避免了锁的开销，又减少了对象创建的次数。

JDK 1.7中引入的标准库类java.util.concurrent.ThreadLocalRandom的初衷与该案例所要实现的目标相似。ThreadLocalRandom也是Random的一个子类，它相当于`ThreadLocal<Random>`。不过，ThreadLocalRandom所产生的随机数并非强随机数。

### 6.4.1 线程特有对象可能导致的问题及其规避

使用线程特有对象可能会导致如下几个问题：

- 退化与数据错乱。由于线程和任务之间可以是一对多的关系，即一个线程可以先后执行多个任务，因此线程特有对象就相当于一个线程所执行的多个任务之间的共享对象。如果线程持有对象是个有状态对象且其状态会随着相应线程所执行的任务而改变，那么这个线程所执行的下一个任务可能“看到”来自前一个任务的数据，而这个数据可能与该任务并不匹配，从而导致数据错乱。因此，在一个线程可以执行多个任务的情况下（比如在生产者-消费者模式中）使用线程特有对象，我们需要确保每个任务的处理逻辑被执行前相应的线程特有对象的状态不受前一个被执行的任务影响。这通常可以通过在任务处理逻辑被执行前为线程局部变量重新关联一个线程特有对象（通过调用ThreadLocal.set(T)实现）或者重置线程特有对象的状态来实现。例如，清单6-9中的XAbstractTask子类的多个实例可以由一个线程负责执行（比如使用第5章的TaskRunner来执行，代码参见清单5-14），因此我们在preRun方法中将线程特有对象HashMap的内容清空，以避免前一个任务（XAbstratTask子类实例）执行时更改了线程特有对象的状态对当前执行的任务造成影响。从清单6-9中可以看出，在线程可以被重复使用来执行多个任务的情况下使用线程特有对象即使不会造成数据错乱，也可能导致这种线程特有对象实际上“退化”成为任务特有对象——被执行的任务可能更改了线程特有对象的状态，而这些状态一旦对其他任务可见又可能导致数据错乱，因此每个任务实际上需要的是状态会受该任务影响并且独立于其他任务的一个对象。

  ~~~java
  public abstract class XAbstractTask implements Runnable {
      static ThreadLocal<HashMap<String, String>> configHolder = new ThreadLocal<HashMap<String, String>>() {
          @Override
          protected HashMap<String, String> initialValue() {
              return new HashMap<String, String>();
          }
      };
      
      // 该方法总是会在任务处理逻辑被执行前执行
      protected void preRun() {
          // 清空线程持有对象HashMap实例，以保证每个任务执行前HashMap的内容是“干净”的
          configHolder.get().clear();
      }
      
      protected void postRun() {
          // 什么也不做
      }
      
      // 暴露给子类用于实现任务处理逻辑
      protected abstract void doRun();
      
      @Override
      public final void run() {
          try {
              preRun();
              doRun();
          } finally {
              postRun();
          }
      }
  }
  ~~~

- ThreadLocal可能导致内存泄漏、伪内存泄漏。在Web应用中使用ThreadLocal极易导致内存泄漏、伪内存泄漏的问题。下面以Tomcat服务器环境为例分析ThreadLocal可能导致内存泄漏、伪内存泄漏的原因，并在此基础上给出规避措施。

  > **内存泄漏**（Memory Leak）指由于对象永远无法被垃圾回收导致其占用的Java虚拟机内存无法被释放。持续的内存泄漏会导致Java虚拟机可用内存逐渐减少，并最终可能导致Java虚拟机内存溢出（Out of Memory），直到Java虚拟机宕机。
  >
  > **伪内存泄漏**（Memory Pseudo-leak）类似于内存泄漏。所不同的是，伪内存泄漏中对象所占用的内存在其不再被使用后的相当长时间仍然无法被回收，甚至可能永远无法被回收。也就是说，伪内存泄漏中对象占用的内存空间可能会被回收，也可能永远无法被回收（此时，就变成了内存泄漏）。

我们先简单了解一下ThreadLocal的内部实现机制。在Java平台中，每个线程（Thread实例）内部会维护一个类似HashMap的对象，我们称之为ThreadLocalMap。每个ThreadLocalMap内部会包含若干Entry（条目，一个键Key-值Value对）。因此，我们可以说每个线程都拥有若干这样的条目，相应的线程就被称为这些条目的**属主线程**。Entry的Key是一个ThreadLocal实例，Value是一个线程特有对象。因此，Entry的作用相当于为其属主线程建立起一个ThreadLocal实例与一个线程特有对象之间的对应关系。由于Entry对ThreadLocal实例的引用（通过Key引用）是一个弱引用（Weak Reference），因此它不会阻止被引用的ThreadLocal实例被垃圾回收。当一个ThreadLocal实例没有对其可达的（Reachable）强引用时，这个实例可以被垃圾回收，即其所在的Entry的Key会被置为null。此时，相应的Entry就成为**无效条目**（State Entry）。另一方面，由于Entry对线程特有对象的引用是强引用，因此如果无效条目本身有对它的可达强引用，那么无效条目也会阻止其引用的线程特有对象被垃圾回收。有鉴于此，当ThreadLocalMap中有新的ThreadLocal到线程特有对象的映射（对应）关系被创建（相当于有新的Entry被添加到ThreadLocalMap）的时候，ThreadLocalMap会将无效条目清理掉，这打破了无效条目对线程特有对象的强引用，从而使相应的线程特有对象能够被垃圾回收。但是，这个处理也有一个缺点——一个线程访问过线程局部变量之后如果该线程有对其可达的强引用，并且该线程在相当长时间内（甚至一直）处于非运行状态，那么该线程的ThreadLocalMap可能就不会有任何变化，因此相应的ThreadLocalMap中的无效条目也不会被清理，这就可能导致这些线程的各个Entry所引用的线程特有对象都无法被垃圾回收，即导致了伪内存泄漏。

线程对象对ThreadLocal和线程特有对象的引用关系如图6-3所示（图中虚线表示弱引用，实线表示强引用）。

~~~mermaid
graph LR
	Thread --threadLocals--> ThreadLocalMap --entries--> Entry -.Key.-> ThreadLocal
	Entry --Value--> TSO
~~~

清单6-10展示了一个使用ThreadLocal并可能导致内存泄漏的Servlet。

~~~java
/**
 * 该类可能导致内存泄漏！
 */
@WebServlet("/memoryLeak")
public class ThreadLocalMemoryLeak extends HttpServlet {
    private static final long serialVersionUID = 4364376277297114653L;
    final static ThreadLocal<Counter> counterHolder = new ThreadLocal<Counter>(){
        @Override
        protected Counter initialValue() {
            Counter tsoCounter = new Counter();
            return tsoCounter;
        }
    };
    
    @Override
    protected void doGet(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        doProcess(req, resp);
        try (PrintWriter pwr = resp.getWriter()) {
            pwr.printf("Thread %s, counter:%d",
                      Thread.currentThread().getName(),
                      countHolder.get().getAndIncrement());
        }
    }
    
    void doProcess(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException {
        counterHolder.get().getAndIncrement();
        // 省略其他代码
    }
}

// 非线程安全
class Counter {
    private int i = 0;
    public int getAndIncrement() {
        return i++;
    }
}
~~~

在Tomcat环境下，Web应用自身定义的类（Custom Class）由类加载器（Class Loader）WebAppClassLoader负责加载，而Java标准库类（例如HashMap）由类加载器StandardClassLoader负责加载。每个类（类本身也是一种对象）都会持有对加载该类的类加载器的强引用，并且类加载器本身又会持有其加载过的所有类的强引用。另外，每个对象（实例）都会持有对其相应类的强引用。由于Servlet类ThreadLocalMemoryLeak及其使用的线程持有对象Counter类都是由WebAppClassLoader负责加载的，并且counterHolder（`ThreadLocal<Counter>`）是ThreadLocalMemoryLeak的一个静态字段，因此我们可以得出图6-4所示的引用关系（图中实线表示强引用）。

~~~mermaid
graph TB
	tsoCounter[tsoCounter:线程持有对象Counter] --class--> Counter[Counter:Web应用自定义类] --> WebAppClassLoader
	subgraph t
		WebAppClassLoader[WebAppClassLoader:类加载器] --loadedClasses--> ThreadLocalMemoryLeak[ThreadLocalMemoryLeak:Servlet子类] --静态变量--> countHolder[countHolder:线程局部变量]
	end
~~~

由图6-4中可以看出，由Web应用自身定义的线程特有对象（tsoCounter）特有对线程局部变量（counterHolder）的可达利用。并且线程（对象）又持有对其线程特有对象的可达引用（如图6-3所示），因此，结合图6-3、图6-4中的引用关系可知，此时线程（对象）不仅持有了对其线程特有对象的可达强引用（见图6-4）。所以，只要系统中还存在对这个线程对象的可达强引用，即线程本身没有被垃圾回收掉，那么这个线程访问过的所有线程局部变量以及相应的线程特有对象都不会被垃圾回收掉！由于Tomcat中的一个工作者线程（负责调用Servlet.service方法进行请求处理，service方法最终会调用doXXX方法）可以为多个Web应用服务，因此当ThreadLocalMemoryLeak所在的Web应用被停止的时候（不是Web服务器被停止）执行过ThreadLocalMemoryLeak.service方法的工作者线程并不会被停止，故而这些线程对象并不会被垃圾回收掉，进而使其所引用的所有线程局部变量及相应的线程特有对象并不会被垃圾回收掉，即导致了内存泄漏。进一步来说，此时的内存泄漏还会导致与当前Web应用相应的类加载器WebAppClassLoader所加载的所有类（以及这些类的静态变量所引用的所有对象）都无法被垃圾回收，而这最终可能导致Java虚拟机的非堆内存（Non-heap）空间中的永久代（Permanent Generation， Java 8 中它被元数据空间 Metaspace 所取代）内存溢出（Out of memory），即Java虚拟机会抛出java.lang.OutOfMemoryError(具体消息为“PermGen space”)。所幸的是，Apache Tomcat以及IBM WebSphere Application Server都提供了一套内存泄漏的检查机制以及一定程度的自动规避机制（不过，我们最好不要依赖于这种自动规避机制）。

如果线程局部变量关联的线程特有对象是一个Java标准库类（如清单6-7所使用的java.text.SimpleDateSimple）实例，那么由于Java 标准库类是由类加载器StandardClassLoader加载的，StandardClassLoader并不会持有对应用自身定义的类（ThreadLocalMemoryLeak）的引用，因此图6-4所示的引用关系中虚线框中的引用关系并不存在，即导致上述内存泄漏的前提不满足。所以，线程局部变量关联的线程特有对象类型如果是 Java 标准库类，那么它并不会导致内存泄漏。但是，由于图6-3中的引用关系——线程（对象）持有对线程特有对象（TSO）的可达强引用，因此只要相应的线程（对象）没有被垃圾回收掉，那么相应的线程特有对象也不会被垃圾回收掉。可见，这种情况下，线程局部变量可能导致伪内存泄漏。

由于ThreadLocal可能导致内存泄漏、伪内存泄漏的最小前提是线程（对象）持有对线程特有对象的可达强引用（见图6-3中的实线所表示的引用关系）。因此，我们只要打破这种引用，即通过在当前线程中调用ThreadLocal.remove()将线程特有对象从其所属的Entry中剥离（清理），便可以使线程特有对象以及线程局部变量都可以被垃圾回收。如果我们仅仅是打破线程特有对象对ThreadLocal的引用关系（如图6-4所示），那么只有线程局部变量可以被垃圾回收，而伪内存泄漏仍然存在，即线程特有对象可能仍然无法被垃圾回收。

对于同一个ThreadLocal实例，ThreadLocal.remove()能够奏效的前提是，其执行线程与ThreadLocal.get()/set(T) 的执行线程必须是同一个线程。由于ThreadLocal.get()/remove()/set(T) 这几个方法都是针对当前线程（即这些方法的执行线程）的，因此即使是针对同一个ThreadLocal实例，我们也无法通过在一个线程中调用ThreadLocal.remove()来将另外一个线程的线程特有对象从所属的Entry中剥离。换而言之，我们无法通过在一个线程中执行ThreadLocal.remove()来规避另外一个线程因使用ThreadLocal而导致的伪内存泄漏！

在Web应用中使用线程特有对象可能导致线程持有对象的“退化”：在上述例子中，为了避免ThreadLocal导致的伪内存泄漏（或内存泄漏），我们在每个请求处理结束后都将该请求的处理线程的线程特有对象（Counter实例）清理掉。因此，不同的请求即使是先后由同一个（任意的）服务器工作者线程来负责处理的，这个（任意的）线程每次执行ThreadLocalMemoryLeak.doGet方法（以对请求进行处理）的时候都会创建新的Counter实例。这就意味着：首先，不同的服务器工作者线程不会访问相同的Counter实例，即Counter实例不会被多个服务器工作者线程共享，这说明该例子对Counter的使用方式（线程局部变量）与直接将Counter实例定义为一个静态变量（`final static Counter COUNTER = new Counter();`）还是不同的。其次，这些服务器工作者线程所访问的线程特有对象（Counter实例）实际上已“退化”成“请求特有对象”——每一个请求都对应一个Counter实例。

### 6.4.2 线程特有对象的典型应用场景

典型应用场景如下。

- **场景一** 需要使用非线程安全对象，但又不希望因此而引入锁。如果多个线程需要使用非线程安全的对象，而我们又不希望该对象被多个线程共享（因为共享往往意味着需要引入锁以保证线程安全），此时可以使用线程特有对象，使得各个线程拥有其特有的非线程安全对象实例。
- **场景二** 使用线程安全对象，但希望避免其使用的锁的开销和相关问题。线程安全的对象虽然可以被多个线程共享，但是由于其可能使用了锁来保证线程安全，而某些情况下我们可能不希望看到锁的开销以及由锁可能引起的相关问题（如死锁）。此时，我们可以将线程安全对象当作非线程安全的对象来看待。因此，这种场景就转化成场景一。只不过此时使用线程特有对象的主要意图在于避免锁的开销，当然线程安全也是由保障的。
- **场景三** 隐式参数传递（Implicit Parameter Passing）。线程特有对象在一个具体的线程中，它是线程全局可见的。一个类的方法中设置的线程特有对象对于该方法调用的任何其他方法（包括其他类的方法）都是可见的。这就可以形成隐式传递参数的效果，即一个类的方法调用另一个类的方法时，前者向后者传递数据可以借助ThreadLocal而不必通过方法参数传递。不过，也有的观点认为隐式参数传递使得系统难于理解。隐式参数传递的实现通常是使用一个只包括静态方法的类或者单例类（包装类）来封装对线程特有对象的访问，其他相应访问线程特有对象的代码只需要调用包装类的静态方法或者实例方法即可以访问线程特有对象。
- **场景四** 特定于线程的单例（Singleton）模式。广为使用的单例模式所实现的效果是在一个Java虚拟机中的一个类加载器下某个类有且只有一个实例。如果我们希望对于某个类每个线程有且仅有该类的一个实例，那么就可以使用线程持有对象。

## 6.5 装饰器模式

# 第8章 线程管理

本章之前的内容我们更加注重的是如何利用线程“做到”我们想要做的事情，而本章的重点则在于如何“做得更好”。在本章中我们会介绍多线程编程实战中所面临以及需要关注的一些重要问题，并提出相应的解决方案。这些问题主要包括：线程在其运行过程中一旦抛出了未捕获异常，我们如何得知并应对的可靠性问题；如何将线程的创建与配置（比如设置线程的优先级）以一种统一的方式管控起来；如何提高线程这种宝贵资源的利用率的问题。

## 8.1 线程组

线程组（ThreadGroup类）可以用来表示一组相似（相关）的线程。线程与线程组之间的关系类似于文件与文件夹之间的关系——一个文件总是位于特定的文件夹之中，而一个文件夹可以包含多个文件以及其他文件夹。类似地，一个线程组可以包含多个线程以及其他线程组。一个线程组包含其他线程组的时候，该线程组被称为这些线程组的**父线程组**。Thread类有几个构造器允许我们在创建线程的时候指定线程所属的线程组。如果创建线程的时候我们没有指定线程组，那么这个线程就属于其父线程（即当前线程）所属的线程组。由于Java虚拟机在创建main线程（Java平台中所有线程的父线程）时会为其指定一个线程组，因此Java平台中的任何一个线程都有一个线程组与之关联，这个线程组可以通过Thread.getThreadGroup()调用来获取。

ThreadGroup最初是出于安全的考虑被设计用来隔离（区分）不同的Applet的。然而，ThreadGroup并未实现这一预期目标，并且它所实现的许多方法是有缺陷的，另外这些方法也不是很常用。一些遗留（Legacy）系统中可能还存在对ThreadGroup的使用。在新开发的系统中，如果我们需要将一些线程归结为一组，那么可以考虑简单的办法：将这些线程存入一个数组或者集合对象中，当然这样处理可能需要注意内存泄漏问题。如果仅仅是为了将一些线程与另外一些线程区分开来，那么也可以使用线程名称的命名规则来实现。

> **提示**
>
> 多数情况下，我们可以忽略线程组这一概念以及线程组的存在。

## 8.2 可靠性：线程的未捕获异常与监控

如果线程的run方法抛出未被捕获的异常（Uncaught Exception），那么随着run方法的退出，相应的线程也提前终止。对于线程的这种异常终止，我们如何得知并做出可能的补救动作，例如重新创建并启动一个替代线程呢？JDK 1.5 为了解决这个问题引入了UncaughtExceptionHandler接口。该接口是在Thread类内部定义的，它只定义了一个方法：

~~~java
void uncaughtException(Thread t, Throwable e)
~~~

uncaughtException方法中两个参数包括了异常终止的线程本身（对应第1个参数）以及导致线程提前终止的异常（对应第2个参数）。那么，在 uncaughtException 方法当中我们就可以做一些有意义的事情，比如将线程异常终止的相关信息记录到日志文件中，甚至于为异常终止的线程创建并启动一个替代线程。设thread为任意一个线程，eh为任意一个 UncaughtExceptionHandler 示例，那么我们可以在启动thread前通过调用 thread.setUncaughtExceptionHandler(eh) 来为 thread 关联一个UncaughtExceptionHandler。当 thread 抛出未被捕获的异常后 thread.run() 返回，接着 thread 会在其终止前调用 eh.uncaughtException 方法。

清单8-1展示了一个利用 UncaughtExceptionHandler 实现线程监控的例子。在这个例子中，系统的某个重要服务（ThreadMonitorDemo）内部维护了一个工作者线程（WorkerThread用于实现该服务的核心功能）。因此，一旦这个工作者线程由于某些未捕获的异常（比如NullPointerException）而提前终止，那么我们需要在第一时间得到“通知”，并为该线程创建并启动一个替代线程来接替其完成其任务，以保障该服务的可靠性。这个接替的过程就是通过 UncaughtExceptionHandler 实现的：ThreadMonitor.uncaughtException方法会重新将工作者线程的启动标记init置为false，并再次调用init方法来创建并启动一个新的工作者线程，用于接替异常终止的工作者线程。

~~~java
public class ThreadMonitorDemo {
    volatile boolean inited = false;
    static int threadIndex = 0;
    final static Logger LOGGER = Logger.getAnonymousLogger();
    final BlockingQueue<String> channel = new ArrayBlockingQueue<String>(100);
    
    public static void main(String[] args) throws InterruptedException {
        ThreadMonitorDemo demo = new ThreadMonitorDemo();
        demo.init();
        for(int i = 0; i < 100; i++){
            demo.service("test-"+i);
        }
        Thread.sleep(2000);
        System.exit(0);
    }
    
    public synchronized void init() {
        if(inited){
            return;
        }
        Debug.info("init...");
        WorkerThread t = new WorkerThread();
        t.setName("Worker0-"+threadIndex++);
        // 为线程t关联一个UncaughtExceptionHandler
        t.setUncaughtExceptionHandler(new ThreadMonitor());
        t.start();
        inited = true;
    }
    
    public void service(String message) throws InterruptedException {
        channel.put(message);
    }
    
    private class ThreadMonitor implements Thread.UncaughtExceptionHandler {
        @Override
        public void uncaughtException(Thread t, Throwable e) {
            Debug.info("Current thread is `t`:%s, it is still alive:%s", Thread.currentThread() == t, t.isAlive());
            
            // 将线程异常终止的相关信息记录到日志中
            String threadInfo = t.getName();
            LOGGER.log(Level.SEVERE, threadInfo + " terminated:", e);
            
            // 创建并启动替代线程
            LOGGER.info("About to restart " + threadInfo);
            // 重置线程启动标记
            inited = false;
            init();
        }
    } // 类ThreadMonitor定义结束
    
    private class WorkerThread extends Thread {
        @Override
        public void run() {
            Debug.info("Do something important...");
            String msg;
            try {
                for (;;) {
                    msg = channel.take();
                    process(msg);
                }
            } catch (InterruptedException e) {
                // 什么也不做
            }
        }
        
        private void process(String message) {
            Debug.info(message);
            // 模拟随机性异常
            if ((int) (Math.random() * 100) < 2) {
                throw new RuntimeException("test");
            }
            Tools.randomPause(100);
        }
    } // 类ThreadMonitorDemo定义结束
}
~~~

线程组本身也实现了 UncaughtExceptionHandler接口。如果一个线程没有关联的 UncaughtExceptionHandler 实例，那么该线程异常终止前其所属线程组的uncaughtException 方法会被调用。线程组的 uncaughtException 方法会调用其父线程组的 uncaughtException 方法会调用其父线程组的 uncaughtException 方法并传递同样的两个参数（t 和 e）。如果一个线程组没有其父线程组（只有最顶层的线程组没有其父线程组，因此一个Java虚拟机中只有一个线程组没有其父线程组），那么线程组的 uncaughtException 方法会调用默认 UncaughtExceptionHandler 的 uncaughtException 方法来处理线程的异常终止。默认UncaughtExceptionHandler 适用于所有线程，即任何一个线程异常终止时默认 UncaughtExceptionHandler 都可能会被调用。 Thread.setDefaultUncaughtExceptionHandler 方法可用来指定默认 UncaughtExceptionHandler。针对一个线程的异常终止，该线程所关联的UncaughtExceptionHandler实例、该线程所在的线程组以及默认UncaughtExceptionHandler之中只有一个UncaughtExceptionHandler实例会被选中。UncaughtExceptionHandler实例的选择优先级如图8-1所示.

~~~mermaid
graph BT
	first(最先考虑 - 线程关联的UncaughtExceptionHandler)--> tg(线程所在的线程组)
	tg --> final(最后考虑 - 默认UncaughtExceptionHandler)
~~~

清单8-2 展示了默认 UncaughtExceptionHandler在Web应用中的使用。在该例子中，我们先在 ServletContextListener.contextInitialized 方法中设置了默认 UncaughtExceptionHandler，接着再启动该Web应用所需的若干工作者线程。该默认 UncaughtExceptionHandler 对线程异常终止的处理仅仅是将抛出异常的线程的相关信息记录到日志文件中。当然，如果有特别的需要，我们也可以在该 UncaughtExceptionHandler 中向告警子系统发送相关告警信息，甚至发送相关的短信。

~~~java
public class AppListener implements ServletContextListener {
    final static Logger LOGGER = Logger.getAnonymousLogger();
    
    @Override
    public void contextInitialized(ServletContextEvent contextEvent) {
        // 设置默认 UncaughtExceptionHandler
        UncaughtExceptionHandler ueh = new LoggingUncaughtExceptionHandler();
        Thread.setDefaultUncaughtExceptionHandler(ueh);
        
        // 启动若干工作者线程
        startServices();
    }
    
    static class LoggingUncaughtExceptionHandler implements UncaughtExceptionHandler {
        @Override
        public void uncaughtException(Thread t, Throwable e) {
            String threadInfo = "Thread[" + t.getName() + "," + t.getId() + "," + t.getThreadGroup().getName() + ",@" + t.hashCode() + "]";
            
            // 将线程异常终止的相关信息记录到日志中
            LOGGER.log(Level.SEVERE, threadInfo + " terminated:", e);
        }
    }
    
    protected void startServices() {
        // 省略其他代码
    }
    
    protected void stopServices() {
        // 省略其他代码
    }
    
    @Override
    public void contextDestroyed(ServletContextEvent contextEvent) {
        Thread.setDefaultUncaughtExceptionHandler(null);
        stopServices();
    }
}
~~~



## 8.3 有组织有纪律：线程工厂

从JDK 1.5开始，Java标准库本身就支持创建线程的工厂方法（Factory Method）。ThreadFactory 接口是工厂方法模式的一个实例，它定义了如下工厂方法：

~~~java
public Thread newThread(Runnable r)
~~~

newThread方法可以用来创建线程，该方法的参数r代表所创建的线程需要执行的任务。如果把线程对象看作某种“产品”，那么通过new方式创建线程就好比手工制作，而使用 ThreadFactory 接口创建线程则好比是工厂采用标准化的流水线进行生产。我们可以在 ThreadFactory.newThread 方法中封装线程创建的逻辑，这使得我们能够以统一的方式为线程创建、配置做一些非常有用的动作。

在如清单8-3所示的例子中，ThreadFactory实现类XThreadFactory的newThread方法为其创建的每一个线程做了这样一些列的处理逻辑：为线程关联UncaughtExceptionHandler, 为线程设置一个含义更加具体的有助于问题定位的名称，确保线程是一个用户线程，确保线程的优先级为正常级别，以及在线程创建的时候打印相关日志信息。并且，这些线程的 toString() 返回值更加有利于问题的定位——在对真实的（商用）多线程系统中的问题进行定位的过程中，将一个线程与另外一个线程区分开来非常有助于问题的定位，线程ID以及线程对象的身份标识（Hash Code）是将一个线程与另外一个线程区分开来的重要依据，而Thread.toString() 的返回值并没有体现这一点。可见XThreadFactory不仅仅是为我们提供了一个新的线程，它还为这个线程做了一些有利于简化客户端代码以及有利于代码调试和问题定位的动作。

~~~java
public class XThreadFactory implements ThreadFactory {
    final static Logger LOGGER = Logger.getAnonymousLogger();
    private final UncaughtExceptionHandler ueh;
    private final AtomicInteger threadNumber = new AtomicInteger(1);
    // 所创建的线程的线程名前缀
    private final String namePrefix;
    
    public XThreadFactory(UncaughtExceptionHandler ueh, String name) {
        this.ueh = ueh;
        this.namePrefix = name;
    }
    // ...
    public XThreadFactory() {
        this(new LoggingUncaughtExceptionHandler(), "thread");
    }
    
    protected Thread doMakeThread(final Runnable r) {
        return new Thread(r) {
            @Override
            public String toString() {
                // 返回对问题定位更加有益的信息
                ThreadGroup group = getThreadGroup();
                String groupName = null == group ? "" : group.getName();
                String threadInfo = getClass().getSimpleName() + "[" + getName() + "," + getId() + "," + groupName + "]@" + hashCode();
                return threadInfo;
            }
        };
    }
    
    @Override
    public Thread newThread(Runnable r) {
        Thread t = doMakeThread(r);
        t.setUncaughtExceptionHandler(ueh);
        t.setName(namePrefix + "-" + threadNumber.getAndIncrement());
        if (t.isDaemon()) {
            t.setDaemon(false);
        }
        if (t.getPriority() != Thread.NORM_PRIORITY) {
            t.setPriority(Thread.NORM_PRIORITY);
        }
        if (LOGGER.isLoggable(Level.FINE)) {
            LOGGER.fine("new thread created" + t);
        }
        return t;
    }
    
    static class LoggingUncaughtExceptionHandler implements UncaughtExceptionHandler {
        @Override
        public void uncaughtException(Thread t, Throwable e) {
            // 将线程异常终止的相关信息记录到日志中
            LOGGER.log(Level.SEVERE, t + " terminated:", e);
        }
    } // LoggingUncaughtExceptionHandler类定义结束
}
~~~

## 8.4 线程的暂挂与恢复

Thread.suspend()、Thread.resume()这两个方法都是已废弃的方法。其作用分别是暂挂线程和恢复线程。

## 8.5 线程的高效利用：线程池

线程是一种昂贵的资源，其开销主要包括以下几个方面。

- 线程的创建与启动的开销。与普通的对象相比，Java线程还占用了额外的存储空间——栈空间。并且，线程的启动会产生相应的线程调度开销。
- 线程的销毁。线程的销毁也有其开销。
- 线程调度的开销。线程的调度会导致上下文切换，从而增加处理器资源的消耗，使得应用程序本身可以使用的处理器资源减少。
- 一个系统能够创建的线程总是受限于该系统所拥有的处理器数目。无论是CPU密集型还是I/O密集型线程，这些线程的数量的临界值总是处理器的数目。

因此，从整个系统乃至整个主机的角度来看我们需要一种有效使用线程的方式。线程池就是有效使用线程的一种常见方式。

常见的对象池（比如数据库连接池）的实现方式是对象池（本身也是个对象）内部维护一定数量的对象，客户端代码需要一个对象的时候就向对象池申请（借用）一个对象，用完之后再将对象返还给对象池，于是对象池中的一个对象就可以先后为多个客户端线程服务。线程池本身也是一个对象，不过它的实现方式与普通的对象池不同，如图8-2所示：线程池内部可以预先创建一定数量的工作者线程，客户端代码并不需要向线程池借用线程而是将其需要执行的任务作为一个对象提交给线程池，线程池可能将这些任务缓存在队列（工作队列）之中，而线程池内部的各个工作者线程则不断地从队列中取出任务并执行之。因此，线程池可以被看作基于生产者-消费者模式的一种服务，该服务内部维护的工作者线程相当于消费者线程，线程池的客户端线程相当于生产者线程，客户端代码提交给线程池的任务相当于“产品”，线程池内部用于缓存任务的队列相当于传输通道。

~~~mermaid
graph TB
	任务 --提交--> 工作队列
	subgraph 线程池
		工作队列 --取出任务--> t1((工作者线程1))
		工作队列 --> t2((工作者线程2))
		工作队列 --> t3((工作者线程3))
	end
~~~

java.util.concurrent.ThreadPoolExecutor 类就是一个线程池，客户端代码可以调用 ThreadPoolExecutor.submit 方法向其提交任务，ThreadPoolExecutor.submit 方法声明如下：

~~~java
public Future<?> submit(Runnable task)
~~~

其中，task参数是一个Runnable实例，它代表客户端需要线程池代为执行的任务。为便于讨论，这里我们先忽略该方法的返回值。

线程池内部维护的工作者线程的数量就被称为该线程池的**线程池大小**（Pool Size）。ThreadPoolExecutor 的线程池大小由3种形态：当前线程池大小（Current Pool Size）表示线程池中实际工作者线程的数量；最大线程池大小（Maximum Pool Size）表示线程池中允许存在的工作者线程的数量上限，其具体取值可参考第4章的式（4-5）；核心线程大小（Core Pool Size）表示一个不大于最大线程池大小的工作者线程数量上限。它们之间的数量关系如下：

当前线程池大小 <= 核心线程池大小 <= 最大线程池大小

或 核心线程池大小 <= 当前线程池大小 <= 最大线程池大小

这里，除了当前线程池大小是对线程池中现有的工作者线程进行计数的结果，其他有关线程池大小的概念实际上都是由开发人员或者系统配置数据指定的一个阈值（Threshold）。这些阈值的具体含义下文会介绍。

ThreadPoolExecutor的构造器中包含参数数量最多的一个构造器的声明如下：

~~~java
public ThreadPoolExecutor(int corePoolSize,
                         int maximumPoolSize,
                         long keepAliveTime,
                         TimeUnit unit,
                         BlockingQueue<Runnable> workQueue,
                         ThreadFactory threadFactory,
                         RejectedExecutionHandler handler)
~~~

其中，workQueue是被称为**工作队列**的阻塞队列，它相当于生产者-消费者模式中传输通道，corePoolSize用于指定线程池核心大小，maximumPoolSize用于指定最大线程池大小。keepAliveTime 和 unit 合在一起用于指定线程池中空闲（Idle）线程的最大存活时间。threadFactory指定用于创建工作者线程的线程工厂。handler参数下面会介绍。

在初始状态下，客户端每提交一个任务线程池就创建一个工作者线程来处理该任务。随着客户端不断地提交任务，当前线程池大小也相应增加。在当前线程池大小达到核心线程池大小的时候，新来的任务会被存入工作队列之中。这些缓存的任务由线程池中的所有工作者线程负责取出进行执行。线程池将任务存入工作队列的时候调用的是BlockingQueue的非阻塞方法offer(E e)，因此工作队列满并不会使提交任务的客户端线程暂停。当工作队列满的时候，线程池会继续创建新的工作者线程，直到当前线程池大小达到最大线程池大小。线程池是通过调用threadFactory.newThread方法来创建工作者线程的。如果我们在创建线程池的时候没有指定线程工厂（即调用了ThreadPoolExecutor的其他构造器），那么ThreadPoolExecutor会使用Executors.defaultThreadFactory()所返回的默认线程工厂。当**线程池饱和**（Saturated）时，即工作者队列满并且当前线程池大小达到最大线程池大小的情况下，客户端试图提交的任务会被**拒绝**（Reject）。为了提高线程池的可靠性，Java标准库引入了一个RejectedExecutionHandler接口用于封装被拒绝任务的处理策略，该接口仅定义了如下方法：

~~~java
void rejectExecution(Runnable r, ThreadPoolExecutor executor)
~~~

其中，r代表被拒绝的任务，executor代表拒绝任务r的线程池实例。我们可以通过线程池的构造器参数handler或者线程池的setRejectedExecutionHandler(RejectedExecutionHandler handler)方法来为线程池关联一个RejectedExecutionHandler。当客户端提交的任务被拒绝时，线程池所关联的RejectedExecutionHandler的rejectedExecution方法会被线程池调用。ThreadPoolExecutor自身提供了几个现成的RejectedExecutionHandler接口实现类（见表8-1），其中ThreadPoolExecutor.AbortPolicy是ThreadPoolExecutor使用的默认RejectedExecutionHandler。如果默认的RejectedExecutionHandler（它会直接抛出异常）无法满足要求，那么我们可以优先考虑ThreadPoolExecutor自身提供的其他RejectedExecutionHandler，其次才去考虑使用自行实现的RejectedExecutionHandler接口。

| 实现类                                 | 所实现的处理策略                                         |
| -------------------------------------- | -------------------------------------------------------- |
| ThreadPoolExecutor.AbortPolicy         | 直接抛出异常                                             |
| ThreadPoolExecutor.DiscardPolicy       | 丢弃当前被拒绝的任务（而不抛出任何异常）                 |
| ThreadPoolExecutor.DiscardOldestPolicy | 将工作队列中最老的任务丢弃，然后重新尝试接纳被拒绝的任务 |
| ThreadPoolExecutor.CallerRunsPolicy    | 在客户端线程中执行被拒绝的任务                           |

在当前线程池大小超过线程池核心大小的时候，超过线程池核心大小部分的工作者线程空闲（即工作者队列中没有待处理的任务）时间达到keepAliveTime所指定的时间后就会被清理掉，即这些工作者线程会自动终止并被从线程池中移除。这种空闲线程清理机制有利于节约有限的线程资源，但是keepAliveTime值设置不合理（特别是设置得太小）可能导致工作者线程频繁地被清理和创建反而增加了开销！

线程池中数量上等于核心线程池大小的那部分工作者线程，习惯上我们称之为**核心线程**（Core Thread）。如前文所述，当前线程池大小是随着线程池接收到的任务的数量而逐渐向核心线程池大小靠拢的，即核心线程是逐渐被创建与启动的。ThreadPoolExecutor.prestartAllCoreThreads()则使得我们可以使线程池在未接收到任何任务的情况下预先创建并启动所有核心线程，这样可以减少任务被线程池处理时所需的等待时间（等待核心线程的创建与启动）。

ThreadPoolExecutor.shutdown()/shutdownNow()方法可用来关闭线程池。使用shutdown()关闭线程池的时候，已提交的任务会被继续执行，而新提交的任务会像线程池饱和时那样被拒绝掉。ThreadPoolExecutor.shutdown()返回的时候线程池可能尚未关闭，即线程池中可能还有工作者线程正在执行任务。应用代码可以通过调用ThreadPoolExecutor.shutdownNow()关闭线程池的时候，正在执行的任务会被停止，已提交而等待执行的任务也不会被执行。该方法的返回值已提交而未被执行的任务列表，这为被取消的任务的重试提供了一个机会。由于ThreadPoolExecutor.shutdownNow()内部是通过调用工作者线程的interrupt方法来停止正在执行的任务的，因此某些无法响应中断的任务可能永远也不会停止。反过来说，在关闭线程池的时候如果我们能够确保已经提交的任务都已执行完毕并且没有新的任务会被提交，那么调用ThreadPoolExecutor.shutdownNow()总是安全可靠的。

### 8.5.1 任务的处理结果、异常处理与取消

如果客户端关心任务的处理结果，那么它可以使用ThreadPoolExecutor的另外一个submit方法来提交任务，该submit方法的声明如下：

~~~java
public <T> Future<T> submit(Callable<T> task)
~~~

task参数代表客户端需要提交的任务，其类型为java.util.concurrent.Callable。Callable接口定义的唯一方法声明如下：

~~~java
V call() throws Exception
~~~

Callable接口也是对任务的抽象：任务的处理逻辑可以在Callable接口实现类的call方法中实现。Callable接口相当于一个增强型的Runnable接口：call方法的返回值代表相应任务的处理结果，其类型V是通过Callable接口的类型参数指定的；call方法代表的任务在其执行过程中可以抛出异常。而Runnable接口中的run方法既无返回值也不能抛出异常。Executors.callable(Runnable task, T result)能够将Runnable接口转换为Callable接口实例。

上述submit方法的返回值类型为java.util.concurrent.Future。Future接口实例可被看作提交给线程池执行的任务的处理结果句柄（Handle），Future.get()方法可以用来获取task参数所指定的任务的处理结果，该方法声明如下：

~~~java
V get() throws InterruptedException, ExecutionException
~~~

Future.get()被调用时，如果相应的任务尚未执行完毕，那么Future.get()会使当前线程暂停，直到相应的任务执行结束（包括正常结束和抛出异常而终止）。因此，Future.get()是个阻塞方法，该方法能够抛出InterruptedException说明它可以响应线程中断。另外，假设相应的任务执行过程中抛出一个任意的异常originalException，那么Future.get()方法本身就会抛出相应的ExecutionException异常。调用这个异常（ExecutionException）的getCause()方法可返回originalException。因此，客户端代码可以捕获Future.get()调用抛出的异常来知晓相应任务执行过程中抛出的异常。

由于在任务未执行完毕的情况下调用Future.get()方法来获取该任务的处理结果会导致等待并由此导致上下文切换，因此客户端代码应该尽可能早地向线程池提交任务，并尽可能晚地调用Future.get()方法来获取任务的处理结果，而线程池则正在利用这段时间来执行已提交的任务（包括我们关心的任务）。

> **注意**
>
> 客户端代码应该尽可能早地向线程池提交任务，并仅在需要相应任务的处理结果数据的那一刻才调用Future.get()方法。

Future接口还支持任务的取消。为此，Future接口定义了如下方法：

~~~java
boolean cancel(boolean mayInterruptIfRunning)
~~~

该方法的返回值表示相应的任务取消是否成功。任务取消失败的原因包括取消的任务已执行完毕或者正在执行、已经被取消以及其他无法取消因素。参数mayInterruptIfRunning表示是否允许通过给相应任务的执行线程发送中断来取消任务。Future.isCancelled()返回值代表相应的任务是否被成功取消。由于一个任务被成功取消之后，相应的Future.get()调用会抛出CancellationException异常（运行时异常），因此如果任务有可能会被取消，那么在获取任务的处理结果之前，我们需要先判断任务是否已经被取消了。

Future.isDone() 方法可以检测相应的任务是否执行完毕。任务执行完毕、执行过程中抛出异常以及任务被取消都会导致该方法返回true。

Future.get()会使其执行线程无限制地等待，直到相应的任务执行结束。商用系统中这种无时间限制的等待往往是不现实的。此时我们可以使用get方法的另外一个版本，其声明如下：

~~~java
V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException
~~~

该方法的作用与Future.get()相同，不过它允许我们指定一个等待超时时间。如果在该时间内相应的任务未执行结束，那么该方法就会抛出TimeoutException。由于该方法参数种指定的超时时间仅仅用于控制客户端线程（即该方法的执行线程）等待相应任务的处理结果最多会等待多长时间，而非响应任务本身的执行时间限制，因此，客户端线程通常需要在捕获TimeoutException之后执行Future.cancel(true)来取消相应任务的执行（因为此时我们已经不再需要该任务的处理结果了）。

### 8.5.2 线程池监控

尽管线程池的大小、工作队列的容量、线程空闲时间限制这些线程池的属性可通过配置的方式进行指定（而不是硬编码在代码中），但是所指定的值是否恰当则需要通过监控来判断。例如，如果我们选择有界队列作为工作队列，那么这个队列的容量以多少为宜呢，这需要在软件测试过程中对线程池进行监控来确实。另外，考虑到测试环境和软件实际允许环境总是存在差别的，出于软件运维的考虑我们也可能需要对线程池进行监控。ThreadPoolExecutor类提供了对线程池进行监控的相关方法，如表8-2所示。

| 方法                    | 用途                                                         |
| ----------------------- | ------------------------------------------------------------ |
| getPoolSize()           | 获取当前线程池大小                                           |
| getQueue()              | 返回工作队列实例，通过该实例可获取工作队列的当前大小         |
| getLargestPoolSize()    | 获取工作者线程曾经达到的最大数，该数值有助于确认线程池的最大大小设置是否合理 |
| getActiveCount()        | 获取线程池中当前正在执行任务的工作者线程数（近似值）         |
| getTaskCount()          | 获取线程池到目前为止所接收到的任务数（近似值）               |
| getCompletedTaskCount() | 获取线程池到目前为止已经处理完毕的任务数（近似值）           |

此外，ThreadPoolExecutor提供的两个钩子方法（Hook Method）：beforeExecute(Thread t, Runnable r) 和 afterExecute(Thread t, Runnable r)也能够用于实现监控。设executor为任意一个ThreadPoolExecutor实例，在任意一个任务r被线程池executor中的任意一个工作者线程t执行前，executor.beforeExecute(t, r)会被执行；当t执行完r之后，不管r的执行是否成功的还是抛出了异常，executor.afterExecute(t, r)始终会被执行。因此，如果有必要的话我们可以通过创建ThreadPoolExecutor的子类并在子类的beforeExecute/afterExecute方法实现监控逻辑，比如计算任务执行的平均耗时。

### 8.5.3 线程池死锁

如果线程池中执行的任务在其执行过程中又会向同一个线程池提交另外一个任务，而前一个任务的执行结束又依赖于后一个任务的执行结果，那么就有可能出现这样的情形：线程池中的所有工作者线程都处于等待其他任务的处理结果而这些任务仍在工作队列中等待执行，这时由于线程池中已经没有可以对工作队列中的任务进行处理的工作者线程，这种等待就会一直持续下去从而形成死锁（Deadlock）。

因此，适合提交给同一线程池实例执行的任务是相互独立的任务，而不是彼此有依赖关系的任务。对于彼此存在依赖关系的任务，我们可以考虑分别使用不同的线程池实例来执行这些任务。

> **注意**
>
> 同一个线程池只能用于执行相互独立的任务。彼此有依赖关系的任务需要提交给不同的线程池执行以避免死锁。

### 8.5.4 工作者线程的异常终止

如果任务是通过ThreadPoolExecutor.submit调用提交给线程池的，那么这些任务在其执行过程中即便是抛出了未捕获的异常也不会导致对其进行执行的工作者线程异常终止。当然，上文我们已经介绍过这种情形下任务所抛出的异常可以通过Future.get()所抛出的ExecutionException来获取。

如果任务是通过ThreadPoolExecutor.execute方法提交给线程池的，那么这些任务在其执行过程中一旦抛出了未捕获的异常，则对其进行执行的工作者线程就会异常终止。尽管ThreadPoolExecutor能够侦测到这种情况并在工作者线程异常终止的时候创建并启动新的替代工作者线程，但是由于线程的创建与启动都有其开销，因此这种情形下我们会尽力避免任务在其执行过程中抛出未捕获的异常。我们可以通过ThreadPoolExecutor的构造器参数或者ThreadPoolExecutor.setThreadFactory方法为线程池关联一个线程工厂。在这个线程工厂里面我们可以为其创建的工作者线程关联一个UncaughtExceptionHandler，通过这个关联的UncaughtExceptionHandler我们可以侦测到任务执行过程中抛出的未捕获异常。不过，由于ThreadPoolExecutor内部实现的原因，只有通过ThreadPoolExecutor.execute调用（而不是ThreadPoolExecutor.submit调用）提交给线程池执行的任务，其执行过程中抛出的未捕获异常才会导致UncaughtExceptionHandler.uncaughtException方法被调用。

> **注意**
>
> 通过ThreadPoolExecutor.submit调用提交给线程池执行的任务，其执行过程中抛出的未捕获异常并不会导致与该线程池中的工作者线程所关联的UncaughtExceptionHandler的uncaughtException方法被调用。

# 第9章 Java异步编程

## 9.1 同步计算与异步计算

从多个任务的角度来看，任务可以是串行执行的，也可以是并发执行的。从单个任务的角度来看，任务的执行方式可以是同步的（Synchronous），也可以是异步的（Asynchronous）。这里的同步与线程同步机制中的“同步”不是同一个概念。

以同步方式执行的任务，我们称之为**同步任务**，其任务的发起与任务的执行是在同一条时间线上进行的。换而言之，任务的发起与任务的执行是串行的。同步任务就好比我们以电话的形式将一个消息通知给朋友的情形：我们先拨打对方的号码（任务的发起）。只有在电话接通（任务开始执行）之后我们才能够将消息告诉对方（任务执行的过程）。

以异步方式执行的任务，我们称之为**异步任务**，其任务的发起与任务的执行是在不同的时间线上进行的。换而言之，任务的发起与执行是并发的。异步任务好比我们以短信的形式将一个消息通知给朋友的情形：我们只要给对方发送一条短信（任务的发起）便认为已经通知到对方了，而不必关心对方何时阅读这条短信，而实际上对方可能在第二天阅读这条短信（任务开始执行）。

同步方式与异步方式的说法是相对的：同一个任务我们既可以说它是异步任务，也可以说它是同步任务。假设我们用一个Runnable实例task来表示一个任务，如果我们直接调用task.run()来执行该任务，那么我们就可以称该任务为同步任务；如果我们通过 new Thread(task).start() 调用创建并启动一个专门的工作者线程来执行该任务，或者将该任务提交给一个Executor实例executor执行（即调用executor.execute(task）），那么我们就可以称该任务为异步任务。同步方式与异步方式的称呼不仅仅取决于一个任务的具体执行方式，还取决于我们的观察角度。在上述例子中，假设我们将task提交给线程池执行，那么从该任务提交线程（即ThreadPoolExecutor.submit方法的执行线程）的角度来看它是一个异步任务，而从线程池中的工作者线程（即实际执行该任务的线程）的角度来看该任务则可能是一个同步任务。

同步任务的发起线程在其发起该任务之后必须等待该任务执行结束才能够执行其他操作，这种等待往往意味着阻塞（Blocking），即任务的发起线程会被暂停，直到任务执行结束。

例如，直接通过InputStream.read()读取一个文件中的内容就是一个同步任务，在InputStream.read()调用返回数据前该任务的发起线程会被暂停。同步任务也并不一定总是使其发起线程被阻塞，同步线程的发起线程也可能以轮询的方式来等待任务的结束。所谓**轮询**（Polling）是指任务的发起线程不断地检查其发起的任务是否执行结束，若任务已执行结束则执行下一步操作，否则继续检查任务，直至该任务完成。阻塞意味着在同步任务执行结束前，该任务的发起线程并没有在运行（其生命周期状态不为RUNNABLE），而轮询意味着在同步任务执行结束前，该任务的发起线程仍然在运行，只不过此时该线程的主要动作是检查相应的任务是否执行结束。同步任务的发起线程是采用阻塞的方式还是轮询方式来等待任务的结束很大程度上取决于我们使用的API。例如，使用java.nio.channels.Selector类来编写网络应用程序的服务端代码的时候，我们能够采用轮询的方式来实现等待同步任务的结束，而多数情况下我们只能够以阻塞方式来实现等待同步任务的结束。单个线程便可以实现同步任务的执行。在使用单个线程的情况下，多个同步任务只能够以同步的方式执行。

异步任务的发起线程在其发起该任务之后不必等待该任务结束便可以继续执行其他操作，即异步任务的发起与实际执行可以是并发的。多线程编程本质上是异步的。比如一个线程通过`ThreadPoolExecutor.submit(Callable<T>)`调用向线程池提交一个任务（任务的发起），在该调用返回之后该线程便可以执行其他操作了，而该任务可能在此之后才被线程池中的某一个工作者线程所执行，这里任务的提交与执行是并发的，而不是串行的。可见，异步任务可以使其发起线程不必因等待其执行结束而被阻塞，即异步任务执行方式往往意味着非阻塞（Non-blocking）。然而，阻塞与非阻塞只是任务执行方式的一种属性，它与任务执行方式之间并没有必然的关系：同步任务执行方式多数情况下意味着阻塞，但是它也可能意味着非阻塞（轮询）；异步任务执行方式多数情况下意味着非阻塞，但是他也可能意味着阻塞。例如，如果我们在向线程池提交一个任务之后立刻调用Future.get()来试图获取该任务的处理结果(即ThreadPoolExecutor.submit(someTask).get())，那么尽管该任务是异步执行的，但是其发起线程仍然可能由于Future.get()调用时该任务尚未被线程池执行结束而被阻塞。异步任务的执行需要借助多个线程来实现。多个异步任务能够以并发的方式被执行。

> **注意**
>
> - 阻塞与非阻塞只是任务执行方式（同步/异步）本身的一种属性，它们与任务执行方式之间并未有必然的联系：异步任务既可能是非阻塞的，也可能是阻塞的；同步任务即可能是阻塞的，也可能是非阻塞的。
> - 同步方式与异步方式的说法是相对的，它取决于任务的执行方式以及我们的观察角度。

同步方式的优点是代码简单、直观，缺点是它往往意味着阻塞，而阻塞会限制系统的吞吐率。异步方式往往意味着非阻塞，因而有利于提高系统的吞吐率。异步方式的代价是更为复杂的代码和更多的资源投入。例如，以异步方式执行任务需要借助额外的工作者线程，并且还需要对这些工作者线程进行管理（启动、停止等）。

## 9.2 Java Executor框架

Runnable接口和Callable接口都是对任务处理逻辑的抽象，这种抽象使得我们无须关心任务的具体处理逻辑：不管是什么样的任务，其处理逻辑总是展现为一个具有统一签名的方法——Runnable.run()或者Callable.call()。java.util.concurrent.Executor接口则是对任务的执行进行的抽象，该接口仅定义了如下方法：

~~~java
void execute(Runnable command)
~~~

其中，command参数代表需要执行的任务。Executor接口使得任务的提交方（相当于生产者）只需要知道它调用Executor.execute方法便可以使指定的任务被执行，而无须关心任务具体的执行细节：比如，任务是采用一个专门的工作者线程执行的，还是采用线程池执行的；采用什么样的线程池执行的；多个任务是以何种顺序被执行的。可见，Executor接口使得任务的提交能够与任务执行的具体细节解耦（Decoupling）。和对任务处理逻辑的抽象类似，对任务执行的抽象也能给我们带来信息隐藏（Information）和关注点分离（Separation Of Concern）的好处。

解耦任务的提交与任务的具体执行细节所带来的好处的一个例子是，它在一定程度上能够屏蔽任务同步执行与异步执行的差异。这个任务不管是同步执行还是异步执行，对于其提交方来说并没有太大差别，这就为更改任务的具体执行方式提供了灵活性和便利：更改任务的具体执行细节可能不会影响到任务的提交方，而这意味着更小的代码改动量和测试量。

~~~java
public class SynchronousExecutor implements Executor {
    @Override
    public void execute(Runnable command) {
        command.run();
    }
}
~~~

可见，Executor接口一定程度上缩小了同步编程与异步编程的代码编写方式。

Executor接口比较简单，功能也十分有限：首先，它只能为客户端代码执行任务，而无法将任务的处理结果返回给客户端代码；其次，Executor接口实现类内部往往会维护一些工作者线程，当我们不再需要一个Executor实例的时候，往往需要主动将该实例内部维护的工作者线程停掉以释放相应的资源，而Executor接口并没定义相应的方法。

ExecutorService接口继承自Executor接口，它解决了上述问题。ExecutorService接口定义了几个submit方法，这些方法能够接受Callable接口或者Runnable接口表示的任务并返回相应的Future实例，从而使客户端代码提交任务后可以获取任务的执行结果。ExecutorService接口还定义了shutdown()方法和shutdownNow()方法来关闭相应的服务（比如关闭其维护的工作者线程）。ThreadPoolExecutor是ExecutorService的默认实现类。

### 9.2.1 实用工具类Executors

第8章我们已经介绍到实用工具类java.util.concurrent.Executors，它除了能够返回默认线程工厂（Executors.defaultThreadFactory()）、能够将Runnable实例转换为Callable实例（Executors.callable方法）之外，还提供了一些能够返回ExecutorService实例的快捷方法，如表9-1所示。这些ExecutorService实例往往使我们在不必手动创建ThreadPoolExecutor实例的情况下使用线程池。

| 方法                                                         | 适用条件及注意实现                                           |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| public static ExecutorService newCachedThreadPool()          | 适合用于执行大量耗时较短且提交比较频繁的任务。如果提交的任务执行耗时较长，那么可能导致线程池中的工作者线程无限制地增加，最后导致过多的上下文切换，从而使得整个系统变慢 |
| public static ExecutorService newCachedThreadPool(ThreadFactory threadFactory) | 同上                                                         |
| public static ExecutorService newFixedThreadPool(int nThreads) | 由于该方法返回的线程池的核心线程池大小等于其最大线程池大小，因此该线程池中的工作者线程永远不会超时。我们必须在不再需要该线程池时主动将其关闭 |
| public static ExecutorService newFixedThreadPool(int nThreads, ThreadFactory threadFactory) | 同上                                                         |
| public static ExecutorService newSingleThreadExecutor()      | 适合用来实现单（多）生产者-单消费者模式。该方法的返回值无法被转换为ThreadPoolExecutor类型 |
| public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) | 同上                                                         |

- Executors.newCachedThreadPool()。该方法的返回值相当于：

  ~~~java
  new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue<Runnable>());
  ~~~

  即一个核心线程池大小为0，最大线程池大小不受限，工作者线程允许的最大空闲时间（keepAliveTime）为60秒，内部以SynchronousQueue为工作队列（以下称之为workQueue）的一个线程池。这种配置意味着该线程池中的所有工作者线程在空闲了指定的时间后都可以被自动清理掉。由于该线程池的核心线程池大小为0，因此提交给该线程池执行的第一个任务会导致该线程池中的第一个工作者线程被创建并启动。后续继续给该线程池提交任务的时候，由于当前线程池大小已经超过核心线程池大小（0），因此ThreadPoolExecutor此时会将任务缓存到工作队列之中（即调用workerQueue.offer方法）。

  SynchronousQueue内部并不维护用于存储队列元素的实际存储空间。一个线程（生产者线程）在执行SynchronousQueue.offer(E)的时候，如果没有其他线程（消费者线程）因执行SynchronousQueue.take()而被暂停，那么SynchronousQueue.offer(E)调用会直接返回false，即入队列失败。因此，在该线程池中的所有工作者线程都在执行任务，即无空闲工作者线程的情况下给其提交任务会导致该任务无法被缓存成功。而ThreadPoolExecutor在任务缓存失败且线程池当前大小未达到最大线程池大小（这里的最大线程池大小实际相当于不限）的情况下会创建并启动新的工作者线程。在极端情况下，给该线程池每提交一个任务都会导致一个新的工作者线程被创建并启动，而这最终会导致系统中的线程过多，从而导致过多的上下文切换而使得整个系统被拖慢。因此，Executors.newCachedThreadPool()所返回的线程池适合于用来执行大量耗时较短且提交频率较高的任务。而提交频率较高且耗时较长的任务（尤其是包含阻塞操作的任务）则不适合用Executors.newCachedThreadPool()所返回的线程池来执行。

- Executors.newFixedThreadPool(int nThreads)。该方法的返回值相当于

  ~~~java
  new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<Runnable>());
  ~~~

  即一个以无界队列为工作队列，核心线程池大小与最大线程池大小均为nThreads且线程池中的空闲工作者线程不会被自动清理的线程池，这是一种线程池大小一旦达到其核心线程池大小就既不会增加也不会减少工作者线程的固定大小的线程池。因此，这样的线程池实例一旦不再需要，我们必须主动将其关闭。

- Executors.newSingleThreadExecutor()。该方法的返回值基本相当于Executors.newFixedThreadPoll(1)所返回的线程池。不过，该线程池并非ThreadPoolExecutor实例，而是一个封装了ThreadPoolExecutor实例且对外仅暴露ExecutorService接口所定义的方法的一个ExecutorService实例。该线程池便于我们实现单（多）生产者-单消费者模式。该线程池确保了在任意一个时刻只有一个任务会被执行，这就形成了类似锁将原本并发的操作改为串行的操作的效果。因此，该线程池适合于用来执行访问了非线程安全对象而我们又不希望因此而引入锁的任务。该线程池也适合于用来执行I/O操作，因为I/O操作往往受限于相应的I/O设备，使用多个线程执行同一种I/O操作（比如多个线程各自读取一个文件）可能并不会提高I/O效率，所以如果使用一个线程执行I/O足以满足要求，那么仅使用一个线程即可，这样可以保障程序的简单性以避免一些不必要的问题（比如死锁）。

### 9.2.2 异步任务的批量执行：CompletionService

尽管Future接口使得我们能够方便地获取异步任务的处理结果，但是如果需要一次性提交一批异步任务并获取这些任务的处理结果的话，那么仅使用Future接口写出来的代码将颇为烦琐。java.util.concurrent.CompletionService接口为异步任务的批量提交以及获取这些任务的处理结果提供了便利。

CompletionService接口定义的一个submit方法可用于提交异步任务，该方法的签名与ThreadPoolExecutor的一个submit方法相同：

~~~java
Future<V> submit(Callable<V> task)
~~~

task参数代表待执行的异步任务，该方法的返回值可用于获取相应异步任务的处理结果。如果是批量提交异步任务，那么通常我们并不关心该方法的返回值。若要获取批量提交的异步任务的处理结果，那么我们可以使用CompletionService接口专门为此定义的方法，其中的一个方法是：

~~~java
Future<V> take() throws InterruptedException
~~~

该方法与Blocking Queue.take()相似，它是一个阻塞方法，其返回值是一个已经执行结束的异步任务对应的Future实例，该实例就是提交相应任务时`submit(Callable<V>)`调用的返回值。如果take()被调用时没有已执行结束的异步任务，那么take()的执行线程就会被暂停，直到有异步任务执行结束。因此，我们批量提交了多少个异步任务，则多少次连续调用CompletionService.take()便可以获取这些任务的处理结果。

CompletionService也定义了两个非阻塞方法用于获取异步任务的处理结果：

~~~java
Future<V> poll()
Future<V> poll(long timeout, TimeUnit unit) throws InterruptedException
~~~

这两个方法与BlockingQueue的poll方法相似，它们的返回值是已执行结束的异步任务对应的Future实例。

Java标准库提供的CompletionService接口的实现类是ExecutorCompletionService。ExecutorCompletionService的一个构造器是：

~~~java
ExecutorCompletionService(Executor executor, BlockingQueue<Future<V>> completionQueue)
~~~

由此可见，ExecutorCompletionService相当于Executor实例与BlockingQueue实例的一个融合体。其中，Executor实例负责接收并执行异步任务，而BlockingQueue实例则用于存储已执行完毕的异步任务对应的Future实例。ExecutorCompletionService会为其客户端提交的每个异步任务（Callable实例或者Runnable实例）都创建一个相应的Future实例，通过该实例其客户端代码便可以获取相应异步任务的处理结果。ExecutorCompletionService每执行完一个异步任务，就将该任务对应的Future实例存入其内部维护的BlockingQueue实例之中，而其客户端代码则可以通过ExecutorCompletionService.take()调用来获取这个Future实例。

使用ExecutorCompletionService的另外一个构造器ExecutorCompletionService(Executor executor)创建实例相当于：

~~~java
new ExecutorCompletionService<V>(executor, new LinkedBlockingQueue<Future<V>>());
~~~

`ExecutorService.invokeAll(Collection<? extends Callable<T>> tasks)`也能够用来批量提交异步任务，该方法能够并发执行tasks参数所指定的一批任务，但是该方法只有在tasks参数所指定的一批任务中的所有任务都执行结束之后才返回，其返回值是一个包含各个任务对应的Future实例的列表（List）。因此，使用invokeAll方法提交批量任务的时候，任务提交方等待invokeAll方法返回的时间取决于这批任务中最耗时的任务的执行耗时。

## 9.3 异步计算助手：FutureTask

无论是Runnable实例还是Callable实例所表示的任务，只要我们将其提交给线程池执行，那么这些任务就是异步任务。采用Runnable实例来表示异步任务，其优点是任务既可以交给一个专门的工作者线程执行（以相应的Runnable实例为参数创建并启动一个工作者线程），也可以交给一个线程池或者Executor的其他实现类来执行；其缺点是我们无法直接获取任务的执行结果。使用Callable实例来表示异步任务，其优点是我们可以通过`ThreadPoolExecutor.submit(Callable<T>)`的返回值获取任务的处理结果；其缺点是Callable实例表示的异步任务只能交给线程池执行，而无法直接交给一个专门的工作者线程或者Executor实现类执行。因此，使用Callable实例来表示异步任务会使任务执行方式的灵活性大为受限。

java.util.concurrent.FutureTask类则融合了Runnable接口和Callable接口的优点：FutureTask是Runnable接口的一个实现类，因此FutureTask表示的异步任务可以交给专门的工作者线程执行，也可以交给Executor实例（比如线程池）执行；FutureTask还能够直接返回其代表的异步任务的处理结果。`ThreadPoolExecutor.submit(Callable<T> task)`的返回值就是一个FutureTask实例。FutureTask是java.util.concurrent.RunnableFuture接口的一个既是Runnable接口的实现类也是Future接口的实现。FutureTask的一个构造器可以将Callable实例转换为Runnable实例，该构造器的声明如下：

~~~java
public FutureTask(Callable<V> callable)
~~~

该构造器使得我们能够方便地创建一个能够返回处理结果的异步任务。我们可以将任务的处理逻辑封装在一个Callable实例中，并以该实例为参数创建一个FutureTask实例。由于FutureTask类实现了Runnable接口，因此上述构造器的作用就相当于将Callable实例转换为Runnable实例，而FutureTask实例本身也代表了我们要执行的任务。我们可以用FutureTask实例（Runnable实例）为参数来创建并启动一个工作者线程以执行相应的任务，也可以将FutureTask实例交给Executor执行（通过Executor.execute(Runnable task)调用）。FutureTask类还实现了Future接口，这使得我们在调用Executor.execute(Runnable task)这样只认Runnable接口的方法来执行任务的情况下依然能够获取任务的执行结果：一个工作者线程（可以是线程池中的一个工作者线程）负责调用FutureTask.run()执行相应的任务，另外一个线程则调用FutureTask.get()来获取任务的执行结果。因此，FutureTask实例可被看作一个异步任务，它使得任务的执行和对任务执行结果的处理得以并发执行，从而有利于提高系统的并发性。

`ThreadPoolExecutor.submit(Callable<T> task)`方法继承自`AbstractExecutorService.submit(Callable<T> task)`。`AbstractExecutorService.submit(Callable<T> task)`内部实现就是借助FutureTask的，如图9-2所示，submit方法会根据指定的Callable实例task创建一个FutureTask实例ftask，并通过Executor.execute(Runnable)调用异步执行task所代表的任务，然后返回ftask，以便该方法的调用方能够获取任务的执行结果。

~~~java
public <T> Future<T> submit(Callable<T> task) {
    if (task == null) throw new NullPointerException();
    RunnableFuture<T> ftask = newTaskFor(task);
    execute(task);
    return ftask;
}
~~~

FutureTask还支持以回调（Callback）的方式处理任务的执行结果。当FutureTask实例所代表的任务执行结束后，FutureTask.done()会被执行。FutureTask.done()是个protected方法，FutureTask子类可以覆盖该方法并在其中实现对任务执行结果的处理。FutureTask.done()中的代码可以通过FutureTask.get()调用来获取任务的执行结果，此时由于任务已经执行结束，因此FutureTask.get()调用并不会使得当前线程暂停。但是，由于任务的执行结束既包括正常终止，也包括异常终止以及任务被取消而导致的终止，因此FutureTask.done()方法中的代码可能需要在调用FutureTask.get()前调用FutureTask.isCancelled()来判断任务是否被取消，以免FutureTask.get()调用抛出CancellationException异常（运行时异常），如清单9-3所示。

### 9.3.1 实践：实现XML文档的异步解析

FutureTask的使用既可以发挥异步编程的好处，又可以在一定程度上屏蔽同步编程与异步编程之间的差异，这简化了代码。

### 9.3.2 可重复执行的异步任务

# 第12章 Java多线程程序的性能调校

## 12.1 Java虚拟机对内部锁的优化

自 Java6/Java7 开始，Java虚拟机对内部锁的实现进行了一些优化。这些优化主要包括锁消除（Lock Elision）、锁粗化（Lock Coarsening）、偏向锁（Biased Locking）以及适应性锁（Adaptive Locking）。这些优化仅在Java虚拟机server模式下起作用。

### 12.1.1 锁消除

锁消除（Lock Elision）是JIT编译器对内部锁的具体实现所做的一种优化，如下所示。（IBM J9 Java虚拟机也支持该优化）

~~~java
// 待编译字节码的等效代码
synchronized(monitor){
    doSomething;
}
// 有且仅有一个线程会执行这段代码
↓
// 编译后的机器码的等效代码
doSomething();
~~~

在动态编译同步块的时候，JIT编译器可以借助一种被称为逃逸分析（Escape Analysis）的技术来判断同步块所使用的锁对象是否能够被一个线程访问而没有被发布到其他线程。如果同步块所使用的锁对象通过这种分析被证实只能够被一个线程访问，那么JIT编译器在编译这个同步块的时候并不生成synchronized所表示的锁的申请与释放对应的机器码，而仅生成原临界区代码对应的机器码，这就造成了被动态编译的字节码就像是不包含monitorenter（申请锁）和monitorexit（释放锁）这两个字节码指令一样，即消除了锁的使用。这种编译器优化就被称为锁消除（Lock Elision），它使得特定情况下我们可以完全消除锁的开销。

Java标准库中的有些类（比如StringBuffer）虽然是线程安全的，但是在实际使用中我们往往不在多个线程间共享这些类的实例。而这些类在实现线程安全的时候往往借助于内部锁。因此，这些类是锁消除优化的常见目标。如清单12-1所示的例子中，JIT编译器在编译 toJSON 方法的时候会将其调用的 StringBuffer.append/toString 方法内联（Inline）到该方法之中，这相当于把 StringBuffer.append/toString 方法的方法体中的指令复制到toJSON的方法体中。这里的StringBuffer实例sbf是一个局部变量，并且该变量所引用的对象并没有被发布到其他线程，因此 sbf 引用的对象只能够被 sbf 所在的方法（toJSON方法）的当前执行线程（一个线程）访问。所以，JIT编译器此时可以消除toJSON方法中从 StringBuffer.append/toString 方法的方法体复制的指令所使用的内部锁。在这个例子中，StringBuffer.append/toString 方法本身所使用的锁并不会被消除，因为系统中可能还有其他地方在使用StringBuffer, 而这些代码可能会共享 StringBuffer 实例。

~~~java
// 清单12-1 可进行锁消除优化的示例代码
public class LockElisionExample {
    public static String toJSON(ProductInfo productInfo){
        StringBuffer sbf = new StringBuffer();
        sbf.append("{\"productID\":\"}").append(productInfo.productID);
        sbf.append("\",\"categoryID\":\"").append(productInfo.categoryID);
        sbf.append("\",\"rank\":\"").append(productInfo.rank);
        sbf.append("\",\"inventory\":\"").append(productInfo.inventory);
        sbf.append("\"}");
        
        return sbf.toString();
    }
}
~~~

锁消除优化所依赖的逃逸分析技术自Java SE 6u23起默认是开启的，但是锁消除优化是在Java 7开始引入的。（开启逃逸分析的虚拟机参数为“-XX:+DoEscapeAnalysis”, 关闭逃逸分析的虚拟机参数为“-XX:-DoEscapeAnalysis”。注意：“-XX:”开头的虚拟机参数表示相应的参数是“不稳定的”，即Oracle公司可能会在不事先通知的情况下更改甚至废弃相应的参数。）

从上述例子可以看出，锁消除优化还可能需要以JIT编译器的内联优化为前提。而一个方法是否会被JIT编译器内联取决于该方法的热度以及该方法对应的字节码的尺寸（Bytecode Size）。因此，锁消除优化能否被实施还取决于被调用的同步方法（或者带同步块的方法）是否能够被内联。

锁消除优化告诉我们在该使用锁的情况下必须使用锁，而不必过多在意锁的开销。开发人员应该在代码的逻辑层面考虑是否需要加锁，而至于代码运行层面上某个锁是否真的有必要使用则由JIT编译器来决定。锁消除优化并不表示开发人员在编写代码的时候可以随意使用内部锁（在不需要加锁的情况下加锁），因为锁消除是JIT编译器而不是javac所做的一种优化，而一段代码只有在其被执行的频率足够大的情况下才有可能会被JIT编译器优化。也就是说在JIT编译器优化介入之前，只要源代码中使用了内部锁，那么这个锁的开销就会存在。另外，JIT编译器所执行的内联优化、逃逸分析以及锁消除优化本身都是有其开销的。

在锁消除的作用下，利用ThreadLocal将一个线程安全的对象（比如Random）作为一个线程特有对象来使用，不仅仅可以避免锁的争用，还可以彻底消除这些对象内部所使用的锁的开销。

### 12.1.2 锁粗化

锁粗化（Lock Coarsening/Lock Merging）是JIT编译器对内部锁的具体实现所做的一种优化。