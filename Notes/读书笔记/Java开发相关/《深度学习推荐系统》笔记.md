# 第1章 互联网的增长引擎——推荐系统

## 1.2 推荐系统的架构

推荐系统要处理的是“人”和“信息”的关系。这里的“信息”，在商品推荐中指的是“商品信息”，在视频推荐中指的是“视频信息”，在新闻推荐中指的是“新闻信息”，简而言之，可统称为“**物品信息**”。

而从“人”的角度触发，为了更可靠地推测出“人”的兴趣点，推荐系统希望利用大量与“人”相关的信息，包括历史行为、人口属性、关系网络等，这些可统称为“**用户信息**”。

此外，在具体的推荐场景中，用户的最终选择一般会受时间、地点、用户的状态等一系列环境信息的影响，可称为“**场景信息**”或“上下文信息”。

### 1.2.1 推荐系统的逻辑框架

在获知“用户信息”“物品信息”“场景信息”的基础上，推荐系统要处理的问题可以较形式化地定义为：对于用户U（User），在特定场景C（context）下，针对海量地“物品”信息，构建一个函数f(U,I,C)，预测用户对特定候选物品I(item)的喜好程度，再根据喜好程度对所有候选物品进行排序，生成推荐列表的问题。

### 1.2.2 数据系统的技术架构

在实际的推荐系统中，工程师需要将抽象的概念和模块具体化、工程化。在前面逻辑框架基础上，工程师需要着重解决的问题有两类。

1. **数据和信息相关的问题**，即“用户信息”“物品信息”“场景信息”分别是什么？如何存储、更新和处理？
2. **推荐系统算法和模型相关的问题**，即推荐模型如何训练、如何预测、如何达成更好的推荐效果？

可以将这两类问题分成两个部分：“数据和信息”部分逐渐发展为推荐系统中融合了数据离线批处理、实时流处理的数据流框架；“算法和模型”部分则进一步细化为推荐系统中集训练（training）、评估（evaluation）、部署（deployment）、线上推断（online inference）为一体的模型框架。

![推荐系统_推荐系统技术架构示意图](..\..\整理后的文件\推荐系统 配图\推荐系统_推荐系统技术架构示意图.png)

### 1.2.3 推荐系统的数据部分

推荐系统的数据部分主要负责“用户”“物品”“场景”的信息收集与处理。具体地讲，讲负责数据收集与处理的三种平台按照实时性的强弱排序，依次为“客户端及服务器端实时数据处理”“流处理平台准实时数据处理”“大数据平台离线数据处理”。在实时性由强到弱递减的同时，三种平台的海量数据处理能力则由弱到强。因此，一个成熟的推荐系统的数据流系统会将三者取长补短，配合使用。

得到原始的数据信息后，推荐系统的数据处理系统会将原始数据进一步加工，加工后的数据出口主要有三个：

1. 生成推荐模型所需的样本数据，用于算法模型的训练和评估。
2. 生成推荐模型服务（model serving）所需的“特征”，用于推荐系统的线上推断。
3. 生成系统监控、商业智能（Business Intelligence，BI）系统所需的统计数据。

### 1.2.4 推荐系统的模型部分

推荐系统的“模型部分”是推荐系统的主体。模型结构一般由“召回层”“排序层”“补充策略与算法层”组成。

1. “**召回层**”
   一般利用高效的召回规则、算法或简单的模型，快速从海量的候选集中召回用户可能感兴趣的物品。
2. “**排序层**”
   利用排序模型对初筛的候选集进行排序
3. “**补充策略与算法层**”
   也被称为“再排序层”，可以在将推荐列表返回用户之前，为兼顾结果的“多样性”“流行度”“新鲜度”等指标，结合一些补充的策略和算法对推荐列表进行一定的调整，最终形成用户可见的推荐列表。

从推荐模型接收到所有候选物品集，到最后产生推荐列表。这一过程一般称为模型服务过程。

在线环境进行模型服务之前，需要通过模型训练（model training）确定模型结构、结构中不同参数权重的具体数值，以及模型相关算法和策略中的参数取值。模型的训练方法又可以根据模型训练环境的不同，分为“离线训练”和“在线更新”两部分，其中：离线训练的特点是可以利用全量样本和特征，使模型逼近全局最优点；在线更新则可以准实时地“消化”新的数据样本，更快地反映新的数据变化趋势，满足模型实时性的需求。

除此之外，为了评估推荐模型的效果，方便模型的迭代优化，推荐系统的模型部分提供了“离线评估”和“线上A/B测试”等多种模块，用得出的线下和线上评估指标，指导下一步的模型迭代优化。

以上所有模块共同组成了推荐系统模型部分的技术框架。模型部分，特别是“排序层”模型是推荐系统产生效果的重点，也是业界和学界研究的重心。下面着重介绍模型部分，特别是“排序层”模型的主流技术及其演化趋势。

# 第2章 前深度学习时代——推荐系统的进化之路

在互联网永不停歇的增长需求的驱动下，推荐系统的发展可谓一日千里，从2010年之前千篇一律的**协同过滤**（Collaborative Filtering，CF）、**逻辑回归**（Logistic Regression，LR），进化到**因子分解机**（Factorization Machine, FM）、**梯度提升树**（Gradient Boosting Decision Tree, GBDT），再到2015年之后**深度学习推荐模型**的百花齐放，各种模型架构层出不穷。推荐模型的主流模型经历了**从单一模型到组合模型，从经典框架到深度学习**的发展过程。

诚然，深度学习推荐模型已经成了推荐、广告、搜索领域的主流，但前深度学习时代的推荐模型仍是十分重要的，原因如下：

1. 即使在深度学习空前流行的今天，协同过滤、逻辑回归、因子分解机等传统推荐模型仍然凭借其可解释性强、硬件环境要求低、易于快速训练和部署等不可替代的优势，拥有大量适用的应用场景。
2. 传统推荐模型是深度学习推荐模型的基础。构成深度神经网络（Deep Neural Network，DNN）的基本单元是神经元，而应用广泛的传统逻辑回归模型正式神经元的另一种表现形式；深度学习推荐模型中影响力很大的**基于因子分解机支持的神经网络**（Factorization machine supported Neural Network，FNN）、**深度因子分解机**（Deep Factorization Machine， DeepFM）、**神经网络因子分解机**（Neural Factorization Machine, NFM）等深度学习模型更是与传统的FM模型有着千丝万缕的联系。此外，在传统推荐模型训练中广泛采用的**梯度下降**等训练方式，更是沿用至深度学习时代。所以说，传统推荐模型是深度学习推荐模型的基础，也是学习的入口。

## 2.1 传统推荐模型的演化关系图

![推荐系统_传统推荐模型的演化关系图](..\..\整理后的文件\推荐系统 配图\推荐系统_传统推荐模型的演化关系图.png)

简要来说，传统推荐模型的发展脉络主要由以下几个部分组成：

1. **协同过滤算法族**（UserCF、ItemCF、MF）。
   经典的协同过滤算法曾是推荐系统的首选模型，从物品相似度和用户相似度角度出发，协同过滤衍生出物品协同过滤（ItemCF）和用户协同过滤（UserCF）两种算法。为了使协同过滤能够更好地处理稀疏共现矩阵问题、增强模型的泛化能力，从协同过滤衍生出矩阵分解模型（Matrix Factorization，MF），并发展出矩阵分解的各分支模型。
2. **逻辑回归模型族**。
   与协同过滤仅仅利用用户和物品之间的显式或隐式反馈信息相比，逻辑回归能够利用和融合更多用户、物品以及上下文特征。从LR模型衍生出的模型同样“枝繁叶茂”，包括增强了非线性能力的大规模分片线性模型（Large Scale Piece-wise Linear Model，LS-PLM），由逻辑回归发展出来的FM模型，以及与多种不同模型配合使用后的组合模型，等等。
3. **因子分解机模型族**。
   因子分解机在传统逻辑回归的基础上，加入了二阶部分，使模型具备了进行特征组合的能力。更进一步，在因子分解机基础上发展出来的域感知因子分解机（Field-aware Factorization Machine，FFM）则通过加入特征域的概念，进一步加强了因子分解机特征交叉的能力。
4. **组合模型**。
   为了融合多个模型的优点，将不同模型组合使用是构建推荐模型的常用方法。Facebook提出GBDT+LR（梯度提升决策树（Gradient Boosting Decision Tree）+逻辑回归）组合模型是在业界影响力较大的组合方式。

## 2.2 协同过滤——经典的推荐算法

### 2.2.1 什么是协同过滤

顾名思义，“协同过滤”就是协同大家的反馈、评价和意见对海量的信息进行过滤，从中筛选出目标用户可能感兴趣的信息的推荐过程。

一个电商网站场景下的协同过滤推荐过程，其推荐过程按照顺序共分为6步。

1. 电商网站的商品库里一共有4件商品：游戏机、某小说、某杂志和某品牌电视机。
2. 用户X访问该电商网站，电商网站的推荐系统需要决定是否推荐电视机给用户X。可以利用的用户数据有用户X对其他商品的历史评价数据，以及其他用户对这些商品的历史评价数据。用户、商品、评价记录构成了带有标识的有向图。
3. 为了便于计算，将有向图转换为矩阵的形式（被称为“共现矩阵”），用户作为矩阵行坐标，商品作为列坐标，将“点赞”和“踩”的用户行为数据转换为矩阵中的相应元素值。
4. 预测的第一步就是找到与用户X兴趣最相似的n（Top n用户）个用户，然后综合相似用户对“电视机”的评价，得出用户X对“电视机”评价的预测。
5. 从共现矩阵中可知，用户B和用户C由于跟用户X的行向量近似，被选为Top n(这里假设n取2)相似用户，用户B和用户C对“电视机”的评价都是负面的。
6. 相似用户对“电视机”的评价是负面的，因此可预测用户X对“电视机”的评价也是负面的。

### 2.2.2 用户相似度的计算

1. **余弦相似度**
   余弦相似度（Cosine Similarity）衡量了用户向量 $\vec i$ 和用户向量$\vec j$ 之间的夹角大小。显然，夹角越小，证明余弦相似度越大，两个用户越相似。
   $$
   sim(i,j)=cos(i,j)=\frac{i \cdot j}{||i||\cdot||j||}
   $$

2. **皮尔逊相关系数**
   相比余弦相似度，皮尔逊相关系数通过使用用户平均分对各独立评分进行修正，减少了用户评分偏置的影响。
   $$
   sim(i,j)=\frac{\sum_{p\in P}(R_{i,p}-\overline{R_i})(R_{j,p}-\overline{R_j})}{\sqrt{\sum_{p\in P}(R_{i,p}-\overline{R_i})^2} \sqrt{\sum_{p\in P}(R_{j,p}-\overline{R_j})^2}}
   \\其中，R_{i,p}代表用户 i 对用户p的评分。
   \\\overline{R_i}代表用户 i 对所有物品的平均评分，
   \\P代表所有物品的集合。
   $$

3. 基于皮尔逊系数的思路，还可以通过引入物品平均分的方式，减少物品评分偏置对结果的影响
   $$
   sim(i,j)=\frac{\sum_{p\in P}(R_{i,p}-\overline{R_p})(R_{j,p}-\overline{R_p})}{\sqrt{\sum_{p\in P}(R_{i,p}-\overline{R_p})^2} \sqrt{\sum_{p\in P}(R_{j,p}-\overline{R_p})^2}}
   \\其中，\overline{R_p} 代表物品p得到的所有评分的平均分。
   $$

在传统协同过滤改进过程中，人们也是通过对相似度定义的改进来解决传统协同过滤算法存在的一些缺陷的。

### 2.2.3 最终结果的排序

获得Top n相似用户之后，利用Top n用户生成最终推荐结果的过程如下。假设“目标用户与其相似用户的喜好是相似的”，可根据相似用户的已有评价对目标用户的偏好进行预测。

这里最常用的方式是利用用户相似度和相似用户的评价的加权平均获得目标用户的评测预测。
$$
R_{u,p}=\frac{\sum_{s\in S}(w_{u,s}\cdot R_{s,p})}{\sum_{s\in S}w_{u,s}}
\\其中，权重w_{u,s}是用户u和用户s的相似度，
\\R_{s,p}是用户s对物品p的评分。
$$
在获得用户u对不同物品的评价预测后，最终的推荐列表根据预测得分进行排序即可得到。至此，完成协同过滤的全部推荐过程。

以上介绍的协同过滤算法基于用户相似度进行推荐，因此也被称为基于用户的协同过滤（UserCF）。但从技术的角度，它也存在一些缺点，主要包括以下两点。

1. 互联网应用的场景下，用户数往往远大于物品数，而UserCF需要维护用户相似度矩阵以便快速找出Top n相似用户。该用户相似度矩阵的存储开销非常大，且随着用户数的增长，存储空间以$n^2$的速度快速增长
2. 用户的历史数据向量往往非常稀疏，对于只有几次购买或者点击行为的用户来说，找到相似用户的准确度是非常低的。

### 2.2.4 ItemCF

由于UserCF技术上的两点缺陷，无论是Amazon，还是NetFlix，都没有采用UserCF算法，而采用了ItemCF算法实现其最初的推荐系统。

具体的讲，ItemCF是基于物品相似度进行推荐的协同过滤算法。通过计算共现矩阵中物品列向量的相似度得到物品之间的相似矩阵，再找到用户历史正反馈物品的相似物品进行进一步排序和推荐，ItemCF的具体步骤如下：

1. 基于历史数据，构建以用户（假设用户总数为m）为行坐标，物品（物品总数为n）为列坐标的 $m\times n$ 维共现矩阵。
2. 计算共现矩阵两两列向量间的相似性（相似度计算方式与用户相似度的计算方式相同），构建 $n\times n$ 维的物品相似度矩阵。
3. 获得用户历史行为数据中的正反馈物品列表。
4. 利用物品相似度矩阵，针对目标用户历史行为中的正反馈物品，找出相似的Top k个物品，组成相似物品集合。
5. 对相似物品集合中的物品，利用相似度分值进行排序，生成最终的推荐列表。

第五步中，如果一个物品与多个用户行为历史中的正反馈物品相似，那么该物品最终的相似度应该是多个相似度的累加
$$
R_{u,p}=\sum_{h \in H}(w_{p,h}\cdot R_{u,h})
\\其中，H是目标用户的正反馈物品集合，
\\w_{p,h}是物品p与物品h的物品相似度，
\\R_{u,h}是用户u对物品h的已有评分。
$$

### 2.2.6 协同过滤的下一步发展

协同过滤是一个非常直观、可解释性很强的模型，但它并不具备较强的泛化能力，换句话说，协同过滤无法将两个物品相似这个信息推广到其他物品的相似性计算上。这就导致了一个比较严重的问题——热门的物品具有很强的头部效应，容易跟大量物品产生相似性；而尾部的物品由于特征向量稀疏，很少与其他物品产生相似性，导致很少被推荐。

这一现象揭示了协同过滤的天然缺陷——**推荐结果的头部效应比较明显，处理稀疏向量的能力弱**。

为解决上述问题，同时增加模型的泛化能力，**矩阵分解技术**被提出。该方法在协同过滤的共现矩阵的基础上，<u>使用更稠密的隐向量标识用户和物品</u>，挖掘用户和物品的隐含兴趣和隐含特征。

另外，<u>协同过滤仅仅利用用户和物品的交互信息</u>，无法有效地引入用户年龄、性别、商品描述、商品分类、当前时间等一系列用户特征、物品特征和上下文特征，<u>这无疑造成了有效信息地遗漏</u>。为了在推荐模型中引入这些特征，推荐系统逐渐发展到以**逻辑回归模型**为核心的、能够综合不同类型特征的**机器学习模型**的道路上。

## 2.3 矩阵分解算法 ——协同过滤的进化

2006年，Netflix举办的著名推荐算法竞赛Netflix Prize Challenge中，以矩阵分解为主的推荐算法大放异彩，拉开了矩阵分解在业界流行的序幕。本节借用Netflix的场景例子说明矩阵分解算法的原理。

### 2.3.1 矩阵分解算法的原理

矩阵分解算法期望为每一个用户和视频生成一个隐向量，将用户和视频定位到隐向量的表示空间上，距离相近的用户和视频表明兴趣特点相近，在推荐过程中，就应该把距离相近的视频推荐给目标用户。

在“矩阵分解”的算法框架下，**用户和物品的隐向量是通过分解协同过滤生成的共现矩阵得到的**。这也是“矩阵分解”名字的由来。

矩阵分解算法将 $m \times n$ 维的共现矩阵R分解为 $m\times k$ 维的用户矩阵U和 $k\times n$ 维的物品矩阵V相乘的形式。其中m是用户数量，n是物品数量，k是隐向量的维度。k的大小决定了隐向量表达能力的强弱。k的取值越小，隐向量包含的信息越少，模型的泛化程度越高；反之，k的取值越大，隐向量的表达能力越强，但泛化程度相应降低。此外，k的取值还与矩阵分解的求解复杂度直接相关。在具体应用中，k的取值要经过多次试验找到一个推荐效果和工程开销的平衡点。

基于用户矩阵U和物品矩阵V，用户u对物品i的预估评分:
$$
\hat r_{ui}=q^T_i p_u
\\其中p_u是用户u在用户矩阵U中的对应行向量，
\\q_i是物品i在物品矩阵V中的对应列向量
$$

### 2.3.2 矩阵分解的求解过程

对矩阵进行矩阵分解的主要方法有三种：**特征值分解**（Eiden Decomposition）、**奇异值分解**（Singular Value Decomposition，SVD）和**梯度下降**（Gradient Descent）。其中，特征值分解只能作用于方阵，显然不适用于分解用户-物品矩阵。

**奇异值分解**的具体描述如下：

假设矩阵$\boldsymbol M$是一个$m\times n$的矩阵，则一定存在一个分解$\boldsymbol M = \boldsymbol{U \Sigma V^T}$，其中$\boldsymbol U$是$m\times m$的正交矩阵，$\boldsymbol V$是$n \times n$的正交矩阵，$\boldsymbol \Sigma$是$m\times n$的对角阵。

取对角阵$\boldsymbol \Sigma$中较大的k个元素作为隐含特征，删除$\boldsymbol \Sigma$的其他维度及$\boldsymbol U$和$\boldsymbol V$中的对应维度，矩阵$\boldsymbol M$被分解为$\boldsymbol M \approx \boldsymbol U_{m\times k}\boldsymbol \Sigma_{k\times k} V_{k\times n}^T$，至此完成了隐向量维度为k的矩阵分解。

可以说，奇异值分解似乎完美地解决了矩阵分解的问题，但其存在两点缺陷，使其不宜作为互联网场景下矩阵分解的主要方法。

1. 奇异值分解要求原始的共现矩阵是稠密的。互联网场景下大部分用户的行为历史非常少，用户-物品的共现矩阵非常稀疏，这与奇异值分解的应用条件相悖。如果应用奇异值分解，就必须对缺失的元素值进行填充。
2. 传统奇异值分解的计算复杂度达到了$O(mn^2)$的级别，这对于商品数量动辄上百万、用户数量往往上千万的互联网场景来说几乎是不可接受的。



由于上述两个原因，传统奇异值分解也不适用于解决大规模稀疏矩阵的矩阵分解问题。因此，**梯度下降法**成了进行矩阵分解的主要方法，这里对其进行具体介绍。

求解矩阵分解的目标函数：
$$
\min_{\boldsymbol q^*,\boldsymbol p^*}\sum_{(u,i)\in K}(\boldsymbol r_{ui}-\boldsymbol q^T_i \boldsymbol p_u)^2
$$


该目标函数的目的是让原始评分 $\boldsymbol r_{ui}$ 与用户向量和物品向量之积 $\boldsymbol q^T_i \boldsymbol p_u$ 的差尽量小，这样才能最大限度地保存共现矩阵地原始信息。其中K是所有用户评分样本的集合。为了减少过拟合现象，加入正则化项后的 <span id="MFfunction">目标函数</span> 如下：
$$
\min_{\boldsymbol q^*,\boldsymbol p^*}\sum_{(u,i)\in K}(\boldsymbol r_{ui}-\boldsymbol q^T_i \boldsymbol p_u)^2+\lambda(||\boldsymbol q_i||^2+||\boldsymbol p_u||^2)
$$

>**什么是过拟合现象和正则化**？
>
>正则化对应的英文是Regulation，直译过来是“规则化”，即希望让训练出的模型更“规则”、更稳定，避免预测出一些不稳定的“离奇”结果。（过拟合现象）
>
>为了让模型更“稳重”，需要给模型加入一些限制，这些限制就是正则化项。在加入正则化项之后再次进行训练，拟合函数避免受个别“噪声点”的影响，模型的预测输出更加稳定。
>
>正则化项严格的数学形式是什么样的呢？下面是某模型的损失函数（Loss Function）
>$$
>\frac{1}{2}\sum^n_{n=1}{t_n-\boldsymbol W^T\varnothing(\boldsymbol X_n)}^2+\frac{\lambda}{q}\sum^M_{j=1}|\boldsymbol w_j|^q\\
>其中t_n是训练集样本的真实输出，\boldsymbol W是权重,\varnothing是基函数。
>$$
>如果不考虑加号后面的部分，则上面式子是一个标准的L2损失函数。
>
>在加号后面的项就是正则化项，其中$\lambda$被称为正则化系数，$\lambda$ 越大，正则化的限制越强。剩余部分就是模型权重的q次方之和，q取1时被称为L1正则化，q取2时被称为L2正则化。
>
>将正则化项加入损失函数来保持模型稳定的做法也可以做如下理解。对于加入了正则化项的损失函数来说，模型权重越大，损失函数的值越大。梯度下降是朝着损失（Loss）小的方向发展的，因此正则化项其实是希望在尽量不影响原模型与数据集之间损失的前提下，使模型的权重变小，权重的减小自然会让模型的输出波动更小，从而达到让模型更稳定的目的。

对[目标函数](#MFfunction)的求解可以利用非常标准的梯度下降过程完成。

1. 确定[目标函数](#MFfunction)。

2. 对目标函数求偏导，求取梯度下降的方向和幅度。
   对$\boldsymbol q_i$求偏导，得到的结果为：
   $$
   2(\boldsymbol r_{ui}-\boldsymbol q^T_i\boldsymbol p_u)\boldsymbol p_u - 2\lambda\boldsymbol q_i
   $$
   对$\boldsymbol p_u$求偏导的结果为
   $$
   2(\boldsymbol r_{ui}-\boldsymbol q^T_i\boldsymbol p_u)\boldsymbol q_i - 2\lambda\boldsymbol p_u
   $$

3. 利用第2步的求导结果，沿梯度的反方向更新参数：
   $$
   \boldsymbol q_i \leftarrow\boldsymbol q_i-\gamma((\boldsymbol r_{ui}-\boldsymbol q^T_i\boldsymbol p_u)\boldsymbol p_u-\lambda\boldsymbol q_i)\\
   \boldsymbol p_u \leftarrow\boldsymbol p_u-\gamma((\boldsymbol r_{ui}-\boldsymbol q^T_i\boldsymbol p_u)\boldsymbol q_i-\lambda\boldsymbol p_u)\\
   其中\gamma为学习率
   $$
   
4. 当迭代次数超过上限n或损失低于阈值$\theta$时，结束训练，否则循环第3步。

在完成矩阵分解过程后，即可得到所有用户和物品的隐向量。在对某用户进行推荐时，可利用该用户的隐向量与所有物品的隐向量进行逐一的内积运算，得出该用户对所有物品的评分评测，再依次进行排序，得到最终的推荐列表。

在了解了矩阵分解的原理之后，就可以更清楚地解释为什么矩阵分解相较协同过滤有更强的泛化能力。在矩阵分解算法中，由于隐向量的存在，使任意的用户和物品之间都可以得到评测分值。而隐向量其实是利用全局信息生成的，有更强的泛化能力；而对协同过滤来说，如果两个用户没有相同的历史行为，两个物品没有相同的购买，那么这两个用户和两个物品的相似度计算，这能使协同过滤不具备泛化利用全局信息的能力）。

### 2.3.3 消除用户和物品打分的偏差

由于不同用户的打分体系不同（比如在5分为满分的情况下，有的用户认为打3分已经是很低的分数了，而有的用户认为打1分才是比较差的评分），不同物品的衡量标准也有所区别（比如电子产品的平均分和日用品的平均分差异也可能比较大），为了消除用户和物品打分的偏差（Bias），常用的做法是在矩阵分解时加入用户和物品的偏差向量，如：
$$
\boldsymbol r_{ui}=\mu+b_i+b_u+\boldsymbol q^T_i\boldsymbol p_u\\
其中\mu是全局偏差常数，\\
b_i是物品偏差系数，可使用物品i收到的所有评分的平均值，\\
b_u是用户偏差系数，可使用用户u给出的所有评分的均值
$$
与此同时，矩阵分解目标函数也需要在[之前目标函数](#MFfunction)基础上做相应改变，如下：
$$
\min_{\boldsymbol q^*,\boldsymbol p^*,\boldsymbol b^*}\sum_{(u,i)\in K}(\boldsymbol r_{ui}-\mu-b_u-b_i-\boldsymbol q^T_i\boldsymbol p_u)^2+\lambda(||\boldsymbol p_u||^2+||\boldsymbol q_i||^2+b_u^2+b_i^2)
$$
同理，矩阵分解的求解过程会随着目标函数的改变而变化，主要区别在于利用新的目标函数，通过求导得出新的梯度下降公式，在此不再赘述。

加入用户和物品的打分偏差项之后，矩阵分解得到的隐向量更能反映不同用户对不同物品的“真实”态度差异，也就更容易捕获评价数据中有价值的信息，从而避免推荐结果有偏。

### 2.3.4 矩阵分解的优点和局限性

相比协同过滤，矩阵分解有如下非常明显的优点。

1. **泛化能力强**。在一定程度上解决了数据稀疏问题。
2. **空间复杂度低**。不需再存储协同过滤服务阶段所需的“庞大”的用户相似性或物品相似性矩阵，只需存储用户和物品隐向量。空间复杂度由$n^2$级别降低到$(n+m)\cdot k$级别。
3. **更好的扩展性和灵活性**。矩阵分解的最终产出是用户和物品隐向量，这其实与深度学习中Embedding思想不谋而合，因此矩阵分解的结果也非常便于与其他特征进行组合和拼接，并便于与深度学习网络进行无缝结合。

与此同时，也要意识到矩阵分解的局限性。与协同过滤一样，矩阵分解同样不方便加入用户、物品和上下文相关的特征，这使得矩阵分解丧失了利用很多有效信息的机会，同时在缺乏用户历史行为时，无法进行有效的推荐。为了解决这个问题，逻辑回归模型及其后续发展出的因子分解机等模型，凭借其天然的融合不同特征的能力，逐渐在推荐系统领域得到更广泛的应用。

## 2.4 逻辑回归——融合多种特征的推荐模型

相比协同过滤模型仅利用用户和物品的相互行为信息进行推荐，逻辑回归模型能够综合利用用户、物品、上下文等多种不同特征，生成较为“全面”的推荐结果。另外，逻辑回归的另一种表现形式“感知机”作为神经网络中最基础的单一神经元，是深度学习的基础性结构。因此，能够进行多特征融合的逻辑回归模型成了独立于协同过滤的推荐模型发展的另一个主要方向。

相比于协同过滤和矩阵分解利用用户和物品的“相似度”进行推荐，逻辑回归将推荐问题看成一个分类问题，通过预测正样本的概率对物品进行排序。这里的正样本可以是用户“点击”了某商品，也可以是用户“观看”了某视频，均是推荐系统希望用户产生的“正反馈”行为。因此，逻辑回归模型将推荐问题转换成了一个点击率（Click Through Rate，CTR）预估问题。

### 2.4.1 基于逻辑回归模型的推荐流程

基于逻辑回归的推荐过程如下：

1. 将用户年龄、性别、物品属性、物品描述、当前时间、当前地点等特征转换成数值型特征向量。
2. 确定逻辑回归模型的优化目标（以优化“点击率”为例），利用已有样本数据对逻辑回归模型进行训练，确定逻辑回归模型的内部参数。
3. 在模型服务阶段，将特征向量输入逻辑回归模型，经过逻辑回归模型的推断，得到用户“点击”（这里用点击作为推荐系统正反馈行为的例子）物品的概率。
4. 利用“点击”概率对所有候选物品进行排序，得到推荐列表。

基于逻辑回归的推荐过程的重点在于，利用样本的特征向量进行模型训练和在线推断。

### 2.4.2 逻辑回归模型的数学形式

![推荐模型_逻辑回归模型的数学形式的推断过程](..\..\整理后的文件\推荐系统 配图\推荐模型_逻辑回归模型的数学形式的推断过程.png)

逻辑回归模型的推断过程可以分为如下几步:

1. 将特征向量 $\boldsymbol x=(x_1,x_2,\cdots,x_n)^T$ 作为模型的输入。
2. 通过为各特征赋予相应的权重 $(w_1,w_2,\cdots,w_{n+1})$ 来表示各特征的重要性差异，将各特征进行加权求和，得到 $\boldsymbol x^T \boldsymbol w$。
3. 将 $\boldsymbol x^T \boldsymbol w$ 输入sigmoid函数，使之映射到0~1的区间，得到最终的“点击率”。

其中sigmoid函数的具体形式：

$$
f(z)=\frac{1}{1+e^{-z}}
$$
 ![sigmoid函数图像](..\..\整理后的文件\推荐系统 配图\sigmoid函数图像.png)

可以直观的看到sigmoid的值域在0~1之间，符合“点击率”的物理意义。

综上，<span id = "LRmath">逻辑回归模型整个推断过程的数学形式 </span>为：
$$
f(\boldsymbol x)=\frac{1}{1+e^{-(\boldsymbol w \cdot \boldsymbol x+b)}}
$$

### 2.4.3 逻辑回归模型的训练方法

对于标准的逻辑回归模型来说，要确定的参数就是特征向量相应的权重向量 $\boldsymbol w$，下面介绍逻辑回归模型的权重向量 $\boldsymbol w$ 的训练方法。

逻辑回归模型常用的训练方法是梯度下降法、牛顿法、拟牛顿法等，其中梯度下降法是应用最广泛的训练方法，也是学习深度学习各种训练方法的基础。

>**什么是梯度下降法**？
>
>梯度下降法是一个一阶最优化算法。应用梯度下降法的目的是找到一个函数局部极小值。为此，必须沿函数上当前点对应梯度（或者近似梯度）的反方向进行规定步长距离的迭代搜索。如果向梯度正方向迭代进行搜索，则会接近函数的局部极大值点，这个过程被称为梯度上升法。
>
>这利用了“梯度”的性质：如果实值函数F(x)在点$x_0$处可微且有定义，那么函数F(x)在点$x_0$处沿着梯度相反的方向$-\nabla F(x)$ 下降最快。
>
>因此，在优化某模型的目标函数时，只需对目标函数进行求导，得到梯度的方向，沿梯度的反方向下降，并迭代此过程直至寻找到局部最小点。

使用梯度下降法求解逻辑回归模型的第一步时确定逻辑回归的目标函数。已知[逻辑回归的数学形式](#LRmath)，这里表示成$f_{\boldsymbol w}(\boldsymbol x)$。对于一个输入样本 $\boldsymbol x$ ，预测结果为正样本（类别1）和负样本（类别0）的概率如下：
$$
\left\{
	\begin{array}{l}
		P(y=1|\boldsymbol x;\boldsymbol w)=f_{\boldsymbol w}(\boldsymbol x)\\
		P(y=0|\boldsymbol x;\boldsymbol w)=1-f_{\boldsymbol w}(\boldsymbol x)
	\end{array}
\right.
$$
综合起来，可以写成：
$$
P(y|\boldsymbol x;\boldsymbol w)=(f_{\boldsymbol w}(\boldsymbol x))^y(1-f_{\boldsymbol w}(\boldsymbol x))^{1-y}
$$
由极大似然估计的原理可以写出逻辑回归的目标函数：
$$
L(\boldsymbol w)=\prod^m_{i=1}P(y|\boldsymbol x;\boldsymbol w)
$$
由于目标函数连乘的形式不便于求导，故在上式两侧取log，并乘以系数-(1/m)，将求最大值的问题转换成求极小值的问题，最终的目标函数形式如下：
$$
J(\boldsymbol w)=-\frac{1}{m}l(\boldsymbol w)=-\frac{1}{m}logL(\boldsymbol w)\\
=-\frac{1}{m}(\sum^m_{i=1}(y^i logf_{\boldsymbol w}(\boldsymbol x^i)+(1-y^i)log(1-f_{\boldsymbol w}(\boldsymbol x^i)))
$$
在得到逻辑回归的目标函数后，需对每个参数求偏导，得到梯度方向，对$J(\boldsymbol w)$中参数$w_j$求偏导的结果如下：
$$
\frac{\partial}{\partial w_j}J(\boldsymbol w)=\frac{1}{m}\sum^m_{i=1}(f_{\boldsymbol w}(\boldsymbol x^i)-y^i)\boldsymbol x^i_j
$$
在得到梯度之后，即可得到模型参数的更新方式，如下：
$$
w_j \leftarrow w_j -\gamma\frac{1}{m}\sum^m_{i=1}(f_w(x^i)-y^i)x^i_j
$$
至此，完成了逻辑回归模型的更新推导。

可以看出，无论矩阵分解还是逻辑回归，在用梯度下降求解时都遵循其基本步骤。问题的关键在于利用模型的数学形式找出其目标函数，并通过求导得到梯度下降的公式。

### 2.4.4 逻辑回归模型的优势

在深度学习模型流行之前，逻辑回归模型曾在相当长的一段时间里是推荐系统、计算广告业界的主要选择之一。除了在形式上适于融合不同特征，形成较“全面”的推荐结果，其流行还有三个方面的原因：一是数学含义上的支撑；二是可解释性强；三是工程化的需要。

1. **数学含义上的支撑**
   逻辑回归作为广义线性模型的一种，它的假设是因变量y服从伯努利分布。那么在CTR预估这个问题上，“点击”事件是否发生就是模型的因变量y，而用户是否点击广告是一个经典的掷偏心硬币问题。因此，CTR模型的因变量显然应该服从伯努利分布。所以，采用逻辑回归作为CTR模型是符合“点击”这一事件的物理意义的。
   与之相比，线性回归作为广义线性模型的另一个特例，其假设是因变量y服从高斯分布，这显然不是点击这类二分类问题的数学假设。

2. **可解释性强**
   直观地讲，逻辑回归模型地数学形式是各特征的加权和，再施以sigmoid函数。在逻辑回归数学基础的支撑下，逻辑回归的简单数学形式页非常符合人类对预估过程的直觉认知。
   使用各特征的加权和是为了综合不同特征对CTR的影响，而不同特征的重要程度不一样，所以，为不同特征指定不同的权重，代表不同的特征的重要程度。最后，通过sigmoid函数，使其值能够映射到0~1区间，正好符合CTR的物理意义。
   逻辑回归如此符合人类的直觉认识显然有其他的好处——使模型具有极强的可解释性。算法工程师可以轻易地根据权重的不同解释哪些特征比较重要，在CTR模型的预测有偏差时定位是哪些因素影响了最后的结果。在与负责运营、产品的同事合作时，也便于给出可解释的原因，有效降低沟通成本。

3. **工程化的需要**

   在互联网公司每天动辄TB级别的数据面前，模型的训练开销和在线推断效率显得异常重要。在GPU尚未流行的2012年之前，逻辑回归模型凭借其易于并行化、模型简单、训练开销小等特点，占据着工程领域的主流。囿于工程团队的限制，即使其他复杂模型的效果有所提升，在没有明显击败逻辑回归模型之前，公司也不会贸然加大计算资源的投入，升级推荐模型或CTR模型，这是逻辑回归持续流行的另一重要原因。

### 2.4.5 逻辑回归模型的局限性

逻辑回归作为一个基础模型，显然有其简单、直观、易用的特点。但其局限性也是非常明显的：表达能力不强，无法进行特征交叉、特征筛选等一系列较为“高级”的操作，因此不可避免地造成信息地损失。为解决这一问题，推荐模型朝着复杂化的方向继续发展，衍生出因子分解机等高维的复杂模型。在进入深度学习时代之后，多层神经网络强大的表达能力可以完全替代逻辑回归模型，让它逐渐从各公司退役。

## 2.5 从FM到FFM——自动化特征交叉的解决方案

逻辑回归模型表达能力不强的问题，会不可避免地造成有效信息地损失。在仅使用单一特征而非交叉特征进行判断地情况下，有时不仅是信息损失地问题，甚至会得出错误地结论。著名地“辛普森悖论”用一个简单地例子，说明了进行多维度特征交叉地重要性。

> **什么是辛普森悖论**？
>
> 在对样本集合进行分组研究时，在分组比较中都占优势的一方，在总评中有时反而是失势的一方，这种有悖常理的现象，被称为“辛普森悖论”。
>
> 假如下面两表为视频应用中男性用户和女性用户点击视频的数据。
>
> 男性：
>
> | 视频  | 点击（次） | 曝光（次） | 点击率 |
> | ----- | ---------- | ---------- | ------ |
> | 视频A | 8          | 530        | 1.51%  |
> | 视频B | 51         | 1520       | 3.36%  |
>
> 女性：
>
> | 视频  | 点击（次） | 曝光（次） | 点击率 |
> | ----- | ---------- | ---------- | ------ |
> | 视频A | 201        | 2510       | 8.01%  |
> | 视频B | 92         | 1010       | 9.11%  |
>
> 从以上数据中可以看出，无论男性用户还是女性用户，对视频B的点击率都高于A，显然推荐系统应该优先考虑向用户推荐B。
>
> 那么，如果忽略性别这个维度，将数据汇总会得出什么结论呢？
>
> 汇总：
>
> | 视频  | 点击（次） | 曝光（次） | 点击率 |
> | ----- | ---------- | ---------- | ------ |
> | 视频A | 209        | 3040       | 6.88%  |
> | 视频B | 143        | 2530       | 5.65%  |
>
> 在汇总结果中，视频A的点击率居然比视频B高。如果据此进行推荐，将得出与之前的结果完全相反的结论，这就是所谓的“辛普森悖论”。

逻辑回归只对单一特征做简单加权，不具备进行特征交叉生成高维组合特征的能力，因此表达能力很弱，甚至可能得出像“辛普森悖论”那样的错误结论。因此，通过改造逻辑回归模型，使其具备特征交叉能力是必要和迫切的。

### 2.5.1 POLY2模型——特征交叉的开始

针对特征交叉的问题，算法工程师经常采用先手动组合特征，再通过各种分析手段筛选特征的方法，但该方法无疑是低效的。更遗憾的是，人类的经验往往有局限性，程序员的时间和精力也无法支撑其找到最优的特征组合。因此，采用POLY2模型进行特征的“暴力”组合成了可行的选择。

$$
\empty POLY2(\boldsymbol w,\boldsymbol x)=\sum^{n-1}_{j_1=1}\sum^n_{j_2=j_1+1}w_h(j_1,j_2)x_{j_1}x_{j_2}
$$

可以看到，该模型对所有特征进行两两交叉（特征$x_{j_1}$和$x_{j_2}$），并对所有的特征组合赋予权重$w_h(j_1,j_2)$。POLY2通过暴力组合特征的方式，在一定程度上解决了特征组合的问题。POLY2模型本质上仍是线性模型，其训练方法与逻辑回归并无区别，因此便于工程上的兼容。

但POLY2模型存在两个较大的缺陷。

1. 在处理互联网数据时，经常采用one-hot编码的方法处理类别型数据，致使特征向量极度稀疏，POLY2进行无选择的特征交叉——原本就非常稀疏的特征向量更加稀疏，导致大部分交叉特征的权重缺乏有效的数据进行训练，无法收敛。
2. 权重参数的数量从n直接上升到$n^2$，极大的增加了训练复杂度。

> **什么是one-hot编码**？
>
> one-hot编码是将类别型特征向量的一种编码方式。由于类别型特征不具备数值化意义，如果不进行one-hot编码，无法将其直接作为特征向量的一个维度使用。
>
> 举例来说，某样本有三个特征，分别是星期、性别和城市，用`[Weekday=Tuesday,Gender=Male,City=London]`表示。由于模型的输入特征向量仅可以是数值型特征向量，最常用的方法就是将特征做one-hot编码。编码结果如下：
> $$
> \begin{matrix} \underbrace{ [0,1,0,0,0,0,0] }\\Weekday=Tuesday \end{matrix}
> \begin{matrix} \underbrace{ [0,1] }\\Gender=Male \end{matrix}
> \begin{matrix} \underbrace{ [0,0,1,0,\cdots,0,0] }\\City=London \end{matrix}
> $$
> 可以看到，Weekday这个特征域有7个维度，Tuesday对应第2个维度，所以把对应维度置为1。Gender分为Male和Female，one-hot编码就有两个维度，City特征域同理。
>
> 虽然one-hot编码方式可以将类别型特征转变成数值型特征向量，但是会不可避免地造成特征向量中存在大量数值为0的特征维度。这在互联网这种海量用户场景下尤为明显。假设某应用有一亿用户，那么将用户id进行one-hot编码后，将造成1亿维特征向量中仅有1维是非零的。这是造成互联网模型的输入特征向量稀疏的主要原因。

### 2.5.2 FM模型——隐向量特征交叉

为了解决POLY2模型的缺陷，2010年，Rendle提出了FM模型。

FM二阶部分的数学形式：
$$
\varnothing FM(\boldsymbol w,\boldsymbol x)=\sum^n_{j_i=1}\sum^n_{j_2=j_1+1}（\boldsymbol w_{j_i}\cdot\boldsymbol w_{j_2}）x_{j_1}x_{j_2}
$$
与POLY2相比，其主要区别是用两个向量的内积（$\boldsymbol w_{j_i}\cdot\boldsymbol w_{j_2}$）取代了单一的权重系数$w_h(j_1,j_2)$。具体地说，FM为每个特征学习了一个隐权重向量（lacent vector）。在特征交叉时，使用两个特征隐向量的内积作为交叉特征的权重。

本质上，FM引入隐向量的做法，与矩阵分解用隐向量代表用户和物品的做法异曲同工。可以说，FM是将矩阵分解隐向量的思想进行了进一步扩展，从单纯的用户、物品隐向量扩展到了所有特征上。

FM通过引入特征隐向量的方式，直接把POLY2模型$n^2$级别的权重参数数量减少到了nk（k为隐向量维度，n>>k）。在使用梯度下降法进行FM训练的过程中，FM的训练复杂度同样可被降低到nk级别，极大地降低了训练开销。

隐向量的引入使FM能更好地解决数据稀疏性地问题。举例来说，在某商品推荐的场景下，样本有两个特征，分别是频道（channel）和品牌（brand），某训练样本的特征组合是（ESPN, Adidas）。在POLY2中，只有当ESPN和Adidas同时出现在一个训练样本中时，模型才能学到这个组合特征对应的权重；而在FM中，ESPN的隐向量也可以通过（ESPN, Gucci）样本进行更新，Adidas的隐向量也可以通过（NBC, Adidas）样本进行更新，这大幅降低了模型对数据稀疏性的要求。甚至对于一个从未出现过的特征组合（NBC, Gucci），由于模型之前已经分别学习过NBC, Gucci的隐向量，具备了计算该特征组合权重的能力，这是POLY2无法实现的。相比POLY2，FM虽然丢失了某些具体特征组合的精确记忆能力，但是泛化能力大大提高。

在工程方面，FM同样可以用梯度下降法进行学习，使其不失实时性和灵活性。相比之后深度学习模型复杂的网络结构导致难以部署和线上服务，FM较容易实现的模型结构使其线上推断的过程相对简单，也更容易进行线上部署和服务。因此，FM在2012-2016年前后，成为业界主流的推荐模型之一。

### 2.5.3 FFM模型——引入特征域的概念

2015年，基于FM提出的FFM在多项CTR预估大赛中夺魁，并被Criteo、美团等公司深度应用在推荐系统、CTR预估等领域。相比FM模型，FFM模型引入了特征域感知（field-aware）这一概念，使模型的表达能力更强。
$$
\varnothing FFM(\boldsymbol w,\boldsymbol x)=\sum^n_{j_1=1}\sum^n_{j_2=j_1+1}(\boldsymbol w_{j_1,f_2}\cdot\boldsymbol w_{j_2,f_1})x_{j_1}x_{j_2}
$$
上式是FFM的数学形式的二阶部分。其与FM的区别在于隐向量由原来的$\boldsymbol w_{j_1}$变成了$\boldsymbol w_{j_1,f_2}$,这意味着每个特征对应的不是唯一一个隐向量，而是一组隐向量。当$\boldsymbol x_{j_1}$特征与$\boldsymbol x_{j_2}$特征进行交叉时，$\boldsymbol x_{j_1}$特征会从$\boldsymbol x_{j_1}$的这一组隐向量中挑出与特征$\boldsymbol x_{j_2}$的域$f_2$对应的隐向量$\boldsymbol w_{j_1,f_2}$进行交叉。同理，$\boldsymbol x_{j_2}$也会用与$\boldsymbol x_{j_1}$的域$f_1$对应的隐向量进行交叉。

这里所说的域（field）简单地讲，代表特征域，域内的特征一般是采用one-hot编码形成的一段one-hot特征向量。例如，用户的性别分为男、女、未知三类，那么对一个女性用户来说，采用one-hot方式的编码的特征向量为`[0,1,0]`，这个三维的特征向量就是一个”性别“特征域。将所有特征域连接起来，就组成了样本的整体特征向量。

下面介绍Criteo FFM的论文中的一个例子，更具体地说明FFM的特点。假设在训练推荐模型过程中接收到的训练样本如下：

~~~
Publisher(P)		Advertiser(A)		Gender(G)
ESPN				NIKE				Male
~~~

其中，Publisher、Advertiser、Gender是三个特征域，ESPN、NIKE、Male分别是这三个特征域的特征值（还需要转换成one-hot特征）。

如果按照FM的原理，特征ESPN和NIKE和Male都有对应的隐向量$\boldsymbol w_{ESPN}$，$\boldsymbol w_{NIKE}$，$\boldsymbol w_{Male}$，那么ESPN特征与NIKE特征、ESPN特征与Male特征做交叉的权重应该是$\boldsymbol w_{ESPN}\cdot \boldsymbol w_{NIKE}$和$\boldsymbol w_{ESPN}\cdot \boldsymbol w_{Male}$。其中，ESPN对应的隐向量$\boldsymbol w_{ESPN}$在两次特征交叉过程中是不变的。

而在FFM中，ESPN与NIKE、ESPN与Male交叉特殊的权重分别是$\boldsymbol w_{ESPN,A}\cdot \boldsymbol w_{NIKE,P}$和$\boldsymbol w_{ESPN,G}\cdot \boldsymbol w_{Male,P}$。

细心的读者肯定已经注意到，ESPN在与NIKE和Male交叉时分别使用了不同的隐向量$\boldsymbol w_{ESPN,A}$和$\boldsymbol w_{ESPN,G}$，这是由于NIKE和Male分别在不同的特征域Advertiser（A）和Gender(G)导致的。

在FFM模型的训练过程中，需要学习n个特征在f个域上的k维隐向量，参数数量共$n\cdot k\cdot f$个。在训练方面，FFM的二次项并不能像FM那样简化，因此其复杂度为$kn^2$。

相比FM，FFM引入了特征域的概念，为模型引入了更多有价值的信息，使模型的表达能力更强，但与此同时，FFM的计算复杂度上升到$kn^2$，远大于FM的$kn$。在实际工程应用中，需要在模型效果和工程投入之间进行权衡。

### 2.5.4 从POLY2到FFM的模型演化过程

POLY2模型直接学习每个交叉特征的权重，若特征数量为n，则权重数量为$n^2$量级，具体为n(n-1)/2个。如下所示，每个圆点代表一个特征交叉项。

~~~
f(w,x) =	⚪		+		⚪		+		⚪
		w(ESPN,NIKE)	w(ESPN,Male)	w(NIKE,Male)
~~~

FM模型学习每个特征的k维隐向量，交叉特征由相应特征隐向量的内积得到，权重数量共nk个。FM比POLY2的泛化能力强，但记忆能力有所减弱，处理稀疏特征向量的能力远强于POLY2。每个特征交叉项不再是单独的圆点，而是3个圆点的内积，代表每个特征有一个3维的隐向量。

~~~
			⚪		⚪				⚪		⚪				⚪		⚪
f(w,x) =	⚪	·	⚪		+		⚪	·	⚪		+		⚪	·	⚪
			⚪		⚪				⚪		⚪				⚪		⚪
		w(ESPN)		w(NIKE)			w(ESPN)		w(Male)			w(NIKE)	w(Male)
~~~

FFM模型在FM模型的基础上引入了特征域的概念，在做特征交叉时，每个特征选择与对方域对应的隐向量做内积运算，得到交叉特征的权重，在有n个特征，f个特征域，隐向量维度为k的前提下，参数数量共$n\cdot k\cdot f$个。如下所示，每个特征都有两个隐向量，根据特征交叉对象特征域的不同，选择使用对应的隐向量。

~~~
			⚪⚪		⚪⚪			⚪⚪		⚪⚪			⚪⚪		⚪⚪
f(w,x) =	⚪⚪	·	⚪⚪		+	⚪⚪	·	⚪⚪		+	⚪⚪	·	⚪⚪
			⚪⚪		⚪⚪			⚪⚪		⚪⚪			⚪⚪		⚪⚪
		w(ESPN,A)	w(NIKE,P)		w(ESPN,G)	w(Male,P)	w(NIKE,G)	w(Male,A)
~~~

理论上，FM模型族利用交叉特征的思路可以引申到三阶特征交叉，甚至更高维的阶段，但由于组合爆炸问题的限制，三阶FM无论是权重数量还是训练复杂度都过高，难以在实际工程中实现。那么，如何突破二阶特征交叉的限制，进一步加强模型特征组合的能力，就成了推荐模型发展的方向。

## 2.6 GBDT+LR——特征工程模型化的开端

FFM模型采用引入特征域的方式增强了模型的特征交叉能力，但无论如何，FFM只能做二阶的特征交叉，如果继续提高特征交叉的维度，会不可避免地产生组合爆炸和计算复杂度过高的问题。那么，有没有其他方法可以有效地处理高维特征组合和筛选的问题呢？2014年，Facebook提出了基于GBDT+LR组合模型的解决方案。

### 2.6.1 GBDT+LR组合模型的结构

简而言之，Facebook提出了一种利用GBDT自动进行特征筛选和组合，进而生成新的离散特征向量，再把该特征向量当作LR模型输入，预估CTR的模型结构。

> GBDT+LR的模型结构：
>
> 输入特征 --> 树分裂 --> 转换后的特征 --> 线性分类器

需要强调的是，用GDBT构建特征工程，利用LR预估CTR这两步是独立训练的，所以不存在如何将LR的梯度回传到GDBT这类复杂的问题。利用LR预估CTR的过程在2.4逻辑回归可以看到，本节着重讲解利用GBDT构建新的特征向量的过程。

> **什么是GBDT模型**？
>
> GBDT的基本结构是决策树组成的树林，学习方式是梯度提升。
>
> 具体地讲，GBDT作为集成模型，预测的方式是把所有子树的结果加起来。
> $$
> D(x)=d_{tree1}(x)+d_{tree2}(x)+\cdots
> $$
> GBDT通过逐一生成决策子树的方式生成整个树林，生成新子树的过程是利用样本标签值与当前树林预测值之间的残差，构建新的子树。
>
> 假设当前已经生成了3棵子树，则当前的预测值为
> $$
> D(x)=d_{tree1}(x)+d_{tree2}(x)+d_{tree3}(x)
> $$
> GBDT期望的是构建第4棵子树，使当前树林的预测结果D(x)与第4棵子树的预测结果$d_{tree4}(x)$之和，能进一步逼近理论上拟合函数f(x)，即
> $$
> D(x)+d_{tree4}(x)=f(x)
> $$
> 所以，第4棵子树的生成过程是以目标拟合函数和已有树林预测结果的残差R(X)为目标的：
> $$
> R(x)=f(x)-D(x)
> $$
> 理论上，如果可以无限生成决策树，那么GBDT可以无限逼近由所有训练集样本组成的目标拟合函数，从而达到减少预测误差的目的。

GBDT是由多棵回归树组成的树林，后一棵树以前面树林的结果与真实结果的残差为拟合目标。每棵树生成的过程是一棵标准的回归树生成过程，因此回归树中每个节点的分裂是一个自然的特征选择的过程，而多层节点的结构则对特征进行了有效的自动组合，也就非常高效的解决了过去棘手的特征选择和特征组合的问题。

### 2.6.2 GBDT进行特征转换的过程

利用训练集训练好GBDT模型之后，就可以利用该模型完成从原始特征向量到新的离散型特征向量的转化。具体过程如下。

一个训练样本在输入GBDT的某一子树后，会根据每个节点的规则最终落入某一叶子节点，把该叶子节点置为1，其他叶子节点置为0，所有叶子节点组成的向量即形成了该棵树的特征向量，把GBDT所有子树的特征向量连接起来，即形成了后续LR模型输入的离散型特征向量。

举例来说，GBDT可以由三棵子树构成，每棵子树有4个叶子节点，输入一个训练样本后，其先后落入”子树1“的第3个叶节点中，那么特征向量就是`[0,0,1,0]`，”子树2“的第1个叶节点，特征向量为`[1,0,0,0]`，”子树3“的第4个叶节点，特征向量为`[0,0,0,1]`，最后连接所有特征向量，形成最终的特征向量`[0,0,1,0,1,0,0,0,0,0,0,1]`。

事实上，决策树的深度决定了特征交叉的阶数。如果决策树的深度为4，则通过3次节点分裂，最终的叶节点实际上是进行三阶特征组合后的结果，如此强的特征组合能力显然是FM系的模型不具备的。但GBDT容易产生过拟合，以及GBDT的特征转换方式实际上丢失了大量特征的数值信息，因此不能简单地说GBDT的特征交叉能力强，效果就比FFM好，在模型的选择和调试上，永远都是多种因素综合作用的结果。

### 1.8.3 GBDT+LR组合模型开启的特征工程新趋势

GBDT+LR组合模型对于推荐系统领域的重要性在于，它大大推进了特征工程模型化这一重要趋势。在GBDT+LR组合模型出现之前，特征工程的主要解决方法有两个：一是进行人工的或半人工的特征组合和特征筛选；二是通过改造目标函数，改进模型结构，增加特征交叉项的方式增强特征组合能力。但这两种方法都有弊端，第一种方法对算法工程师的经验和精力投入要求较高；第二种方法则要求从根本上改变模型结构，对模型设计能力的要求较高。

GBDT+LR组合模型的提出，意味着特征工程可以完全交由一个独立的模型来完成，模型的输入可以是原始的特征向量，不必在特征工程上投入过多的人工筛选和模型设计的精力，实现真正的端到端（End to End）训练。

广义上讲，深度学习模型通过各类网络结构、Embedding层等方法完成特征工程的自动化，都是GBDT+LR开启的特征工程模型化这一趋势的延续。

## 2.7 LS-PLM——阿里巴巴曾经的主流推荐模型

阿里巴巴曾经的主流推荐模型——”大规模分段线性模型“（Large Scale Piece-wise Linear Model，简称为LS-PLM）。

虽然该模型在2017年才被阿里巴巴公之于众，但其实早在2012年，它就是阿里巴巴主流的推荐模型，并在深度学习模型提出之前长时间应用于阿里巴巴的各类广告场景。

LS-PLM的结构与三层神经网络极其相似，在深度学习来临的前夜，可以将它看作推荐系统领域连接两个时代的节点。

### 2.7.1 LS-PLM模型的主要结构

LS-PLM，又被称为MLR（Mixed Logistic Regression，混合逻辑回归）模型。本质上，LS-PLM可以看作对逻辑回归的自然推广，它在逻辑回归的基础上采用分而治之的思路，先对样本进行分片，再在样本分片中应用逻辑回归进行CTR预估。

在逻辑回归的基础上加入聚类思想，其灵感来自对广告推荐领域样本特点的观察。举例来说，如果CTR模型要预估的是女性受众点击女装广告的CTR，那么显然，我们不希望把男性用户点击数码类产品的样本数据也考虑进来，因为这样的样本不仅与女性购买女装的广告场景毫无相关性，甚至会在模型训练过程中干扰相关特征的权重。为了让CTR模型对不同用户群体、不同使用场景更有针对性，其采用的方法是先对全量样本进行聚类，再对每个分类施以逻辑回归模型进行CTR预估。LS-PLM的实现思路就是由该灵感产生的。

LS-PLM的数学形式，首先用聚类函数$\pi$对样本进行分类（这里的$\pi$采用了softmax函数对样本进行多分类），再用LR模型计算样本在分片中具体的CTR，然后将二者相乘后求和。
$$
f(x)=\sum^m_{i=1}\pi_i(x)\cdot\eta_i(x)=\sum^m_{i=1}\frac{e^{\eta_i\cdot x}}{\sum^m_{j=1}e^{\mu_j\cdot x}}\cdot\frac{1}{1+e^{-w_i\cdot x}}
$$
其中的超参数”分片数“m可以较好地平衡模型的拟合与推广能力。当m=1时，LS-PLM就退化为普通的逻辑回归。m越大，模型的拟合能力越强。与此同时，模型参数规模也随m的增大而线性增长，模型收敛所需的训练样本也随之增长。在实践中，阿里巴巴给出的m的经验值为12.

> **什么是softmax函数**？
>
> softmax函数，又称**归一化指数函数。**它是二分类函数sigmoid在多分类上的推广，目的是将多分类的结果以概率的形式展现出来。
>
> 它能将一个含任意实数的K维向量z“压缩”到另一个K维实向量σ(z)中，使得每一个元素的范围都在(0,1)之间，并且所有元素的和为1。该函数多于多分类问题中。

如下图所示，分别用红色和蓝色表示两类训练数据，传统LR模型的拟合能力不足，无法找到非线性的分类面，而MLR模型用4个分片可以完美地拟合出数据中的菱形分类面。

![推荐系统_MLR模型对训练数据的拟合](..\..\整理后的文件\推荐系统 配图\推荐系统_MLR模型对训练数据的拟合.jpg)

### 1.9.2 LS-PLM模型的优点

LS-PLM模型适用于工业级的推荐、广告等大规模稀疏数据的场景，主要是因为其具有以下两个优势。

1. 端到端的非线性学习能力：LS-PLM具有样本分片的能力，因此能够挖掘出数据中蕴藏的非线性模式，省去了大量的人工样本处理和特征工程的过程，使LS-PLM算法可以端到端地完成训练，便于用一个全局模型对不同应用领域、业务场景进行统一建模。
2. 模型的稀疏性强：LS-PLM在建模时引入了L1和L2，L1范数，可以使最终训练出来的模型具有较高的稀疏度，使模型的部署更加轻量级。模型服务过程仅需使用权重非零特征，因此稀疏模型也使其在线推断的效率更高。

## 2.8 总结——深度学习推荐系统的前夜

| 模型名称 | 基本原理                                                     | 特点                                                         | 局限性                                                       |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 协同过滤 | 根据用户的行为历史生成用户-物品共现矩阵，利用用户相似性和物品相似性进行推荐 | 原理简单、直接，应用广泛                                     | 泛化能力差，处理稀疏矩阵的能力差，推荐结果头部效应比较明显   |
| 矩阵分解 | 将协同过滤算法中的共现矩阵分解为用户矩阵和物品矩阵，利用用户隐向量和物品隐向量的内积进行排序并推荐 | 相较协同过滤，泛化能力有所增强，对稀疏矩阵的处理能力有所增强 | 除了用户历史行为数据，难以利用其他用户、物品特征及上下文特征 |
| 逻辑回归 | 将推荐问题转化成类似CTR预估的二分类问题，将用户、物品、上下文等不同特征转换成特征向量，输入逻辑回归模型得到CTR，再按照预估CTR进行排序并推荐 | 能够融合多种类型的不同特征                                   | 模型不具备特征组合能力，表达能力较差                         |
| FM       | 在逻辑回归的基础上，在模型中加入二阶特征交叉的部分，为每一维特征训练得到相应特征隐向量，通过隐向量间的内积运算得到交叉特征权重 | 相比逻辑回归，具备了二阶特征交叉能力，模型的表达能力增强     | 由于组合爆炸的问题的限制，模型不易扩展到三阶特征交叉阶段     |
| FFM      | 在FM模型的基础上，加入“特征域”的概念，使每个特征在与不同域的特征交叉时采用不同的隐向量 | 相比FM，进一步加强了特征交叉的能力                           | 模型的训练开销达到了$O(n^2)$的量级，训练开销较大             |
| GBDT+LR  | 利用GBDT进行“自动化”的特征组合，将原始特征向量转换成离散型特征向量，并输入逻辑回归模型，进行最终的CTR预估 | 特征工程模型化，使模型具备了更高阶特征组合的能力             | GBDT无法进行完全并行的训练，更新所需的训练时长较长           |
| LS-PLM   | 首先对样本进行“分片”，在每个“分片”内部构建逻辑回归模型，将每个样本的各个“分片”概率与逻辑回归的得分进行加权平均，得到最终的预估值 | 模型结构类似三层神经网络，具备了较强的表达能力               | 模型结构相比深度学习模型仍比较简单，有进一步提高的空间       |

# 第3章 浪潮之巅——深度学习在推荐系统中的应用

在进入深度学习时代后，推荐系统主要在以下两方面取得了重大进展。

1. 与传统的机器学习模型相比，深度学习模型的表达能力更强，能够挖掘出更多数据中潜藏的模式。
2. 深度学习的模型结构非常灵活，能够根据业务场景和数据特点，灵活调整模型结构，使模型与应用场景完美契合。

## 3.1 深度学习推荐模型的演化关系图

以多层感知机（Multi-Layer Perception, MLP) 为核心，通过改变神经网络的结构，构建特点各异的深度学习推荐模型，其主要的演变方向如下：

![推荐系统_主流深度学习推荐模型的演化图谱](..\..\整理后的文件\推荐系统 配图\推荐系统_主流深度学习推荐模型的演化图谱.png)

1. **改变神经网络的复杂程度**：从最简单的单层神经网络模型AutoRec（自编码器推荐），到经典的深度神经网络结构Deep Crossing（深度特征交叉），其主要的进化方式在于——增加了深度神经网络的层数和结构复杂度。
2. **改变特征交叉方式**：这类模型的主要改变在于丰富了深度学习中特征交叉的方式。例如，改变了用户向量和物品向量互操作方式的NeuralCF（Neural Collaborative Filtering，神经网络协同过滤），定义了多种特征向量交叉操作的PNN（Product-based Neural Network，基于积操作的神经网络）模型。
3. **组合模型**：这类模型主要是指Wide&Deep模型及其后续变种Deep&Cross、DeepFM等，其思路是通过组合两种不同特点、优势互补的深度学习网络，提升模型的综合能力。
4. **FM模型的深度学习演化版本**：传统推荐模型FM在深度学习时代有了诸多后续版本，其中包括NFM（Neural Factorization Machine，神经网络因子分解机）、FNN（Factorization-machine supported Neural Network，基于因子分解机支持的神经网络）、AFM（Attention neural Factorization Machine，注意力因子分解机）等，它们对FM的改进方向各不相同。例如，NFM主要使用神经网络提升FM二阶部分的特征交叉能力，AFM是引入了注意力机制的FM模型，FNN利用FM的结果进行网络初始化。
5. **注意力机制与推荐模型的结合**：这类模型主要是将“注意力机制”应用于深度学习推荐模型中，主要包括结合了FM与注意力机制的AFM和引入了注意力机制的CTR预估模型DIN（Deep Interest Network，深度兴趣网络）。
6. **序列模型与推荐模型的结合**：这类模型的特点是使用序列模型模拟用户行为或用户兴趣的演化趋势，代表模型是DIEN（Deep Interest Evolution Network，深度兴趣进化网络）。
7. **强化学习与推荐模型的结合**：这类模型将强化学习应用于推荐领域，强调模型的在线学习和实时更新，其代表模型是DRN（Deep Reinforcement Learning Network，深度强化学习网络）。

## 3.2 AutoRec——单隐层神经网络推荐模型

2015年由澳大利亚国立大学提出单隐层神经网络推荐模型AutoRec。它将自编码（AutoEncoder）的思想和协同过滤结合，提出了一种单隐层神经网络推荐模型。因其简洁的网络结构和清晰易懂的模型原理，AutoRec非常适合作为深度学习推荐模型的入门模型来学习。

### 3.2.1 AutoRec模型的基本原理

AutoRec模型是一个标准的自编码器，它的基本原理是利用协同过滤中的共现矩阵，完成物品向量或者用户向量的自编码。再利用自编码的结果得到用户对物品的预估评分，进而进行推荐排序。

> **什么是自编码器**？
>
> 顾名思义，自编码器是指能够完成数据“自编码”的模型。无论是图像、音频，还是文本数据，都可以转换成向量的形式进行表达。假设其数据向量为$\boldsymbol r$, 自编码器的作用是将向量$\boldsymbol r$作为输入，通过自编码器后，得到的输出向量尽量接近其本身。
>
> 假设自编码器的重建函数为$h(\boldsymbol r;\theta)$，那么自编码器的目标函数如下所示
> $$
> \min_\theta \sum_{\boldsymbol r\in S}||\boldsymbol r - h(\boldsymbol r;\theta)||^2_2\\
> 其中，S是所有数量向量的集合。
> $$
> 在完成自编码器的训练后，就相当于在重建函数$h(\boldsymbol r;\theta)$中存储了所有数据向量的“精华”。一般来说，重建函数的参数数量远小于输入向量的维度数量，因此自编码器相当于完成了数据压缩和降维的工作。
>
> 经过自编码器生成的输出向量，由于经过了自编码器的“泛化”过程，不会完全等同于输入向量，也因此具备了一定的缺失维度的预测能力，这也是自编码器能用于推荐系统的原因。

假设有m个用户，n个物品，用户会对n个物品中的一个或几个进行评分，未评分的物品分值可用默认值或平均分值表示，则所有m个用户对物品的评分可形成一个$m \times n$维的评分矩阵，也就是协同过滤中的共现矩阵。

对一个物品i来说，所有m个用户对它的评分可形成一个m维的向量$\boldsymbol r^{(i)}=(R_{1i},\cdots,R_{mi})^T$，如“什么是自编码器”中介绍的，AutoRec要解决的问题是构建一个重建函数$h(\boldsymbol r;\theta)$，使所有该重建函数生成的评分向量与原评分向量的平方残差和最小，如自编码器目标函数所示。

在得到AutoSec模型的重建函数后，还要经过评分预估和排序的过程才能得到最终的推荐列表。下面介绍AutoRec模型的两个重点内容——重建函数的模型结构和利用重建函数得到最终推荐列表的过程。

### 3.2.2 AutoRec模型的结构

AutoRec使用单隐层神经网络的结构来解决构建重建函数的问题。从模型的结构图中可以看出，网络的输入层是物品的评分向量$\boldsymbol r$，输出层是一个多分类层。图中蓝色的神经元代表模型的k维单隐层，其中k<<m。

![推荐系统_AutoRec模型的结构图](..\..\整理后的文件\推荐系统 配图\推荐系统_AutoRec模型的结构图.png)

图中的$\boldsymbol V$和$\boldsymbol W$分别代表输入层到隐层，以及隐层到输出层的参数矩阵。该模型结构代表的重建函数的具体形式如下所示：
$$
h(\boldsymbol r;\theta)=f(\boldsymbol W \cdot g(\boldsymbol V \boldsymbol r +\mu)+b)\\
其中，f(\cdot),g(\cdot)分别为输出层神经元和隐层神经元的激活函数。
$$
为防止重构函数的过拟合，在加入L2正则化项后，AutoRec目标函数的具体形式如下：
$$
\min_\theta \sum_{i=1}^n||\boldsymbol r^{(i)} - h(\boldsymbol r^{(i)};\theta)||^2_0 + \frac{\lambda}{2}\cdot(||\boldsymbol W||^2_F+||V||^2_F)
$$
由于AutoRec模型是一个非常标准的三层神经网络，模型的训练应用梯度反向传播即可完成。

> **什么是神经元、神经网络和梯度反向传播**？
>
> 神经元（Neuron），又名感知机（Perception），在模型结构上与逻辑回归一致，这里以一个二维输入向量的例子对其进行进一步的解释。假设模型的输入向量是一个二维特征向量$(\boldsymbol x_1, x_2)$, 则单神经元的模型结构如下所示
>
> ~~~
> 输入	 |								   |  输出
> x_1 --|--> [x] ---\						|
>       |            |---> [+] ---> [ ] --|--> y
> x_2 --|--> [x] ---/						|
> 	  |									|
> ~~~
>
> 其中，输入输出中间的部分可以看作线性的加权求和，再加上一个常数偏置b的操作，最终得到输入如下。
> $$
> (x_1\cdot w_1)+(x_2\cdot w_2)+b
> $$
> 图中的输入输出中间的部分可以看作激活函数，它的主要作用是把一个无界输入映射到一个规范的、有界的值域上。常用的激活函数除了“1.4 逻辑回归”介绍的sigmoid函数，还包括tanh、ReLU等。单神经元由于受到简单结构的限制，拟合能力不强，因此在解决复杂问题时，经常会用多神经元组成一个网络，使之具备拟合任意复杂函数的能力，这就是我们常说的**神经网络**。下图展示了一个由输入层，两神经元隐层和单神经元输出层组成的简单神经网络 。
>
> ~~~mermaid
> graph LR
>     subgraph 输出层
>     o1((o1))
>     style o1 fill:#0BF
>     end
>     subgraph 隐层
>     h1((h1))-->o1
>     h2((h2))-->o1
>     style h1 fill:#0BF
>     style h2 fill:#0BF
>     end
>     subgraph 输入层
>     x1((x1))-->h1
>     x1-->h2
>     x2((x2))-->h1
>     x2-->h2
>     end
> ~~~
>
> 其中，隐层和输出层的神经元构造和上面所述的感知机的构造相同，h1和h2神经元的输入是由x1和x2组成的特征向量，而神经元o1的输入则是由h1和h2输出组成的输入向量。本例是最简单的神经网络，在深度学习的发展历程中，正是研究人员对神经元不同连接方式的探索，才衍生出各种不同特性的深度学习网络，让深度学习模型的家族树枝繁叶茂。
>
> 在清楚了神经网络的模型结构之后，重要的问题就是如何训练一个神经网络。这里需要用到神经网络的重要训练方法——**前向传播**（Forward Propagation）和**反向传播**。前向传播的目的是在当前网络参数的基础上得到模型对输入的预估值，也就是说常见的模型推断过程。在得到预估值之后，就可以利用损失函数（Loss Function）的定义计算模型的损失。对输出层神经元来说（图中的o1），可以直接利用梯度下降法计算神经元相关权重（即下图中的权重w5和w6）的梯度，从而进行权重更新，但对隐层神经元的相关参数（比如w1）,应该如何利用输出层的损失进行梯度下降呢？
>
> ~~~mermaid
> graph LR
>     subgraph 输出层
>     o1((o1))
>     style o1 fill:#0BF
>     end
>     subgraph 隐层
>     h1((h1))--w5-->o1
>     h2((h2))--w6-->o1
>     style h1 fill:#0BF
>     style h2 fill:#0BF
>     end
>     subgraph 输入层
>     体重--w1-->h1
>     体重--w3-->h2
>     身高--w2-->h1
>     身高--w4-->h2
>     end
> ~~~
>
> 利用求导过程中的链式法则（Chain Rule），可以解决梯度反向传播的问题。如下式所示，最终的损失函数到权重w1的梯度是由损失函数到神经元h1输出的偏导，以及神经元h1输出到权重w1的偏导相乘而来的。也就是说，最终的梯度逐层传导回来，“指导”权重w1的更新。
> $$
> \frac{\partial L_{o_1}}{\partial w_1}=\frac{\partial L_{o_1}}{\partial h_1}\cdot\frac{\partial L_{h_1}}{\partial w_1}
> $$
> 在具体的计算中，需要明确最终损失函数的形式，以及每层神经元激活函数的形式，再根据具体的函数形式进行偏导的计算。
>
> 总的来说，神经元是神经网络中的基础结构，其具体实现、数学形式和训练方式与逻辑回归模型一致。神经网络是通过将多个神经元以某种方式连接起来形成网络，神经网络的训练方法就是基于链式法则的梯度反向传播。

### 3.2.3 基于AutoRec模型的推荐过程

基于AutoRec模型的推荐过程并不复杂。当输入物品i的评分向量为$\boldsymbol r^{(i)}$时，模型的输出向量$h(\boldsymbol r^{(i)};\theta)$就是所有用户对物品i的评分预测。那么，其中的第u维就是用户u对物品i的预测$\hat R_{ui}$，如下式所示
$$
\hat R_{ui} = (h(\boldsymbol r^{(i)};\hat\theta))_u
$$
通过遍历输入物品向量就可以得到用户u对所有物品的评分预测，进而根据评分预测排序得到推荐列表。

与协同过滤算法一样，AutoRec也分为基于物品的AutoRec和基于用户的AutoRec。以上介绍的AutoRec输入向量是物品的评分向量，因此可称为I-AutoRec(Item based AutoRec)，如果换做把用户的评分向量作为输入向量，则得到U-AutoRec(User based AutoRec)。在进行推荐列表生成过程中，U-AutoRec相比I-AutoRec的优势在于仅需输入一次目标用户的用户向量，就可以重建用户对所有物品的评分向量。也就是说，得到用户的推荐列表仅需一次模型推断过程；其劣势是用户向量的稀疏性可能会影响模型效果。

### 3.2.4 AutoRec模型的特点和局限性

AutoRec模型从神经网络的角度出发，使用一个单隐层的AutoEncoder泛化用户或物品评分，使模型具有一定的泛化和表达能力。由于AutoRec模型的结构比较简单，使其存在一定的表达能力不足的问题。

在模型结构上，AutoRec模型和后来的词向量模型（Word2vec）完全一致，但优化目标和训练方法有所不同。

从深度学习的角度来说，AutoRec模型的提出，拉开了使用深度学习的思想解决推荐问题的序幕，为复杂深度学习网络的构建提供了思路。

## 3.3 Deep Crossing模型——经典的深度学习架构

如果说AutoRec模型是将深度学习的思想应用于推荐系统的初步尝试，那么微软于2016年提出的Deep Crossing模型就是一次深度学习架构在推荐系统中的完整应用。虽然自2014年以来，就陆续有公司透露在其推荐系统中应用了深度学习模型，但直到Deep Crossing模型发布的当年，才有正式的论文分享了完整的深度学习推荐系统的技术细节。相比AutoRec模型过于简单的网络结构带来的一些表达能力不强的问题，Deep Crossing模型完整地解决了从特征工程、稀疏向量稠密化、多层神经网络进行优化目标拟合等一系列深度学习在推荐系统中的应用问题，为后续的研究打下了良好的基础。

### 3.3.1 Deep Crossing模型的应用场景

Deep Crossing模型的应用场景是微软搜索引擎Bing中的搜索广告推荐场景。用户在搜索引擎中输入搜索词之后，搜索引擎除了会返回相关结果，还会返回与搜索词相关的广告，这也是大多数搜索引擎的主要赢利模式。尽可能地增加搜索广告地点击率，准确地预测广告点击率，并以此作为广告排序的指标之一，是非常重要的工作，也是Deep Crossing模型的优化目标。

针对该使用场景，微软使用的特征如下表所示，这些特征可以分为三类：

- 一类是可以被处理成one-hot或者multi-hot向量的类别型特征，包括用户搜索词（query）、广告关键词（keyword）、广告标题（title）、落地页（landing page）、匹配类型（match type）;
- 一类是数值型特征，微软称其为计数型（counting）特征，包括点击率、预估点击率（click prediction）；
- 一类是需要进一步处理的特征，包括广告计划（campaign）、曝光样例（impression）、点击样例（click）等。

严格地说，这些都不是独立的特征，而是一个特征的组别，需要进一步处理。例如，可以将广告计划中的预算（budget）作为数值型特征，而广告计划的id则可以作为类别型特征。

| 特征       | 特征含义                                                     |
| ---------- | ------------------------------------------------------------ |
| 搜索词     | 用户在搜索框中输入的搜索词                                   |
| 广告关键词 | 广告主为广告添加的描述其产品的关键词                         |
| 广告标题   | 广告标题                                                     |
| 落地页     | 点击广告后的落地页面                                         |
| 匹配类型   | 广告主选择的广告——搜索词匹配类型（包括精准匹配、短语匹配、语义匹配等） |
| 点击率     | 广告的历史点击率                                             |
| 预估点击率 | 另一个CTR模型的CTR预估值                                     |
| 广告计划   | 广告主创建的广告投放计划，包括预算、定向条件等               |
| 曝光样例   | 一个广告“曝光”的例子，该例子记录了广告在实际曝光场景中的相关信息 |
| 点击样例   | 一个广告“点击”的例子，该例子记录了广告在实际点击场景中的相关信息 |

类别型特征可以通过one-hot或multi-hot编码生成特征向量，数值型特征则可以直接拼接进特征向量中，在生成所有输入特征的向量表达后，Deep Crossing模型利用该特征向量进行CTR预估。深度学习网络的特点是可以根据需求灵活地对网络结构进行调整，从而达成从原始特征向量到最终的优化目标的端到端的训练目的。下面通过剖析Deep Crossing模型的网络结构，探索深度学习是如何通过对特征的层层处理，最终准确地预估点击率的。

### 3.3.2 Deep Crossing模型的网络结构

为完成端到端的训练，Deep Crossing模型要在其内部网络中解决如下问题。

1. 离散类特征编码后过于稀疏，不利于直接输入神经网络进行训练，如何解决稀疏特征向量稠密化的问题。
2. 如何解决特征自动交叉组合的问题。
3. 如何在输出层中达成问题设定的优化目标

Deep Crossing模型分别设置了不同的神经网络层来解决上述问题。如下图所示，其网络结构主要包括4层——Embedding层、Stacking层、Multiple Residual Units层和Scoring层。接下来，从下至上依次介绍各层的功能和实现。

~~~mermaid
graph TB
	target((优化目标))
	target-->score[Scoring层]
	score-->mru[Multiple Residual Units层]
	mru-->stack[Stacking层]
	stack-->embed1[Embedding #1]
	embed1-->feature1[Feature #1]
	stack--->feature2[Feature #2]
	stack-->embedn[Embedding #n]
	embedn-->featuren[Feature #n]
~~~

**Embedding层**：Embedding层的作用是将稀疏的类别型特征转换成稠密的Embedding向量。从上图可以看到，每一个特征（如Feature#1，这里指的是经one-hot编码后的稀疏特征向量）经过Embedding层后，会转换成对应的Embedding向量（如Embedding#1）。

Embedding层的结构以经典的全连接层（Fully Connected Layer）结构为主，但Embedding技术本身作为深度学习中研究非常广泛的话题，已经衍生出了Word2vec、Graph Embedding等多种不同的Embedding方法，第4章将对Embedding的主流方法做更详尽的介绍。

一般来说，Embedding向量的维度应远小于原始的稀疏特征向量，几十到上百维一般就能满足需求。这里补充一点，上图中的Feature#2实际上代表了数值型特征，可以看到，数值型特征不需要经过Embedding层，直接进入了Stacking层。

**Stacking层**：Stacking层（堆叠层）的作用比较简单，是把不同的Embedding特征和数值型特征拼接在一起，形成新的包含全部特征的特征向量，该层通常也被称为连接（concatenate）层。

**Multiple Residual Units层**：该层的主要结构是多层感知机，相比标准的以感知机为基本单元的神经网络，Deep Crossing模型采用了多层残差网络（Multi-Layer Residual Network）作为MLP的具体实现。在推荐模型中的应用，也是残差网络首次在图像识别领域之外的成功推广。

通过多层残差网络对特征向量各个维度进行充分的交叉组合，使模型能够抓取到更多的非线性特征和组合特征的信息，进而使深度学习模型在表达能力上较传统机器学习模型大为增强。

> **什么是残差神经网络，其特点是什么？**
>
> 残差神经网络就是由残差单元（Residual Unit）组成的神经网络。残差单元的具体结构如下所示。
>
> ~~~
>       ┌---------------------------------┐
>       |									|
>       |	  ┌---------┐	  ┌---------┐	|
>  x^i  |	  |			| ReLU|			|	↓    x^o
> ------┴---| w_0,b_0 |-----| w_1,b_1 |--(+)-------->
> 		  |			|	  |			|		ReLU
> 		  └---------┘	  └---------┘
> ~~~
>
> 与传统的感知机不同，残差单元的特点主要有两个：
>
> 1. 残差单元中包含了一个以ReLU为激活函数的全连接层。
> 2. 输入通过一个短路（shortcut）通路直接与ReLU全连接层输出进行元素加（element-wise plus）操作。
>
> 在这样的结构下，残差单元其实拟合的是输出和输入之间的“残差”（$\boldsymbol x^o-\boldsymbol x^i$），这就是残差神经网络名称的由来。
>
> 残差神经网络的诞生主要是为了解决两个问题：
>
> 1. 神经网络是不是越深越好？对于传统的基于感知机的神经网络，当网络加深之后，往往存在过拟合现象，即网络越深，在测试集上的表现越差。而在残差神经网络中，由于有输入向量短路的存在，很多时候可以越过两层ReLU网络，减少过拟合现象的发生。
> 2. 当神经网络足够深时，往往存在严重的梯度消失现象。梯度消失现象是指在梯度反向传播过程中，越靠近输入端，梯度的幅度越小，参数收敛的速度越慢。为了解决这个问题，残差单元使用了ReLU激活函数取代原来的sigmoid激活函数。此外，输入向量短路相当于直接把梯度毫无变化地传递到下一层，这也使残差网络的收敛速度更快。

> **什么是ReLU**？
>
> 线性整流函数（Rectified Linear Unit, *ReLU*），又称修正线性单元，是一种人工神经网络中常用的激活函数（activation function），通常指代以斜坡函数及其变种为代表的非线性函数。

**Scoring层**：Scoring层作为输出层，就是为了拟合优化目标而存在的。对于CTR预估这类二分类问题，Scoring层往往使用的是逻辑回归模型，而对于图像分类等多分类问题，Scoring层往往采用softmax模型。

以上是Deep Crossing的模型结构，在此基础上采用梯度反向传播的方法进行训练，最终得到基于Deep Crossing的CTR预估模型。

### 3.3.3 Deep Crossing模型对特征交叉方法的革命

从目前的时间节点上看，Deep Crossing模型是平淡无奇的，因为它没有引入任何诸如注意力机制、序列模型等特殊的模型结构，只是采用了常规的"Embedding+多层神经网络"的经典深度学习结构。但从历史的尺度看，Deep Crossing模型的出现是有革命意义的。Deep Crossing模型中没有任何人工特征工程的参与，原始特征经Embedding后输入神经网络层，将全部特征交叉的任务交给模型。相比之前介绍的FM、FFM模型只具备二阶特征交叉的能力，Deep Crossing模型可以通过调整神经网络的深度进行特征之间的“深度交叉”，这也是Deep Crossing名称的由来。

## 3.4 NeuralCF模型——CF与深度学习的结合

新加坡国立大学的研究人员于2017年提出了基于深度学习的协同过滤模型NeuralCF。

### 3.4.1 从深度学习的视角重新审视矩阵分解模型

在2.2节对Deep Crossing模型的介绍中提到，Embedding层的主要作用是将稀疏矩阵转化成稠密向量。事实上，如果从深度学习的视角看待矩阵分解模型，那么矩阵分解层的用户隐向量和物品隐向量完全可以看作一种Embedding方法。最终的“Scoring层”就是将用户隐向量和物品隐向量进行内积操作后得到“相似度”，这里的“相似度”就是对评分的预测。综上，利用深度学习网络图的方式来描述矩阵分解模型的架构。

~~~mermaid
graph BT
	subgraph input[输入层-稀疏]
	u[用户向量-u]
	i[物品向量-i]
	end
	subgraph embedding层
	u--P_MK=p_uk-->用户隐向量
	i--Q_NK=q_ik-->物品隐向量
	style 用户隐向量 fill:#0AF
	style 物品隐向量 fill:#0A7
	end
	subgraph 内积
	用户隐向量-->cdot((内积))
	物品隐向量-->cdot
	end
	subgraph 输出层
	打分((打分\hat y_ui))
	目标((目标y_ui))
	style 打分 fill:#F77
	end
	cdot-->打分
	目标--训练-->打分
~~~

在实际使用矩阵分解来训练和评估模型的过程中，往往会发现模型容易处于欠拟合的状态，究其原因是因为矩阵分解的模型结构比较简单，特别是“输出层”（也被称为“Scoring层”），无法对优化目标进行有效的拟合。这就要求模型有更强的表达能力，在此动机的启发下，新加坡国立大学的研究人员提出了NeuralCF模型。

### 3.4.2 NeuralCF模型的结构

NeuralCF用“多层神经网络+输出层”的结构替代了矩阵分解模型中简单的内积操作。这样做的收益是直观的：

- 一是让用户向量和物品向量做更充分的交叉、得到更多有价值的特征组合信息；
- 二是引入更多的非线性特征，让模型的表达能力更强。

以此类推，事实上，用户和物品向量的互操作层可以被任意的互操作形式所代替，这就是所谓的“广义矩阵分解”模型（Generalized Matrix Factorization）。

原始的矩阵分解使用“内积”的方式让用户和物品向量进行交互，为了进一步让向量在各维度上进行充分交叉，可以通过“元素积”（element-wise product，长度相同的两个向量的对应维相乘得到另一向量）的方式进行互操作，再通过逻辑回归等输出层拟合最终预测目标。NeuralCF利用神经网络拟合互操作函数的做法是广义的互操作形式。在介绍PNN模型、Deep&Cross模型的章节中，还会介绍更多可行的互操作形式。

再进一步，可以把通过不同互操作网络得到的特征向量拼接起来，交由输出层进行目标拟合。NeuralCF的论文中给出了整合两个网络的例子，如下图。可以看出，NeuralCF混合模型整合了上面提出的原始NeuralCF模型和以元素积为互操作的广义矩阵分解模型。这让模型具有了更强的特征组合和非线性能力。

~~~mermaid
graph BT
	subgraph input
	u[用户向量-u]
	i[物品向量-i]
	end
	subgraph 向量
	u-->MF用户向量
	u-->MLP用户向量
	i-->MF物品向量
	i-->MLP物品向量
	style MF用户向量 fill:#0AF
	style MLP用户向量 fill:#0AF
	style MF物品向量 fill:#0A7
	style MLP物品向量 fill:#0A7
	end
	subgraph neural
	MF用户向量--元素乘连接-->GMF层
	MLP用户向量--连接-->MLP第一层
	MF物品向量--元素乘连接-->GMF层
	MLP物品向量--连接-->MLP第一层
	MLP第一层--ReLU-->MLP第二层
	MLP第二层--ReLU-->MLP第x层
	MLP第x层--连接-->NeuralCF层
	GMF层--连接-->NeuralCF层
	end
	subgraph 输出层
	打分((打分\hat y_ui))
	目标((目标y_ui))
	style 打分 fill:#F77
	end
	NeuralCF层-->打分
	目标--训练损失函数-->打分
~~~

> **什么是softmax函数**？
>
> 在对Deep Crossing和NeuralCF模型进行介绍的过程中，曾多次提及将softmax函数作为模型的最终输出层，解决多分类问题的目标拟合问题。
>
> softmax函数的数学形式定义：给定一个n维向量，softmax函数将其映射为一个概率分布。标准的softmax函数$\sigma:\mathbb{R}^n\rightarrow\mathbb{R}^n$ 由下面的公式定义：
> $$
> \sigma(\boldsymbol X)_i = \frac{exp(x_i)}{\sum^n_{j=1}exp(x_j)},当i=1,\cdots，n且\boldsymbol X = [x_1,\cdots,x_n]^T \in \mathbb{R}^n
> $$
> 可以看到，softmax函数解决了从一个原始的n维向量，向一个n维的概率分布映射的问题。那么在多分类问题中，假设分类数是n，模型希望预测的就是某样本在n个分类上的概率分布。如果用深度学习模型进行建模，那么最后输出层的形式是由n个神经元组成的，再把n个神经元的输出结果作为一个n维向量输入最终的softmax函数，在最后的输出中得到最终的多分类概率分布。在一个神经网络中，softmax输出层的结构如下所示：
>
> ~~~mermaid
> graph BT
> 	subgraph 输出层神经元
> 	1((1))
> 	2((2))
> 	n((n))
> 	end
> 	1-->vec[x1, x2, ..., xn]
> 	2-->vec
> 	n-->vec
> 	vec-->softmax((softmax函数))
> 	softmax-->vec2[p1, p2, ..., pn]
> ~~~
>
> 在分类问题中，softmax函数往往和交叉熵(cross-entropy)损失函数一起使用：
> $$
> Loss_{Cross Entropy}=-\sum_i y_i\ln(\sigma(\boldsymbol x)_i)\\
> 其中，y_i是第i个分类的真实标签值，\sigma(\boldsymbol x)_i 代表softmax函数对第i个分类的预测值。
> $$
> 因为softmax函数把分类输出标准化成了多个分类的概率分布，而交叉熵正好刻画了预测分类和真实结果之间的相似度，所以softmax函数往往与交叉熵搭配使用。在采用交叉熵作为损失作为损失函数时，整个输出层的梯度下降形式变得异常简单。
>
> softmax函数的导数形式为
> $$
> \frac{\partial\sigma(\boldsymbol x)_i}{\partial x_j}=
> 	\begin{cases}
> 		\sigma(\boldsymbol x)_i(1-\sigma(\boldsymbol x)_j), &i=j\\
> 		-\sigma(\boldsymbol x)_i\cdot\sigma(\boldsymbol x)_j,& i\neq j
> 	\end{cases}
> $$
> 基于链式法则，交叉熵函数到softmax函数第j维输入$x_j$的导数形式为
> $$
> \frac{\partial Loss}{\partial x_j}=\frac{\partial Loss}{\partial \sigma(\boldsymbol x)}\cdot\frac{\partial \sigma(\boldsymbol x)}{\partial x_j}
> $$
> 在多分类问题中，真实值中只有一个维度是1，其余维度都为0。假设第k维是1，即$y_k=1$，那么交叉熵损失函数可以简化成如下形式：
> $$
> Loss_{Cross Entropy}=-\sum_i y_i \ln(\sigma(\boldsymbol x)_i)=-y_k\cdot\ln(\sigma(\boldsymbol x)_k)=-\ln(\sigma(\boldsymbol x)_k)
> $$
> 则有
> $$
> \frac{\partial Loss}{\partial x_j}=\frac{\partial(-\ln(\sigma(\boldsymbol x)_k))}{\partial\sigma(\boldsymbol x)_k}\cdot\frac{\partial\sigma(\boldsymbol x)_k}{\partial x_j}\\
> =-\frac{1}{\sigma(\boldsymbol x)_k}\cdot\frac{\partial\sigma(\boldsymbol x)_k}{\partial x_j}\\
> =\begin{cases}
> 		\sigma(\boldsymbol x)_j-1, &j=k\\
> 		\sigma(\boldsymbol x)_j, &j\neq k
> 	\end{cases}
> $$
> 可以看出，softmax函数和交叉熵的配合，不仅在数学含义上完美统一，而且在梯度形式上也非常简介。基于上式的梯度形式，通过梯度反向传播的方法，即可完成整个神经网络权重的更新。

### 3.4.3 NeuralCF模型的优势和局限性

NeuralCF模型实际上提出了一个模型框架，它基于用户向量和物品向量这两个Embedding层，利用不同的互操作层进入特征的交叉组合，并且可以灵活地进行不同互操作层的拼接。从这里可以看出深度学习构建推荐模型的优势——利用神经网络理论上能够拟合任意函数的能力，灵活地组合不同的特征，按需增加或减少模型的复杂度。

在实践中要注意：并不是模型结构越复杂、特征越多越好。一是要防止过拟合的风险，二是往往需要更多的数据和更长的训练时间才能使复杂的模型收敛，这需要算法工程师在模型的实用性、实时性和效果之间进行权衡。

NeuralCF模型也存在局限性。由于是基于协同过滤的思想进行构造的，所以NeuralCF模型并没有引入更多其他类型的特征，这在实际应用中无疑浪费了其他有价值的信息。此外，对于模型中互操作的种类并没有做进一步的探究和说明。这都需要后来者进行更深入的探索。

## 3.5 PNN模型——加强特征交叉能力

NeuralCF模型的主要思想是利用多层神经网络替代经典协同过滤的点积操作，加强模型的表达能力。广义上，任何向量之间的交互计算方式都可以用来替代协同过滤的内积操作，相应的模型可称为广义的矩阵分解模型。但NeuralCF模型只提到了用户向量和物品向量两组特征向量，如果加入多组特征向量又该如何设计特征交互的方法呢？2016年，上海交通大学的研究人员提出的PNN模型，给出了特征交互方式的几种设计思路。

### 3.5.1 PNN模型的网络架构

PNN模型的提出同样是为了解决CTR预估和推荐系统的问题，因此不再赘诉模型的应用场景，直接进入模型架构的部分。下图所示为模型结构图，相比Deep Crossing模型，PNN模型在输入、Embedding层、多层神经网络，以及最终的输出层部分并没有结构上的不同，唯一的区别在于PNN模型用乘积层（Product Layer）代替了DeepCrossing模型中的Stacking层。也就是说，不同特征的Embedding向量不再是简单的拼接，而是用Product操作进行两两交互，更有针对性地获取特征之间的交叉信息。

![推荐系统_PNN模型结构图](..\..\整理后的文件\推荐系统 配图\推荐系统_PNN模型结构图.png)

另外，相比NeuralCF，PNN模型的输入不仅包括用户和物品信息，还可以有更多不同形式、不同来源的特征，通过Embedding层的编码生成同样长度的稠密特征Embedding向量。针对特征的交叉方式，PNN模型也给出了更多具体的互操作方法。

### 3.5.2 Product层的多种特征交叉方式

PNN模型对于深度学习结构的创新主要在于乘积层的引入。具体地说，PNN模型的乘积层由线性操作部分（上图中乘积层的z部分，对各特征向量进行线性拼接）和乘积操作部分（上图中乘积层的p部分）组成。其中，乘积特征交叉部分又分为内积操作和外积操作，使用内积操作的PNN模型被称为IPNN（Inner Product-based Neural Network），使用外积操作的PNN模型被称为OPNN（Outer Product-based Neural Network）。

无论是内积操作还是外积操作，都是对不同的特征Embedding向量进行两两组合。为保证乘积操作能够顺利进行，各Embedding向量的维度必须相同。

内积操作就是经典的向量内积运算，假设输入特征向量分别为$\boldsymbol f_i,\boldsymbol f_j$，特征的内积互操作$g_{inner}(\boldsymbol f_i,\boldsymbol f_j)$的定义如下所示：
$$
g_{inner}(\boldsymbol f_i,\boldsymbol f_j) =  \langle\boldsymbol f_i,\boldsymbol f_j\rangle
$$
外积操作是对输入特征向量$\boldsymbol f_i,\boldsymbol f_j$的各维度进行两两交叉，生成特征交叉矩阵，外积互操作$g_{inner}(\boldsymbol f_i,\boldsymbol f_j)$的定义如下所示
$$
g_{inner}(\boldsymbol f_i,\boldsymbol f_j) = \boldsymbol f_i\boldsymbol f_j^T
$$
外积互操作生成的是特征向量$\boldsymbol f_i,\boldsymbol f_j$各维度两两交叉而成的一个 $M\times M$ 的方形矩阵（其中M是输入向量的维度）。这样的外积操作无疑会直接将问题的复杂度从原来的M提升到$M^2$，为了在一定程度上减小模型训练的负担，PNN模型的论文中介绍了一种降维的方法，就是把所有两两特征Embedding向量外积互操作的结果叠加（superposition），形成了一个叠加外积互操作矩阵$\boldsymbol p$,具体定义如下：
$$
\boldsymbol p = \sum^N_{i=1}\sum^N_{j=1}g_{inner}(\boldsymbol f_i,\boldsymbol f_j) = \sum^N_{i=1}\sum^N_{j=1}\boldsymbol f_i\boldsymbol f_j^T = \boldsymbol f_\sum\boldsymbol f_\sum^T ,\\
其中 \boldsymbol f_\sum=\sum^N_{i=1}\boldsymbol f_i
$$
从式子的最终形式看，叠加矩阵$\boldsymbol p$ 的最终形式类似于让所有特征Embedding向量通过一个平均池化层（Average Pooling）后，再进行外积互操作。

在实际应用中，还应对平均池化的操作谨慎对待。因为把不同特征对应维度进行平均，实际上是假设不同特征的对应维度有类似的含义。但显然，如果一个特征是“年龄”，一个特征是“地域”，那么这两个特征在经过各自的Embedding层后，二者的Embedding向量不在一个向量空间中，显然不具备任何可比性。这时，把两者平均起来，会模糊很多有价值的信息。平均池化的操作经常发生在同类Embedding上，例如，将用户浏览过的多个物品的Embedding进行平均。因此，PNN模型的外积池化操作也需要谨慎，在训练效率和模型效果上进行权衡。

事实上，PNN模型在经过对特征的线性和乘积操作后，并没有把结果直接送入上层的$L_1$全连接层，而是在乘积层内部又进行了局部全连接层的转换，分别将线性部分z，乘积部分p映射成了$D_1$维的输入向量$\boldsymbol l_z$和$\boldsymbol l_p$($D_1$为$L_1$隐层的神经元数量)，再将$\boldsymbol l_z$和$\boldsymbol l_p$叠加，输入$L_1$隐层。这部分操作不具备创新性，并且可以被其他转换操作完全替代，因此不再详细介绍。

### 3.5.3 PNN模型的优势和局限性

PNN的结构特点在于强调了特征Embedding向量之间的交叉方式是多样化的，相比于简单的交由全连接层进行无差别化的处理，PNN模型定义的内积和外积操作显然更有针对性地强调了不同特征之间的交互，从而让模型更容易捕获特征的交叉信息。

但PNN模型同样存在着一些局限性，例如在外积操作的实际应用中，为了优化训练效率进行了大量的简化操作。此外，对所有特征进行无差别的交叉，在一定程度上忽略了原始特征向量中包含的有价值信息。如何综合原始特征及交叉特征，让特征交叉的方式更加高效，后续的Wide&Deep模型和基于FM的各类深度学习模型将给出它们的解决方案。

## 3.6 Wide&Deep模型——记忆能力和泛化能力

本节介绍的是自提出以来就在业界发挥着巨大影响力的模型——谷歌于2016年提出的Wide&Deep模型。Wide&Deep模型的主要思路正如其名，是由单层的Wide部分和多层的Deep部分组成的混合模型。其中，Wide部分的主要作用是让模型具有较强的“记忆能力”（memorization）；Deep部分的主要作用是让模型具有“泛化能力”（generalization），正是这样的结构特点，使模型兼具了逻辑回归和深度神经网络的优点——能够快速处理并记忆大量历史行为特征，并且具有强大的表达能力，不仅在当时迅速成为业界争相应用的主流模型，而且衍生出了大量以Wide&Deep模型为基础结构的混合模型，影响力一直延续至今。

### 3.6.1 模型的记忆能力与泛化能力

Wide&Deep模型的设计初衷和其最大的价值在于同时具备较强的“记忆能力”和“泛化能力”。“记忆能力”是一个新的概念，“泛化能力”虽在之前的章节中屡有提及，但从没有给出详细的解释，本节就对这两个概念进行详细的解释。

**“记忆能力”可以被理解为模型直接学习并利用历史数据中物品或者特征的“共现频率”的能力**。一般来说，协同过滤、逻辑回归等简单模型有较强的“记忆能力”。由于这类模型的结构简单，原始数据往往可以直接影响推荐结果，产生类似于“如果点击过A，就推荐B”这类规则式的推荐，这就相当于模型直接记住了历史数据的分布特点，并利用这些记忆进行推荐。

因为在Wide&Deep是由谷歌应用商店（Google Play）推荐团队提出的，所以这里以App推荐的场景为例，解释什么是模型的“记忆能力”。

假设在Google Play推荐模型的训练过程中，设置如下组合特征：AND(user_installed_app=netflix, impression_app=pandora)(简称netflix&pandora)，它代表用户已经安装了netflix这款应用，而且曾在应用商店中看到过pandora这款应用。如果以“最终是否安装pandora”为数据标签（label），则可以轻而易举地统计出netflix&pandora这个特征和安装pandora这个标签之间的共现频率。假设二者的共现频率高达10%（全局的平均安装率为1%），这个特征如此之强，以至于在设计模型时，希望模型一发现有这个特征，就推荐pandora这款应用（就像一个深刻的记忆点一样印在脑海里），这就是所谓的模型的“记忆能力”。像逻辑回归这类简单模型，如果发现这样的“强特征”，则其相应的权重就会在模型训练过程中被调整得非常大，这样就实现了对这个特征的直接记忆。相反，对于多层神经网络，特征会被多层处理，不断与其他特征进行交叉，因此模型对这个强特征的记忆反而没有简单模型深刻。

**“泛化能力”可以被理解为模型传递特征的相关性，以及发掘稀疏甚至从未出现过的稀有特征与最终标签相关性的能力。**矩阵分解比协同过滤的泛化能力强，因为矩阵分解引入了隐向量这样的结构，使得数据稀少的用户或者物品也能生成隐向量，从而获得有数据支撑的推荐得分，这就是非常典型的将全局数据传递到稀疏物品上，从而提高泛化能力的例子。再比如，深度神经网络通过特征的多次自动组合，可以深度发掘数据中潜在的模式，即使是非常稀疏的特征向量输入，也能得到较稳定平滑的推荐概率，这就是简单模型所缺乏的“泛化能力”。

### 3.6.2 Wide&Deep模型的结构

既然简单模型的“记忆能力”强，深度神经网络的“泛化能力”强，那么设计Wide&Deep模型的直接动机就是将两者融合。

Wide&Deep模型把单输入层的Wide部分与由Embedding层和多隐层组成的Deep部分连接起来，一起输入最终的输出层。单层的Wide部分善于处理大量稀疏的id类特征；Deep部分利用神经网络表达能力强的特点，进行深层的特征交叉，挖掘藏在特征背后的数据模式。最终，利用逻辑回归模型，输出层将Wide部分和Deep部分组合起来，形成统一的模型。

### 3.6.3 Wide&Deep模型的进化——Deep&Cross模型

Wide&Deep模型的提出不仅综合了“记忆能力”和“泛化能力”，而且开启了不同网络融合的新思路。在Wide&Deep模型之后，有越来越多的工作集中于分别改进Wide&Deep模型的Wide部分或是Deep部分。较典型的工作是2017年由斯坦福大学和谷歌的研究人员提出的Deep&Cross模型（简称DCN）。

Deep&Cross模型的主要思路是使用Cross网络替代原来的Wide部分。由于Deep部分的设计思路并没有本质的改变，所以本节着重介绍Cross部分的设计思路和具体实现。

设计Cross网络的目的是增加特征之间的交互力度，使用多层交叉层（Cross layer）对输入向量进行特征交叉。假设第l层交叉层的输出向量为$\boldsymbol x_l$，那么第l+1层的输出向量如下式所示：
$$
\boldsymbol x_{l+1}=\boldsymbol x_0\boldsymbol x^T_l\boldsymbol W_l+\boldsymbol b_l+\boldsymbol x_l
$$
可以看到，交叉层操作的二阶部分非常类似于3.5节PNN模型中提到的外积操作，在此基础上增加了外积操作的权重向量$\boldsymbol w_l$，以及原输入向量$\boldsymbol x_l$和偏置向量$\boldsymbol b_l$。

可以看出，交叉层在增加参数方面是比较“克制”的，每一层仅增加了一个n维的权重向量$\boldsymbol w_l$（n维输入向量维度），并且在每一层均保留了输入向量，因此输出与输入之间的变化不会特别明显。由多层交叉层组成的Cross网络在Wide&Deep模型中的Wide部分的基础上进行特征的自动化交叉，避免了更多基于业务理解的人工特征组合。同Wide&Deep模型一样，Deep&Cross模型的Deep部分相比Cross部分表达能力更强，使模型具备更强的非线性学习能力。

### 3.6.4 Wide&Deep模型的影响力

Wide&Deep模型能够取得成功的关键在于：

（1）抓住了业务问题的本质特点，能够融合传统模型记忆能力和深度学习模型泛化能力的优势。

（2）模型的结构并不复杂，比较容易在工程上实现、训练和上线，这加速了其在业界的推广应用。

## 3.7 FM与深度学习模型的结合

### 3.7.1 FNN——用FM的隐向量完成Embedding层初始化

FNN由伦敦大学学院的研究人员于2016年提出，其模型结构初步看是一个类似Deep Crossing模型的经典神经网络，从稀疏输入向量到稠密向量的转换过程也是经典的Embedding层的结构。那么，FNN模型到底在哪里与FM模型进行了结合呢？

问题的关键还在于Embedding层的改进。在神经网络的参数初始化过程中，往往采用随机初始化这种不包含任何先验信息的初始化方法。由于Embedding层的输入极端稀疏化，导致Embedding层的收敛速度非常缓慢。再加上Embedding层的参数数量往往占整个神经网络参数数量的大半以上，因此模型的收敛速度往往受限于Embedding层。

针对Embedding层收敛速度的难题，FNN模型的解决思路是用FM模型训练好的各个特征隐向量初始化Embedding的参数，相当于在初始化神经网络参数时，已经引入了有价值的先验信息。也就是说，神经网络训练的起点更接近目标的最优点，自然加速了整个神经网络的收敛过程。

### 3.7.2 DeepFM——用FM代替Wide部分

FNN把FM的训练结果作为初始化权重，并没有对神经网络的结构进行调整，而2017年由哈尔滨工业大学和华为公司联合提出的DeepFM则将FM的模型结构与Wide&Deep模型进行了整合。

3.6节曾经提到，在Wide&Deep模型之后，诸多模型延续了双模型组合的结构，DeepFM就是其中之一。DeepFM对Wide&Deep模型的改进之处在于，它用FM替换了原来的Wide部分，加强了浅层网络部分特征组合的能力。FM部分与神经网络部分共享相同的Embedding层。FM部分对不同特征域的Embedding进行了两两交叉，也就是将Embedding向量当作原FM中的特征隐向量。最后将FM的输出与Deep部分的输出一同输入最后的输出层，参与最后的目标拟合。

### 3.7.3 NFM——FM的神经网络化尝试

有没有可能利用深度神经网络更强的表达能力改进FM模型呢？2017年，新加坡国立大学的研究人员进行了这方面的尝试，提出了NFM模型。

在数学形式上，NFM模型的主要思路是用一个表达能力更强的函数替代原FM中二阶隐向量内积的部分。

如果用传统机器学习的思路来设计NFM模型中的函数f(x)，那么势必会通过一系列的数学推导构造一个表达能力更强的函数。但进入深度学习时代后，由于深度学习网络理论上有拟合任何复杂函数的能力，f(x)的构造工作可以交由某个深度学习网络来完成，并通过梯度反向传播来学习。

在NFM模型中，用以替代FM二阶部分的神经网络结构的特点非常明显，就是在Embedding层和多层神经网络之间加入特征交叉池化层（Bi-Interaction Pooling Layer）。

### 3.7.4 基于FM的深度学习模型的优点和局限性

本节介绍了FNN、Deep FM、NFM三个结合FM思路的深度学习模型。它们的特点都是在经典多层神经网络的基础上加入有针对性地特征交叉操作，让模型具备更强的非线性表达能力。

沿着特征工程自动化的思路，深度学习模型从PNN一路走来，经过了Wide&Deep、Deep&Cross、FNN、DeepFM、NFM等模型，进行了大量的、基于不同特征互操作思路的尝试。但特征工程的思路走到这里几乎已经穷尽了可能的尝试，模型进一步提升的空间非常小，这也是这类模型的局限性所在。

从这以后，越来越多的深度学习推荐模型开始探索更多“结构”上的尝试，诸如注意力机制、序列模型、强化学习等在其他领域大放异彩的模型结构也逐渐进入推荐模型领域，并且在推荐模型的效果提升上成果显著。

## 3.8 注意力机制在推荐模型中的应用

### 3.8.1 AFM——引入注意力机制的FM

### 3.8.2 DIN——引入注意力机制的深度学习网络

### 3.8.3 注意力机制对推荐系统的启发

## 3.9 DIEN——序列模型与推荐系统的结合

### 3.9.1 DIEN的“进化”动机

### 3.9.2 DIEN模型的架构

### 3.9.3 兴趣抽取层的结构

### 3.9.4 兴趣进化层的结构

### 3.9.5 序列模型对推荐系统的启发

## 3.10 强化学习与推荐系统的结合

## 3.11 总结——推荐系统的深度学习时代

| 模型名称      | 基本原理                                                     | 特点                                                         | 局限性                                                       |
| ------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| AutoRec       | 基于自编码器，对用户或者物品进行编码，利用自编码器的泛化能力进行推荐 | 单隐层神经网络结构简单，可实现快速训练和部署                 | 表达能力较差                                                 |
| Deep Crossing | 利用“Embedding层+多隐层+输出层”的经典深度学习框架，预完成特征的自动深度交叉 | 经典的深度学习推荐模型框架                                   | 利用全连接隐层进行特征交叉，针对性不强                       |
| NeuralCF      | 将传统的矩阵分解中用户向量和物品向量的点积操作，换成由神经网络代替的互操作 | 表达能力加强版的矩阵分解模型                                 | 只使用了用户和物品的id特征，没有加入更多其他特征             |
| PNN           | 针对不同特征域之间的交叉操作，定义“内积”“外积”等多种积操作   | 在经典深度学习框架上模型对提高特征交叉能力                   | “外积”操作进行了近似化，一定程度上影响了其表达能力           |
| Wide&Deep     | 利用Wide部分加强模型的“记忆能力”，利用Deep部分加强模型的“泛化能力” | 开创了组合模型的构造方法，对深度学习推荐模型的后续发展产生重大影响 | Wide部分需要人工进行特征组合的筛选                           |
| Deep&Cross    | 用Cross网络替代Wide&Deep模型中的Wide部分                     | 解决了Wide&Deep模型人工组合特征的问题                        | Cross网络的复杂度较高                                        |
| FNN           | 利用FM的参数来初始化深度神经网络的Embedding层参数            | 利用FM初始化参数，加快整个网络的收敛速度                     | 模型的主结构比较简单，没有针对性的特征交叉层                 |
| DeepFM        | 在Wide&Deep模型的基础上，用FM替代原来的线性Wide部分          | 加强了Wide部分的特征交叉能力                                 | 与经典的Wide&Deep模型相比，结构差别不明显                    |
| NFM           | 用神经网络代替FM中二阶隐向量交叉的操作                       | 相比FM，NFM的表达能力和特征交叉能力更强                      | 与PNN模型的结构非常相似                                      |
| AFM           | 在FM的基础上，在二阶隐向量交叉的基础上对每个交叉结果加入了注意力得分，并使用注意力网络学习注意力得分 | 不同交叉特征的重要性不同                                     | 注意力网络的训练过程比较复杂                                 |
| DIN           | 在传统深度学习推荐模型的基础上引入注意力机制，并利用用户行为历史物品和目标广告物品的相关性计算注意力得分 | 根据目标广告物品的不同，进行更有针对性的推荐                 | 并没有充分利用除“历史行为”以外的其他特征                     |
| DIEN          | 将序列模型与深度学习推荐模型结合，使用序列模型模拟用户的兴趣进化过程 | 序列模型增强了系统对用户兴趣变迁的表达能力，使推荐系统开始考虑时间相关的行为序列中包含的有价值信息 | 序列模型的训练复杂，线上服务的延迟较长，需要进行工程上的优化 |
| DRN           | 将强化学习的思路应用于推荐系统，进行推荐系统的线上实时学习和更新 | 模型对数据实时性的利用能力大大加强                           | 线上部分较复杂，工程实现难度较大                             |



# 第4章 Embedding技术在推荐系统中的应用

# 第5章 多角度审视推荐系统

在构建推荐模型的过程中，推荐模型的作用是重要的，但这绝不意味着推荐模型就是推荐系统的全部。事实上，推荐系统需要解决的问题是综合性的，任何一个技术细节的缺失都会影响最终的推荐效果。这就要求推荐工程师从不同的维度审视推荐系统，不仅抓住问题的核心，更要从整体上思考推荐问题。

本章从7个不同的角度切入推荐系统，希望能够较为全面地覆盖推荐系统相关知识，具体包括以下内容：

1. 推荐系统如何选取和处理特征？
2. 推荐系统召回层地主要策略有哪些？
3. 推荐系统实时性的重要性体现在哪儿？有哪些提高实时性的方法？
4. 如何根据具体场景构建推荐模型的优化目标？
5. 如何基于用户动机改进模型结构？
6. 推荐系统冷启动问题的解决方法有哪些？
7. 什么是“探索和利用”问题？有哪些主流的解决方法？

## 5.1 推荐系统的特征工程

"Garbage in garbage out(垃圾进，垃圾出)"是算法工程师经常提到的一句话。机器学习模型的能力边界在于对数据的拟合和泛化，那么数据及表达数据的特征本身就决定了机器学习模型效果的上限。因此，特征工程对推荐系统效果提升的作用是无法替代的。为了构建一个“好”的特征工程，需要依次解决三个问题：

1. 构建特征工程应该遵循的基本原则是什么？
2. 有哪些常用的特征类别？
3. 如何在原始特征的基础上进行特征处理，生成可供推荐系统训练和推断用的特征向量？

### 5.1.1 构建推荐系统特征工程的原则

在推荐系统中，**特征的本质其实是对某个行为过程相关信息的抽象表达**。推荐过程中某个行为必须转换成某种数学形式才能被机器学习模型所学习，因此为了完成这种转换，就必须将这些行为过程中的信息以特征的形式抽取出来，用多维度上的特征表达这一行为。

从具体的行为转化成抽象的特征，这一过程必然涉及信息的损失。

- 一是因为具体的推荐行为和场景中包含大量原始的场景、图片和状态信息，保存所有信息的存储空间过大，无法在现实中满足；
- 二是因为具体的推荐场景中包含大量冗余的、无用的信息，都考虑进来甚至会损害模型的泛化能力。

搞清楚这两点后，就可以顺利成章地提出构建**推荐系统特征工程的原则**：

尽可能地让特征工程抽取出的一组特征能够保留推荐环境及用户行为过程中的所有有用信息，尽量摒弃冗余信息。



举例来说，在一个电影推荐的场景下，应该如何抽取特征才能代表“用户点击某个电影”这一行为呢？

为了回答这个问题，我们可以想象自己选择点击某个电影过程受什么因素影响？

1. 自己对电影类型的兴趣偏好
2. 该电影是否是流行的大片。
3. 该影片中是否有自己喜好的演员和导演。
4. 电影的海报是否有吸引力。
5. 自己是否看过该影片。
6. 自己当时的心情。

秉着“**保留行为过程中的所有有用信息**”的原则，从电影推荐场景中抽取特征时，应该让特征能够尽量保留上述6个要素的信息。因此，要素、有用信息和数据抽取出的特征的对应关系如下表所示

| 要素                               | 有用信息和数据           | 特征                                            |
| ---------------------------------- | ------------------------ | ----------------------------------------------- |
| 自己对电影类型的兴趣偏好           | 历史观看影片序列         | 影片id序列特征，或进一步抽取出兴趣Embedding特征 |
| 该电影是否是流行的大片             | 影片的流行分数           | 流行度特征                                      |
| 该影片中是否有自己喜好的演员和导演 | 影片的元数据，即相关信息 | 元数据标签类特征                                |
| 电影的海报是否有吸引力             | 影片海报的图像           | 图像内容类特征                                  |
| 自己是否看过该影片                 | 用户观看历史             | 是否观看的布尔型特征                            |
| 自己当时的心情                     | 无法抽取                 | 无                                              |

值得注意的是，在抽取特征的过程中，必然存在着信息的损失，例如，“自己当时的心情”这个要素被无奈地舍弃了。再比如，用用户观看历史推断用户的“兴趣偏好”也一定会存在信息丢失的情况。因此，在已有的、可获得的数据基础上，“尽量”保留有用信息是一个现实的工程上的原则。

### 5.1.2 推荐系统中的常用特征

在推荐系统特征工程原则的基础上，本节列出在推荐系统中常用的特征类别，供读者在构建自己的特征工程时参考。

#### 1. 用户行为数据

用户行为数据是推荐系统最常用，也是最关键的数据。用户在潜在兴趣、用户对物品的真实评价均包含在用户的行为历史中。用户行为在推荐系统中一般分为显性反馈行为（explicit feedback）和隐性反馈行为（implicit feedback）两种，在不同的业务场景中，则以不同的形式体现。下表所示为不同业务场景下用户行为数据的例子。

| 业务场景     | 显性反馈行为             | 隐形反馈行为             |
| ------------ | ------------------------ | ------------------------ |
| 电子商务网站 | 对商品的评分             | 点击、加入购物车、购买等 |
| 视频网站     | 对视频的评分、点赞等     | 点击、播放、播放时长等   |
| 新闻类网站   | 赞、踩等行为             | 点击、评论等             |
| 音乐网站     | 对歌曲、歌手、专辑的评分 | 点击、播放、收藏等       |

对用户行为数据的使用往往涉及对业务的理解，不同的行为在抽取特征时的权重不同，而且一些跟业务特点强相关的用户行为需要推荐工程师通过自己的观察才能发现。

在当前的推荐系统特征工程中，隐性反馈行为越来越重要，主要原因是显性反馈行为的收集难度过大，数据量小。在深度学习模型对数据量的要求越来越大的背景下，仅用显性反馈的数据不足以支持推荐系统训练过程的最终收敛。因此，能够反映用户行为特点的隐性反馈是目前特征挖掘的重点。

在具体的用户行为类特征的处理上，往往有两种方式：一种是将代表用户行为的物品id序列转换成multi-hot向量，将其作为特征向量；另一种是预先训练好物品的Embedding（可参考第4章介绍的Embedding方法），再通过平均或者类似于DIN模型（可参考3.8节）注意力机制的方法生成历史行为Embedding向量，将其作为特征向量。

#### 2. 用户关系数据

互联网本质上就是人与人、人与信息之间的连接。如果说用户行为数据是人与物之间的“连接”日志，那么用户关系数据就是人与人之间连接的记录。用户关系数据毫无疑问是值得推荐系统利用的有价值信息。

用户关系数据也可以分为“显性”和“隐性”两种，或者称为“强关系”和“弱关系”。用户和用户之间可以通过“关注”“好友关系”等连接建立“强关系”，也可以通过“互相点赞”“同处一个社区”，甚至“同看一部电影”建立“弱关系”。

在推荐系统中，利用用户关系数据的方式不尽相同，可以将用户关系作为召回层的一种物品召回方式；也可以通过用户关系建立关系图，使用Graph Embedding的方法生成用户和物品的Embedding；还可以直接利用关系数据，通过“好友”的特征为用户添加新的属性特征；甚至可以利用用户关系数据直接建立社会化推荐系统。

#### 3. 属性、标签类数据

这里把属性类和标签类数据归为一组进行讨论，因为本质上它们都是直接描述用品或物品的特征。属性和标签的主体可以是用户，也可以是物品。他们的来源非常多样化，大体上包含下表中的几类

| 主体 | 类别                                                         | 来源                                                         |
| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 用户 | 人口属性数据（性别、年龄、住址等）                           | 用户注册信息、第三方DMP（Data Management Platform，数据管理平台） |
|      | 用户兴趣标签                                                 | 用户选择                                                     |
| 物品 | 物品标签                                                     | 用户或者系统管理员添加                                       |
|      | 物品属性（例如，商品的类别、价格；电影的分类、年代、演员、导演等信息） | 后台录入、第三方数据库                                       |

用户属性、物品属性、标签类数据是最重要的描述性特征。成熟的公司往往会建立一套用户和物品的标签体系，由专门的团队负责维护，典型的例子就是电商公司的商品分类体系；也可以有一些社交化的方法由用户添加。例如豆瓣的“添加收藏”页面，在添加收藏的过程中，用户需要为收藏对象打上对应的标签，这是一种常见的社交化标签添加方法。

在推荐系统中使用属性、标签类数据，一般是通过multi-hot编码的方式将其转换成特征向量，一些重要的属性标签类特征也可以先转换成Embedding，再输入推荐模型。

#### 4. 内容类数据

内容类数据可以看作属性标签型特征的延伸，它们同样是描述物品或用户的数据，但相比标签类特征，内容类数据往往是大段的描述型文字、图片，甚至视频。

一般来说，内容类数据无法直接转换成推荐系统可以“消化”的特征，需要通过自然语言处理、计算机视觉等技术手段提取关键内容特征，再输入推荐系统。例如，在图片类、视频类或是带有图片的信息流推荐场景中，往往会利用计算机视觉模型进行目标检测，抽取图片特征，再把这些特征（要素）转换成标签类数据，供推荐系统使用。

#### 5. 上下文信息

上下文信息（context）是描述推荐行为产生的场景的信息。最常用的上下文信息是“时间”和通过GPS获得的“地点”信息。根据推荐场景的不同，上下文信息的范围极广，包含但不限于时间、地点、季节、月份、是否节假日、天气、空气质量、社会大事件等信息。

引入上下文信息的目的是尽可能地保存推荐行为发生场景的信息。典型的例子是：在视频推荐场景中，用户倾向于在傍晚看轻松浪漫题材的电影，在深夜看悬疑惊悚题材的电影。如果不引入上下文特征，则推荐系统无法捕捉到与这些场景相关的有价值的信息。

#### 6. 统计类特征

统计类特征是指通过统计方法计算出的特征，例如历史CTR、历史CVR、物品热门程度、物品流行程度等。统计类特征一般是连续型特征，仅需经过标准归一化等处理就可以直接输入推荐系统进行训练。

统计类特征本质上是一些粗粒度的预测指标。例如在CTR预估问题中，完全可以将某物品的历史平均CTR当作最简易的预测模型，但该模型的预测能力很弱，因此历史平均CTR往往仅被当作复杂CTR模型的特征之一。统计类特征往往与最后预测目标有较强相关性，因此是绝不应该被忽视的重要特征类别。

#### 7.  组合类特征

组合类特征是指将不同特征进行组合后生成的新特征。最常见的是“年龄+性别”组成的人口属性分段特征（segment）。在早期的推荐系统中，推荐模型（比如逻辑回归）往往不具备特征组合的能力。但是随着更多深度学习推荐系统的提出，组合类特征不一定通过人工组合、人工筛选的方法提出，还可以交给模型进行自动处理。

### 5.1.3 常用的特征处理方法

对推荐系统来说，模型的输入往往是由数字组成的特征向量。5.1.2节提到的诸多特征类别中，有“年龄”“播放时长”“历史CTR”这些可以由数字表达的例如用户的性别、用户的观看历史，它们是如何转变成数值型特征向量的呢？本节将从连续型（continuous）特征和类别型（categorical）特征两个角度介绍常用的特征处理方法。

#### 1. 连续性特征

连续性特征的典型例子是上文提到的用户年龄、统计类特征、物品的发布时间、影片的播放时长等数值型的特征。对于这类特征的处理，最常用的处理手段包括归一化、离散化、加非线性函数等方法。

归一化的主要目的是统一各特征的量纲，将连续特征归一到[0,1]区间。也可以做0均值归一化，即将原始数据集归一化为均值为0、方差为1的数据集。

离散化是通过确定分位数的形式将原来的连续值进行分桶，最终形成离散值的过程。离散化的主要目的是防止连续值带来的过拟合现象及特征值分布不均匀的情况。经过离散化处理的连续型特征和经过one-hot处理的类别型特征一样，都是以特征向量的形式输入推荐模型中的。

加非线性函数的处理方法，是直接把原来的特征通过非线性函数做变换，然后把原来的特征及变换后的特征一起加入模型进行训练的过程。常用的非线性函数包括$x^a,\log_a(x),\log(\frac{x}{1-x})$。

加非线性函数的目的是更好地捕获特征与优化目标之间的非线性关系，增强这个模型的非线性表达能力。

#### 2. 类别性特征

类别型特征的典型例子是用户的历史行为数据、属性标签类数据等。它的原始表现形式往往是一个类别或者一个id。这类特征最常用的处理方法是使用one-hot编码将其转换成一个数值向量，2.5节的“基础知识”部分已经详细介绍了one-hot编码的具体过程，在one-hot编码的基础上，面对同一个特征域非唯一的类别选择，还可以采用multi-hot编码。

> **什么是multi-hot编码**？
>
> 对历史行为序列类、标签特征等数据来说，用户往往会与多个物品产生交互行为，或者被打上同类别标签，这时最常用的特征向量生成方式就是把其转换为multi-hot编码。
>
> 举例来说，某电商网站共有10000种商品，用户购买过其中的10种，那么用户的历史行为数据就可以转换成一个10000维的数值向量，其中仅有10个已购买商品对应的维度是1，其余维度均为0，这就是multi-hot编码。

对类别特征进行one-hot或multi-hot编码的主要问题是特征向量维度过大，特征过于稀疏，容易造成模型欠拟合，模型的权重参数的数量过多，导致模型收敛过慢。因此，在Embedding技术成熟后，被广泛应用在类别特征的处理上，先将类别型特征编码成稠密Embedding向量，再与其他特征组合，形成最终的输入特征向量。

### 5.1.4 特征工程与业务理解

## 5.2 推荐系统召回层的主要策略

在1.2节的推荐系统技术架构图中，清晰地描述了推荐模型部分的两个主要阶段——召回阶段和排序阶段。其中召回阶段负责将海量的候选集快速缩小为几百到几千的规模；而排序阶段则负责对缩小后的候选集进行精准排序。第2章和第3章的推荐模型主要应用于推荐系统的排序阶段，本节将着重介绍召回层的主要策略。

### 5.2.1 召回层和排序层的功能特点

推荐系统的模型部分将推荐过程分成召回层和排序层的主要原因是基于工程上的考虑。在排序阶段，一般会使用复杂模型，利用多特征进行精准排序，而在这一过程中，如果直接对百万量级的候选集进行逐一推断，则计算资源和延迟都是在线服务过程无法忍受的。因此加入召回过程，利用少量的特征和简单的模型或规则进行候选集的快速筛选，减少精准排序阶段的时间开销。

结合召回层、排序层的设计初衷和系统结构，可以总结出召回层和排序层的如下特点：

- **召回层**：待计算的候选集合大、速度快、模型简单、特征较少，尽量让用户感兴趣的物品在这个阶段能够被快速召回，即保证相关物品的召回率。
- **排序层**：首要目标是得到精准的排序结果。需处理的物品数量少，可利用较多特征，使用比较复杂的模型。

在设计召回层时，“计算速度”和“召回率”其实是矛盾的两个指标，为提高“计算速度”，需要使召回策略尽量简单；而为了提高“召回率”，要求召回策略能够尽量选出排序模型需要的候选集，这又要求召回策略不能过于简单，导致召回物品无法满足排序模型的要求。

在权衡计算速度和召回率后，目前工业界主流的召回方法是采用多个简单策略叠加的“多路召回策略”。

### 5.2.2 多路召回策略

所谓“多路召回策略”，就是指采用不同的策略、特征或简单模型，分别召回一部分候选集，然后把候选集混合在一起供后续排序模型使用的策略。

可以明显地看出，“多路召回策略”是在“计算速度”和“召回率”之间进行权衡地结果。其中，各简单策略保证候选集的快速召回，从不同角度设计的策略保证召回率接近理想的状态，不至于损害排序效果。

以某信息流应用为例，展示了其常用的多路召回策略，包括“热门新闻”“兴趣标签”“协同过滤”“最近流行”“朋友喜欢”等多种召回方法。其中，既包括一些计算效率高的简单模型（如协同过滤）；也包括一些基于单一特征的召回方法（如兴趣标签），还包括一些预处理好的召回策略（如热门新闻、最近流行等）。

~~~mermaid
graph LR
	subgraph 召回层
		热门新闻
		兴趣标签
		协同过滤
		最近流行
		朋友喜欢
	end
	subgraph 排序层
		排序模型[排序模型:LR/FM/DeepFM/DIN/DIEN/DRN等等]
	end
	热门新闻--Top K1-->排序模型
	兴趣标签--Top K2-->排序模型
	协同过滤--Top K3-->排序模型
	最近流行--Top K4-->排序模型
	朋友喜欢--Top K5-->排序模型
~~~

事实上，召回策略的选择与业务强相关。

每一路召回策略会拉回K个候选物品，对于不同的召回策略，K值可以选择不同的大小。这里的K值是超参数，一般需要通过离线评估加线上A/B测试的方式确定合理的取值范围。

虽然多路召回是实用的工程方法，但从策略选择到候选集大小参数的调整都需要人工参与，策略间的信息也是割裂的，无法综合考虑不同策略对一个物品的影响。那么，是否存在一个综合性强且计算速度也能满足需求的召回方法呢？基于Embedding的召回方法给出了可行的方案。

### 5.2.3 基于Embedding的召回方法

4.5节曾详细介绍了YouTube推荐系统中利用深度学习网络生成Embedding作为召回层的方法。再加上可以使用局部敏感哈希进行快速的Embedding最近邻计算，基于Embedding的召回方法在效果和速度上均不逊色于多路召回。

事实上，多路召回中使用“兴趣标签”“热门度”“流行趋势”“物品属性”等信息都可以作为Embedding召回方法中的附加信息（side information）融合进最终的Embedding向量中（典型例子是4.4节介绍的EGES Embedding方法）。就相当于在利用Embedding召回的过程中，考虑到了多路召回的多种策略。

Embedding召回的另一个优势在于评分的连续性。多路召回中不同召回策略产生的相似度、热度等分值不具备可比性，无法据此决定每个召回策略放回候选集的大小。Embedding召回可以把Embedding间的相似度作为唯一的判断标准，因此可以随意限定召回的候选集大小。

生成Embedding的方法也绝不是唯一的。除了第4章介绍的Item2vec、GraphEmbedding等方法，矩阵分解、因子分解机等简单模型也完全可以得出用户和物品的Embedding向量。在实际应用中可以根据效果确定最优的召回层Embedding的生成方法。

## 5.3 推荐系统的实时性

### 5.3.1 为什么说推荐系统的实时性是重要的

在解决怎样提高推荐系统实时性这个问题之前，我们先思考“推荐系统的实时性是不是一个重要的影响推荐效果的因素”。为了证明推荐系统实时性和推荐效果之间的关系，Facebook曾利用“GBDT+LR”模型进行过实时性的实验，损失函数Normalized Entropy（归一化交叉熵）的相对值的值跟模型更新延迟有正相关的关系，也就意味着模型更新的间隔时间越长，推荐系统的效果越差；反过来说，模型更新得越频繁，实时性越好，损失越小，效果越好。

从用户体验的角度讲，只要推荐系统能感知用户反馈、实时地满足用户的期望目标，就能提高推荐的效果，这就是推荐系统“实时性”作用的直观体现。

从机器学习的角度讲，推荐系统实时性的重要之处体现在以下两个方面：

1. 推荐系统的更新速度越快，代表用户最近习惯和爱好的特征更新越快，越能为用户进行更有时效性的推荐。
2. 推荐系统更新得越快，模型越容易发现最新流行的数据模式（data pattern），越能让模型快速抓住最新的流行趋势。

这两方面的原因直接对应着推荐系统实时性的两个要素：一是推荐系统“特征”的实时性；二是推荐系统“模型”的实时性。

### 5.3.2 推荐系统“特征”的实时性

**推荐系统特征的实时性指的是“实时”地收集和更新推荐模型的输入特征，使推荐系统总能使用最新的特征进行预测和推荐。**

#### 1.客户端实时特征

客户端是最接近用户的环节，也是能够实时手机用户会话内行为及所有上下文特征的地方。在经典的推荐系统中，利用客户端收集时间、地点、推荐场景等上下文特征，然后让这些特征随http请求一起到达服务器端是常用的请求推荐结果的方式。但容易被忽视的一点是客户端还是能实时收集session（会话）内用户行为的地方。

如果客户端能够缓存session内部的行为，将其作为与上下文特征同样的实时特征传给推荐服务器，那么推荐模型就能够实时地得到session内部的行为特征，进行实时的推荐。这就是利用客户端实时特征进行实时推荐的优势所在。

#### 2.流计算平台的准实时特征处理

随着Storm、Spark Streaming、Flink等一批非常优秀的流计算平台的日益成熟，利用流计算平台进行准实时的特征处理几乎成了当前推荐系统的标配。所谓流计算平台，是将日志以流的形式进行微批处理（mini batch）。由于每次需要等待并处理一小批日志，流计算平台并非完全实时的平台，但它的优势是能够进行一些简单的统计类特征的计算，比如一个物品在该时间窗口内的曝光次数、点击次数、一个用户在该时间窗口内的点击话题分布，等等。

流计算平台计算出的特征可以立刻存入特征数据库供推荐模型使用。虽然无法实时根据用户行为改变用户结果，但分钟级别的延迟基本可以保证推荐系统能够准实时地引入用户的近期行为。

#### 3.分布式批处理平台的全量特征处理

随着数据最终到达以HDFS为主的分布式存储系统，Spark等分布式批处理计算平台终于能够进行全量特征的计算和抽取了。在这个阶段着重进行的还有多个数据源的数据联结（join）及延迟信号的合并等操作。

用户的曝光、点击、转化数据往往是在不同时间到达HDFS的，有些游戏类应用的转化数据延迟甚至高达几个小时，因此只有在全量数据批处理这一阶段才能进行全部特征及相应标签的抽取和合并。也只有在全量特征准备好之后，才能够进行更高阶的特征组合的工作。这往往是无法在客户端和流计算平台上进行的。

分布式批处理平台的计算结果的主要用途是：

1. 模型训练和离线评估
2. 特征保存入特征数据库，供之后的线上推荐模型使用。

数据从产生到完全进入HDFS，再加上Spark的计算延迟，这一过程的总延迟往往达到小时级别，已经无法进行所谓的“实时”推荐，因此更多的是保证推荐系统特征的全面性，以便在用户下次登录时进行更准确的推荐。

### 5.3.3 推荐系统“模型”的实时性

与“特征”的实时性相比，推荐系统“模型”的实时性往往是从更全局的角度考虑问题。特征的实时性力图用更准确的特征用户、物品和相关场景，从而让推荐系统给出更符合当时场景的推荐结果。而模型的实时性则是希望更快地抓住全局层面的新数据模式，发现新的趋势和相关性。

模型的实时性是与模型的训练方式紧密相关的，**模型的实时性从弱到强的训练方式分别是全量更新、增量更新和在线学习（Online Learning）**。

#### 1.全量更新

“全量更新”是指模型利用某时间段内的所有训练样本进行训练。全量更新是最常用的模型训练方式，但它需要等待所有训练数据都“落盘”（记录在HDFS等大数据存储系统中）才能进行，并且训练全量样本的时间往往较长，因此全量更新也是实时性最差更新方式。与之相比，“增量更新”的训练方式可以有效提高训练效率。

#### 2.增量更新

增量更新仅将新加入的样本“喂”给模型进行增量训练。从技术上讲，深度学习模型往往采用随机梯度下降（SGD）法及其变种进行学习，模型对增量样本的学习相当于在原有样本的基础上继续输入增量样本进行梯度下降。增量更新的缺点是：增量更新的模型往往无法找到全局最优点，因此在实际的推荐系统中，经常采用增量更新与全局更新，纠正模型在增量更新过程中积累的误差。

#### 3.在线学习

在线学习是进行模型实时更新的主要方法，也就是在获得一个新样本的同时更新模型。与增量更新一样，在线学习在技术上也通过SGD的训练方式实现，但由于需要在线上环境进行模型的训练和大量模型相关参数的更新和存储，工程上的要求相对比较高。

在线学习的另一个附带问题是模型的稀疏性不强，例如，在一个输入特征向量达到几百万维的模型中，如果模型的稀疏性好，就可以在模型效果不受影响的前提下，仅让极小一部分特征对应的权重非零，从而让上线的模型体积很小（因为可以摒弃所有权重为0的特征），这有利于加快整个模型服务的过程。但如果使用SGD的方式进行模型更新，相比batch的方式，容易产生大量小权重的特征，这就增大了模型体积，从而增大模型部署和更新的难度。为了在在线学习过程中兼顾训练效果和模型稀疏性，有大量相关的研究，最著名的包括微软的FOBOS、谷歌的FTRL等。

在线学习的另一个方向是将强化学习与推荐系统结合，在3.10节介绍的强化学习推荐模型DRN中，应用了一种竞争梯度下降算法，它通过“随机探索新的深度学习模型参数，并根据实时效果反馈进行参数调整”的方法进行在线学习，这是在强化学习框架下提高模型实时性的有效尝试。

#### 4.局部更新

提高模型实时性的另一个改进方向是进行模型的局部更新，大致的思路是降低训练效率低的部分的更新频率，提高训练效率高的部分的更新频率。这种形式的代表是Facebook的“GBDT+LR”模型。

2.6节已经介绍过“GBDT+LR”的模型结构，模型利用GBDT进行自动化的特征工程，利用LR拟合优化目标。GBDT是串行的，需要依次训练每一棵树，因此训练效率低，更新的周期长，如果每次都同时训练“GBDT+LR”整个模型，那么GDBT的低效问题将拖慢LR的更新速度。为了兼顾GBDT的特征处理能力和LR的更新速度。为了兼顾GBDT的特征处理能力和LR快速拟合优化目标的能力，Facebook采取的部署方式是每天训练一次GBDT模型，固定GBDT模型后，实时训练LR模型以快速捕捉数据整体的变化。通过模型的局部更新，做到GBDT和LR能力的权衡。

“模型局部更新”的做法较多应用在“Embedding层+神经网络”的深度学习模型中，Embedding层参数由于占据了深度学习模型参数的大部分，其训练过程会拖慢模型整体的收敛速度，因此业界往往采用Embedding曾单独预训练，Embedding层以上的模型部分高频更新的混合策略，这也是“模型局部更新”思想的有一次应用。

#### 5.客户端模型实时更新

客户端模型实时更新在推荐系统业界仍处于探索阶段。

### 5.3.4 用“木桶理论”看待推荐系统的迭代升级

推荐系统的模型部分和工程部分总是迭代进行、交替优化的。当通过改进模型增加推荐效果的尝试受阻或者成本较高时，可以将优化的方向聚焦在工程部分，从而达到花较少的精力，达成更显著效果的目的。

## 5.4 如何合理设定推荐系统中的优化目标

**如果一项技术本身是新颖的、先进的，但应用的方向与实际需求的方向有偏差，那这项技术的成果不可能是显著的**。在推荐系统中，如果你的推荐模型的优化目标是不准确的，即使模型的评估指标做得再好，也肯定与实际所希望达到的目标南辕北辙。

设定一个“合理”的推荐系统优化目标，首先需要确立一个“合理”的原则。对一家商业公司而言，在绝大多数情况下，推荐系统的目标都是完成某个商业目标，所以根据公司的商业目标来制定推荐系统的优化目标理应作为“合理”的战略性目标。

### 5.4.1 YouTube以观看时长为优化目标的合理性

为了完成公司的商业目标，YouTube推荐系统的优化目标并不是点击率、播放率等通常意义上的CTR预估类的优化目标，而是用户的播放时长。

### 5.4.2 模型优化和应用场景的统一性

优化目标的指定还应该考虑的要素是模型优化场景和应用场景的统一性，在这一点上，阿里巴巴的多目标优化模型给出了一个很好的例子。

与YouTube等视频网站不同，对电商类网站而言，公司的商业目标是通过推荐使用户产生更多的购买行为。按照“优化目标应与公司商业目标一致”的原则，电商类推荐模型应该是一个CVR预估模型。

### 5.4.3 优化目标是和其他团队的接口性工作

## 5.5 推荐系统中比模型结构更重要的是什么

### 5.5.1 有解决推荐问题的“银弹”吗

推荐模型的结构不是构建一个好的推荐系统的“银弹”，真正的“银弹”是你对用户行为和应用场景的观察，基于这些观察，改进出最能表达这些观察的模型结构。

### 5.5.2 Netflix对用户行为的观察

### 5.5.3 观察用户行为，在模型中加入有价值的用户信息

### 5.5.4 DIN模型的改进动机

### 5.5.5 算法工程师不能只是一个“炼金术士”

如果阅读本书的你已经有了几年工作经验，对机器学习的相关技术已经驾轻就熟，反而应该从技术中跳出来，站在用户的角度，深度体验他们的想法，发现他们想法中的偏好和习惯，再用机器学习工具去验证它、模拟它，会得到意想不到的效果。

## 5.6 冷启动的解决方法

# 第7章 推荐系统的评估

# 第8章 深度学习推荐系统的前沿实践

## 8.1 Facebook的深度学习推荐系统

### 8.1.6 Facebook的深度学习模型DLRM

时隔5年，Facebook于2019年再次公布了其推荐系统深度学习模型DLRM（Deep Learning Recommender Model），相比于GBDT+LR，DLRM是一次彻底的应用深度学习模型的尝试。

# 第9章 构建属于你的推荐系统知识框架

## 9.2 推荐模型发展的时间线

| 年代       | 机构                 | 模型                        |
| ---------- | -------------------- | --------------------------- |
| 1992年     | Xerox研究中心        | 协同过滤算法                |
| 2003年     | 亚马逊               | ItemCF                      |
| 2006年     | Netflix Prize        | 矩阵分解模型                |
| 2010年     | 大阪大学             | FM                          |
| 2013年     | 谷歌                 | FTRL                        |
| 2013年     | 谷歌                 | Word2vec                    |
| 2014年     | 石溪大学             | Graph Embedding、Deep Walk  |
| 2014年     | Facebook             | GBDT+LR                     |
| 2015年     | 澳大利亚国立大学     | AutoRec                     |
| 2016年1月  | 伦敦大学学院         | FNN                         |
| 2016年3月  | 微软                 | Item2vec                    |
| 2016年6月  | 谷歌                 | Wide&Deep                   |
| 2016年7月  | 斯坦福大学           | Node2vec                    |
| 2016年8月  | 微软                 | Deep Crossing               |
| 2016年9月  | Criteo               | FFM                         |
| 2016年11月 | 上海交通大学         | PNN                         |
| 2017年3月  | 华为、哈尔滨工业大学 | DeepFM                      |
| 2017年4月  | 新加坡国立大学       | NeuralCF                    |
| 2017年4月  | 阿里巴巴             | MLR                         |
| 2017年6月  | 阿里巴巴             | DIN                         |
| 2017年8月  | 斯坦福大学、谷歌     | DCN                         |
| 2017年8月  | 新加坡国立大学       | NeuralFM                    |
| 2017年8月  | 浙江大学             | Attentional FM              |
| 2018年5月  | 阿里巴巴             | EGES                        |
| 2018年8月  | Airbnb               | 实时个性化搜索中的Embedding |
| 2019年5月  | Facebook             | DLRM                        |
| 2019年7月  | 阿里巴巴             | DIEN                        |

